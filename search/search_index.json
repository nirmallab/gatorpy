{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#gator-a-scalable-framework-for-automated-processing-of-highly-multiplexed-tissue-images","title":"GATOR: A scalable framework for automated processing of highly multiplexed tissue images","text":"<p>Multiplexed imaging has advanced spatial biology and revealed critical cell communication networks in tissue development and diseases. However, the scalable application of multiplexed imaging technology remains a significant challenge due to the need for human-in-the-loop processes. We developed a computational framework called GATOR that combines deep learning and statistical approaches to pre-process and phenotype single cells without visual intervention. An end-end python implementation of Gator is provided to facilitate the large-scale application of spatial biology in clinical and research settings. </p>"},{"location":"Getting%20Started/","title":"\ud83d\udc0a Getting Started with Gator","text":"<p>Kindly note that Gator is not a plug-and-play solution. It's a framework that requires significant upfront investment of time from potential users for training and validating deep learning models, which can then be utilized in a plug-and-play manner for processing large volumes of similar multiplexed imaging data.</p> <p>There are two ways to set it up based on how you would like to run the program - Using an interactive environment like Jupyter Notebooks - Using Command Line Interface  </p> <p>Before we set up Gator, we highly recommend using a environment manager like Conda. Using an environment manager like Conda allows you to create and manage isolated environments with specific package versions and dependencies. </p> <p>Download and Install the right conda based on the opertating system that you are using</p>"},{"location":"Getting%20Started/#create-a-new-conda-environment","title":"Create a new conda environment","text":"<pre><code># use the terminal (mac/linux) and anaconda promt (windows) to run the following command\nconda create --name gator -y python=3.9\nconda activate gator\n</code></pre> <p>Install <code>gatorpy</code> within the conda environment.</p> <pre><code>pip install gatorpy\n</code></pre>"},{"location":"Getting%20Started/#interactive-mode","title":"Interactive Mode","text":"<p>Using IDE or Jupyter notebooks</p> <pre><code>pip install notebook\n\n# open the notebook and import Gator\nimport gatorpy as ga\n# Go to the tutorial section to follow along\n</code></pre>"},{"location":"Getting%20Started/#command-line-interface","title":"Command Line Interface","text":"<pre><code>wget https://github.com/nirmalLab/gatorpy/archive/main.zip\nunzip main.zip \ncd gatorpy-main/gatorpy \n# Go to the tutorial section to follow along\n</code></pre>"},{"location":"Getting%20Started/#docker-container","title":"Docker Container","text":"<pre><code>docker pull nirmallab/gatorpy:gatorpy\n# Go to the tutorial section to follow along\n</code></pre>"},{"location":"Workflow/","title":"Workflow","text":""},{"location":"Workflow/#cheatsheet-for-gator-workflow","title":"Cheatsheet for Gator Workflow","text":""},{"location":"Functions/addPredictions/","title":"addPredictions","text":"<p>Short Description</p> <p>The <code>addPredictions</code> function serves as a link between <code>gatorpy</code> and <code>scimap</code> package.  It's useful for evaluating model performance. The function transforms results  stored in <code>anndata.uns</code> to <code>anndata.obs</code> so they can be visualized using  the <code>scimap</code> package's <code>sm.pl.image viewer</code> function. This displays <code>positive</code>  and <code>negative</code> cells overlaid on the raw image.</p> <p>The <code>addPredictions</code> function can take in two methods.  <code>gatorOutput</code> displays the result of running the <code>gator</code> function,  while <code>gatorScore</code> shows the raw output produced by the <code>gatorScore</code>  function, which returns a probability score. The <code>midpoint</code> parameter,  with a default value of 0.5, can be adjusted to define what is  considered a <code>positive</code> result, when method is set to <code>gatorScore</code>.</p>"},{"location":"Functions/addPredictions/#gatorpy.addPredictions--function","title":"Function","text":""},{"location":"Functions/addPredictions/#gatorpy.addPredictions.addPredictions","title":"<code>addPredictions(gatorObject, method='gatorOutput', gatorOutput='gatorOutput', gatorScore='gatorScore', midpoint=0.5, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gatorObject</code> <code>anndata</code> <p>Single or combined Gator object.</p> required <code>method</code> <code>str</code> <p>There are two options: <code>gatorOutput</code> and <code>gatorScore</code>.  <code>gatorOutput</code> displays the result of running the <code>gator</code> function,  while <code>gatorScore</code> shows the raw output produced by the <code>gatorScore</code>  function, which returns a probability score. The <code>midpoint</code> parameter,  with a default value of 0.5, can be adjusted to define what is  considered a <code>positive</code> result, when method is set to <code>gatorScore</code>.</p> <code>'gatorOutput'</code> <code>gatorOutput</code> <code>str</code> <p>The name under which the <code>gatorOutput</code> is stored.</p> <code>'gatorOutput'</code> <code>gatorScore</code> <code>str</code> <p>The name under which the <code>gatorScore</code> is stored.</p> <code>'gatorScore'</code> <code>midpoint</code> <code>float</code> <p>The threshold for determining positive cells, in conjunction with 'gatorScore'.</p> <code>0.5</code> <code>projectDir</code> <code>string</code> <p>Provide the path to the output directory. If <code>None</code>, the <code>gatorObject</code> will  be returned to memory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>gatorObject</code> <code>anndata</code> <p>If output directory is provided the <code>gatorObject</code> will  be stored else it will be returned to memory. The results are stored in  <code>anndata.obs</code> with a <code>p_</code> appended to the markers names. So if you would  like to vizulaize <code>CD3</code>, the column that you are looking for is <code>p_CD3</code>.</p> Example <p>```python    </p> Source code in <code>gatorpy/addPredictions.py</code> <pre><code>def addPredictions (gatorObject, \n                    method='gatorOutput',\n                    gatorOutput='gatorOutput',\n                    gatorScore='gatorScore', \n                    midpoint=0.5,\n                    projectDir=None):\n\"\"\"\nParameters:\n\n    gatorObject (anndata):  \n        Single or combined Gator object.\n\n    method (str, optional):  \n        There are two options: `gatorOutput` and `gatorScore`. \n        `gatorOutput` displays the result of running the `gator` function, \n        while `gatorScore` shows the raw output produced by the `gatorScore` \n        function, which returns a probability score. The `midpoint` parameter, \n        with a default value of 0.5, can be adjusted to define what is \n        considered a `positive` result, when method is set to `gatorScore`.\n\n    gatorOutput (str, optional):  \n        The name under which the `gatorOutput` is stored.\n\n    gatorScore (str, optional):  \n        The name under which the `gatorScore` is stored.\n\n    midpoint (float, optional):  \n        The threshold for determining positive cells, in conjunction with 'gatorScore'.\n\n    projectDir (string, optional):  \n        Provide the path to the output directory. If `None`, the `gatorObject` will \n        be returned to memory.\n\nReturns:\n\n    gatorObject (anndata):  \n        If output directory is provided the `gatorObject` will \n        be stored else it will be returned to memory. The results are stored in \n        `anndata.obs` with a `p_` appended to the markers names. So if you would \n        like to vizulaize `CD3`, the column that you are looking for is `p_CD3`.\n\nExample:\n\n    \t```python    \n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n\n        # Module specific paths\n        gatorObject = cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\n\n        adata = ga.addPredictions (gatorObject, \n                        method='gatorOutput',\n                        gatorOutput='gatorOutput',\n                        gatorScore='gatorScore', \n                        midpoint=0.5,\n                        projectDir=None)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python addPredictions.py --gatorObject Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad    \t\n\n    \"\"\"\n\n    # Load the adata\n    if isinstance(gatorObject, str):\n        adata = ad.read(gatorObject)\n    else: \n        adata = gatorObject\n\n    # function to convert the prob scores to binary pos or neg\n    def assign_labels(df, midpoint):\n        df = df.applymap(lambda x: 'neg' if x &lt; midpoint else 'pos')\n        return df\n\n    # intialize the data    \n    if method == 'gatorOutput':\n        attach_df = adata.uns[gatorOutput]\n    elif method == 'gatorScore':\n        df = adata.uns[gatorScore]\n        attach_df = assign_labels (df, midpoint=midpoint)\n\n\n    obs = adata.obs.copy()\n    columns_to_drop = [col for col in obs.columns if col.startswith('p_')]\n    obs.drop(columns_to_drop, axis=1, inplace=True)\n\n    new_col_names = ['p_{}'.format(idx) for idx in attach_df.columns]\n    attach_df.columns = new_col_names\n    # add to obs\n    final_obs = pd.concat([obs, attach_df], axis=1)\n    adata.obs = final_obs\n\n\n    # Return to adata\n    # Save data if requested\n    if projectDir is not None:    \n        finalPath = pathlib.Path(projectDir)     \n        if not os.path.exists(finalPath):\n            os.makedirs(finalPath)\n        # determine file name\n        if isinstance (gatorObject, str):\n            imid = pathlib.Path(gatorObject).stem\n        else:\n            imid = 'addPredictions'    \n        adata.write(finalPath / f'{imid}.h5ad')\n    else:\n        # Return data\n        return adata\n</code></pre>"},{"location":"Functions/addPredictions/#gatorpy.addPredictions.addPredictions--set-the-working-directory-set-paths-to-the-example-data","title":"set the working directory &amp; set paths to the example data","text":"<p>cwd = '/Users/aj/Desktop/gatorExampleData'</p>"},{"location":"Functions/addPredictions/#gatorpy.addPredictions.addPredictions--module-specific-paths","title":"Module specific paths","text":"<p>gatorObject = cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'</p> <p>adata = ga.addPredictions (gatorObject,                  method='gatorOutput',                 gatorOutput='gatorOutput',                 gatorScore='gatorScore',                  midpoint=0.5,                 projectDir=None)</p>"},{"location":"Functions/addPredictions/#gatorpy.addPredictions.addPredictions--same-function-if-the-user-wants-to-run-it-via-command-line-interface","title":"Same function if the user wants to run it via Command Line Interface","text":"<p>python addPredictions.py --gatorObject Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad</p>"},{"location":"Functions/cloneFolder/","title":"cloneFolder","text":"<p>Short Description</p> <p>The purpose of the <code>cloneFolder</code> function is to copy user actions from one  folder to another. For example, if a user manually arranges thumbnails in  the <code>localNorm</code> folder, this function can replicate those changes to the  raw thumbnails.</p>"},{"location":"Functions/cloneFolder/#gatorpy.cloneFolder--function","title":"Function","text":""},{"location":"Functions/cloneFolder/#gatorpy.cloneFolder.cloneFolder","title":"<code>cloneFolder(copyFolder, applyFolder, TruePos='TruePos', TrueNeg='TrueNeg', PosToNeg='PosToNeg', NegToPos='NegToPos', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>copyFolder</code> <code>list</code> <p>List of folders from which the user wants to replicate the file structure.</p> required <code>applyFolder</code> <code>list</code> <p>List of folders where the replicated file structure should be applied, in the same order as the <code>copyFolder</code> list.</p> required <code>TruePos</code> <code>str</code> <p>Name of the folder that holds the Thumbnails classified as True Positive.</p> <code>'TruePos'</code> <code>TrueNeg</code> <code>str</code> <p>Name of the folder that holds the Thumbnails classified as True Negative.</p> <code>'TrueNeg'</code> <code>PosToNeg</code> <code>str</code> <p>Name of the folder that holds the Thumbnails that were moved from <code>True Positive</code> to <code>True Negative</code>.</p> <code>'PosToNeg'</code> <code>NegToPos</code> <code>str</code> <p>Name of the folder that holds the Thumbnails that were moved from <code>True Negative</code> to <code>True Positive</code>.</p> <code>'NegToPos'</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <p>Returns:</p> Type Description <p>The file structure of the source Folder is replicated in the destination Folder.</p> Example <pre><code># High level working directory\ncwd = '/Users/aj/Desktop/gatorExampleData'\n\n# list of folders to copy settings from\ncopyFolder = [cwd + '/GATOR/Thumbnails/localNorm/CD3D',\n              cwd + '/GATOR/Thumbnails/localNorm/ECAD']\n# list of folders to apply setting to\napplyFolder = [cwd + '/GATOR/Thumbnails/CD3D',\n              cwd + '/GATOR/Thumbnails/ECAD']\n# note: Every copyFolder should have a corresponding applyFolder. The order matters! \n\n# The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\nga.cloneFolder (copyFolder, \n                applyFolder, \n                TruePos='TruePos', TrueNeg='TrueNeg', \n                PosToNeg='PosToNeg', NegToPos='NegToPos',\n                verbose=True)\n\n\n# Same function if the user wants to run it via Command Line Interface\npython cloneFolder.py --copyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/ECAD --applyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD\n</code></pre> Source code in <code>gatorpy/cloneFolder.py</code> <pre><code>def cloneFolder (copyFolder, \n                 applyFolder,\n                 TruePos='TruePos', \n                 TrueNeg='TrueNeg',\n                 PosToNeg='PosToNeg', \n                 NegToPos='NegToPos',\n                 verbose=True):\n\"\"\"\nParameters:\n\n    copyFolder (list):\n        List of folders from which the user wants to replicate the file structure.\n\n    applyFolder (list):\n        List of folders where the replicated file structure should be applied,\n        in the same order as the `copyFolder` list.\n\n    TruePos (str, optional):\n        Name of the folder that holds the Thumbnails classified as True Positive.\n\n    TrueNeg (str, optional):\n        Name of the folder that holds the Thumbnails classified as True Negative.\n\n    PosToNeg (str, optional):\n        Name of the folder that holds the Thumbnails that were moved from `True Positive`\n        to `True Negative`.\n\n    NegToPos (str, optional):\n        Name of the folder that holds the Thumbnails that were moved from `True Negative`\n        to `True Positive`.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\nReturns:\n    The file structure of the source Folder is replicated in the destination Folder.\n\nExample:\n\n        ```python\n\n        # High level working directory\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n\n        # list of folders to copy settings from\n        copyFolder = [cwd + '/GATOR/Thumbnails/localNorm/CD3D',\n                      cwd + '/GATOR/Thumbnails/localNorm/ECAD']\n        # list of folders to apply setting to\n        applyFolder = [cwd + '/GATOR/Thumbnails/CD3D',\n                      cwd + '/GATOR/Thumbnails/ECAD']\n        # note: Every copyFolder should have a corresponding applyFolder. The order matters! \n\n        # The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\n        ga.cloneFolder (copyFolder, \n                        applyFolder, \n                        TruePos='TruePos', TrueNeg='TrueNeg', \n                        PosToNeg='PosToNeg', NegToPos='NegToPos',\n                        verbose=True)\n\n\n        # Same function if the user wants to run it via Command Line Interface\n        python cloneFolder.py --copyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/ECAD --applyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD\n\n        ```\n\n    \"\"\"\n\n    #TruePos='TruePos'; TrueNeg='TrueNeg'; PosToNeg='PosToNeg'; NegToPos='NegToPos'\n\n    # Convert the path to list\n    if isinstance (copyFolder, str):\n        copyFolder = [copyFolder]\n    if isinstance (applyFolder, str):\n        applyFolder = [applyFolder]\n\n    # Quick Check!\n    if len(copyFolder) is not len(applyFolder):\n        raise ValueError('The number of copyFolder and applyFolder should match, please check!' )\n\n    # function to delete images\n    def deleteFile(files, location):\n        for f in files:\n            # full path\n            #full_path = location  + f\n            full_path = pathlib.Path.joinpath(location, f)\n            if os.path.exists(full_path):\n                os.remove(full_path)\n\n    # Function to move images\n    def moveFile(files, from_loc, to_loc):\n        for f in files:\n            # full path\n            full_path_from = pathlib.Path.joinpath(from_loc, f) # from_loc + f\n            full_path_to = pathlib.Path.joinpath(to_loc, f) # to_loc + f\n            # move file\n            if os.path.exists(full_path_from):\n                shutil.move(full_path_from, full_path_to)\n\n    # path lib of all folder\n    all_folders = [pathlib.Path(p) for p in copyFolder]\n\n    # copy from location\n    pos_aug_location = [pathlib.Path(p + '/' + str(TruePos)) for p in copyFolder]\n    neg_aug_location = [pathlib.Path(p + '/' + str(TrueNeg)) for p in copyFolder]\n    pos2neg_aug_location = [pathlib.Path(p + '/' + str(PosToNeg)) for p in copyFolder]\n    neg2pos_aug_location = [pathlib.Path(p + '/' + str(NegToPos)) for p in copyFolder]\n\n    # copy to location\n    pos_real_location = [pathlib.Path(p + '/' + str(TruePos)) for p in applyFolder]\n    neg_real_location = [pathlib.Path(p + '/' + str(TrueNeg)) for p in applyFolder]\n    pos2neg_real_location = [pathlib.Path(p + '/' + str(PosToNeg)) for p in applyFolder]\n    neg2pos_real_location = [pathlib.Path(p + '/' + str(NegToPos)) for p in applyFolder]\n\n\n\n    # function\n    def processFolder (folderIndex):\n        if verbose is True:\n            print ('Processing: ' + str(all_folders[folderIndex].stem))\n\n        # create a list of all file names in the applyFolder\n        pos_files = next(walk(pos_real_location[folderIndex]), (None, None, []))[2]\n        neg_files = next(walk(neg_real_location[folderIndex]), (None, None, []))[2]\n\n        # Find file names within each of the copyFolder\n        pos = next(walk(pos_aug_location[folderIndex]), (None, None, []))[2]\n        neg = next(walk(neg_aug_location[folderIndex]), (None, None, []))[2]\n        pos2neg = next(walk(pos2neg_aug_location[folderIndex]), (None, None, []))[2]\n        neg2pos = next(walk(neg2pos_aug_location[folderIndex]), (None, None, []))[2]  # [] if no file\n\n        # Find images to delete\n        pos_del = list(set(pos_files).difference(pos + pos2neg))\n        neg_del = list(set(neg_files).difference(neg + neg2pos))\n\n        # delete files\n        deleteFile(files=pos_del, location=pos_real_location[folderIndex])\n        deleteFile(files=neg_del, location=neg_real_location[folderIndex])\n\n        # move files\n        moveFile (files=pos2neg, from_loc=pos_real_location[folderIndex], to_loc=pos2neg_real_location[folderIndex])\n        moveFile (files=neg2pos, from_loc=neg_real_location[folderIndex], to_loc=neg2pos_real_location[folderIndex])\n\n        # print the number of files\n        posaug = len(next(walk(pos_aug_location[folderIndex]), (None, None, []))[2])\n        posreal = len(next(walk(pos_real_location[folderIndex]), (None, None, []))[2])\n        negaug = len(next(walk(neg_aug_location[folderIndex]), (None, None, []))[2])\n        negreal = len(next(walk(neg_real_location[folderIndex]), (None, None, []))[2])\n        postonegaug = len(next(walk(pos2neg_aug_location[folderIndex]), (None, None, []))[2])\n        postonegreal = len(next(walk(pos2neg_real_location[folderIndex]), (None, None, []))[2])\n        negtoposaug = len(next(walk(neg2pos_aug_location[folderIndex]), (None, None, []))[2])\n        negtoposreal = len(next(walk(neg2pos_real_location[folderIndex]), (None, None, []))[2])\n\n        #print ('No of Files in TruePos-&gt; copyFolder: ' + str(posaug) + ' ; applyFolder: '+ str(posreal))\n        #print ('No of Files in TrueNeg-&gt; copyFolder: ' + str(negaug) + ' ; applyFolder: '+ str(negreal))\n        #print ('No of Files in PosToNeg-&gt; copyFolder: ' + str(postonegaug) + ' ; applyFolder: '+ str(postonegreal))\n        #print ('No of Files in NegToPos-&gt; copyFolder: ' + str(negtoposaug) + ' ; applyFolder: '+ str(negtoposreal))\n\n    # apply function to all folders\n    r_processFolder = lambda x: processFolder (folderIndex=x)\n    process_folders = list(map(r_processFolder, list(range(len(copyFolder)))))\n\n    # Finish Job\n    if verbose is True:\n        print('Cloning Folder is complete, head over to /GATOR/Thumbnails\" to view results')\n</code></pre>"},{"location":"Functions/gator/","title":"gator","text":"<p>Short Description</p> <p>The gator function identifies positive and negative cells for a marker. To  get optimal results, consider adjusting the following parameters:  </p> <ol> <li>The <code>gatorObject</code> parameter can accept either the loaded gatorObject or a path to the <code>.h5ad</code> file.  </li> <li>The <code>minAbundance</code> parameter determines the minimum percentage of a marker's abundance to consider it a failure.  </li> <li>It is suggested to drop background markers with the <code>dropMarkers</code> option as they can interfere with classifiers.  </li> <li><code>RobustScale</code>: Scaling the data before training the classifier model has been shown to improve results.  However, in our experience a simple log transformation was found to be sufficient.   </li> </ol>"},{"location":"Functions/gator/#gatorpy.gator--function","title":"Function","text":""},{"location":"Functions/gator/#gatorpy.gator.gator","title":"<code>gator(gatorObject, gatorScore='gatorScore', minAbundance=0.005, percentiles=[1, 20, 80, 99], dropMarkers=None, RobustScale=False, log=True, stringentThreshold=False, x_coordinate='X_centroid', y_coordinate='Y_centroid', imageid='imageid', random_state=0, rescaleMethod='minmax', label='gatorOutput', verbose=True, projectDir=None, **kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gatorObject</code> <code>anndata</code> <p>Pass the <code>gatorObject</code> loaded into memory or a path to the <code>gatorObject</code>  file (.h5ad).</p> required <code>gatorScore</code> <code>str</code> <p>Include the label used for saving the <code>gatorScore</code> within the Gator object.</p> <code>'gatorScore'</code> <code>minAbundance</code> <code>float</code> <p>Specify the minimum percentage of cells that should express a specific marker in order to determine if the marker is considered a failure. A good approach is to consider the lowest percentage of rare cells expected within the dataset.</p> <code>0.005</code> <code>percentiles</code> <code>list</code> <p>Specify the interval of percentile levels of the expression utilized to intialize the GMM. The cells falling within these percentiles are utilized to distinguish between negative cells (first two values) and positive cells (last two values).</p> <code>[1, 20, 80, 99]</code> <code>dropMarkers</code> <code>list</code> <p>Specify a list of markers to be removed from the analysis, for example: <code>[\"background_channel1\", \"background_channel2\"]</code>. </p> <code>None</code> <code>RobustScale</code> <code>bool</code> <p>When set to True, the data will be subject to Robust Scaling before the Gradient Boosting Classifier is trained. </p> <code>False</code> <code>log</code> <code>bool</code> <p>Apply <code>log1p</code> transformation on the data, unless it has already been log transformed in which case set it to <code>False</code>. </p> <code>True</code> <code>stringentThreshold</code> <code>bool</code> <p>The Gaussian Mixture Model (GMM) is utilized to distinguish positive and  negative cells by utilizing gatorScores. The stringentThreshold can be utilized  to further refine the classification of positive and negative cells.  By setting it to True, cells with gatorScore below the mean of the negative  distribution and above the mean of the positive distribution will be  labeled as true negative and positive, respectively.</p> <code>False</code> <code>x_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the X coordinates for each cell. </p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the Y coordinates for each cell.</p> <code>'Y_centroid'</code> <code>imageid</code> <code>str</code> <p>The name of the column that holds the unique image ID. </p> <code>'imageid'</code> <code>random_state</code> <code>int</code> <p>Seed used by the random number generator. </p> <code>0</code> <code>rescaleMethod</code> <code>string</code> <p>Choose between <code>sigmoid</code> and <code>minmax</code>.</p> <code>'minmax'</code> <code>label</code> <code>str</code> <p>Assign a label for the object within <code>adata.uns</code> where the predictions from Gator will be stored. </p> <code>'gatorOutput'</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>projectDir</code> <code>str</code> <p>Provide the path to the output directory. The result will be located at <code>projectDir/GATOR/gatorOutput/</code>. </p> <code>None</code> <code>**kwargs</code> <code>keyword parameters</code> <p>Additional arguments to pass to the <code>HistGradientBoostingClassifier()</code> function.</p> <code>{}</code> <p>Returns:</p> Name Type Description <code>gatorObject</code> <code>anndata</code> <p>If projectDir is provided the updated Gator Object will saved within the provided projectDir.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\ngatorObject = cwd + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n\n# Run the function\nadata = ga.gator ( gatorObject=gatorObject,\n            gatorScore='gatorScore',\n            minAbundance=0.002,\n            percentiles=[1, 20, 80, 99],\n            dropMarkers = None,\n            RobustScale=False,\n            log=True,\n            x_coordinate='X_centroid',\n            y_coordinate='Y_centroid',\n            imageid='imageid',\n            random_state=0,\n            rescaleMethod='sigmoid',\n            label='gatorOutput',\n            verbose=True,\n            projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython gator.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/gator.py</code> <pre><code>def gator (gatorObject,\n           gatorScore='gatorScore',\n           minAbundance=0.005,\n           percentiles=[1, 20, 80, 99],\n           dropMarkers = None,\n           RobustScale=False,\n           log=True,\n           stringentThreshold=False,\n           x_coordinate='X_centroid',\n           y_coordinate='Y_centroid',\n           imageid='imageid',\n           random_state=0,\n           rescaleMethod='minmax',\n           label='gatorOutput',\n           verbose=True,\n           projectDir=None, **kwargs):\n\"\"\"\nParameters:\n    gatorObject (anndata):\n        Pass the `gatorObject` loaded into memory or a path to the `gatorObject` \n        file (.h5ad).\n\n    gatorScore (str, optional):\n        Include the label used for saving the `gatorScore` within the Gator object.\n\n    minAbundance (float, optional):\n        Specify the minimum percentage of cells that should express a specific\n        marker in order to determine if the marker is considered a failure.\n        A good approach is to consider the lowest percentage of rare cells\n        expected within the dataset.\n\n    percentiles (list, optional):\n        Specify the interval of percentile levels of the expression utilized to intialize\n        the GMM. The cells falling within these percentiles are utilized to distinguish\n        between negative cells (first two values) and positive cells (last two values).\n\n    dropMarkers (list, optional):\n        Specify a list of markers to be removed from the analysis, for\n        example: `[\"background_channel1\", \"background_channel2\"]`. \n\n    RobustScale (bool, optional):\n        When set to True, the data will be subject to Robust Scaling before the\n        Gradient Boosting Classifier is trained. \n\n    log (bool, optional):\n        Apply `log1p` transformation on the data, unless it has already been log\n        transformed in which case set it to `False`. \n\n    stringentThreshold (bool, optional):\n        The Gaussian Mixture Model (GMM) is utilized to distinguish positive and \n        negative cells by utilizing gatorScores. The stringentThreshold can be utilized \n        to further refine the classification of positive and negative cells. \n        By setting it to True, cells with gatorScore below the mean of the negative \n        distribution and above the mean of the positive distribution will be \n        labeled as true negative and positive, respectively.\n\n    x_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        X coordinates for each cell. \n\n    y_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        Y coordinates for each cell.\n\n    imageid (str, optional):\n        The name of the column that holds the unique image ID. \n\n    random_state (int, optional):\n        Seed used by the random number generator. \n\n    rescaleMethod (string, optional):\n        Choose between `sigmoid` and `minmax`.\n\n    label (str, optional):\n        Assign a label for the object within `adata.uns` where the predictions\n        from Gator will be stored. \n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    projectDir (str, optional):\n        Provide the path to the output directory. The result will be located at\n        `projectDir/GATOR/gatorOutput/`. \n\n    **kwargs (keyword parameters):\n        Additional arguments to pass to the `HistGradientBoostingClassifier()` function.\n\nReturns:\n    gatorObject (anndata):\n        If projectDir is provided the updated Gator Object will saved within the\n        provided projectDir.\n\nExample:\n\n        ```python\n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n        gatorObject = cwd + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n\n        # Run the function\n        adata = ga.gator ( gatorObject=gatorObject,\n                    gatorScore='gatorScore',\n                    minAbundance=0.002,\n                    percentiles=[1, 20, 80, 99],\n                    dropMarkers = None,\n                    RobustScale=False,\n                    log=True,\n                    x_coordinate='X_centroid',\n                    y_coordinate='Y_centroid',\n                    imageid='imageid',\n                    random_state=0,\n                    rescaleMethod='sigmoid',\n                    label='gatorOutput',\n                    verbose=True,\n                    projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gator.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n\n\n        ```\n\n    \"\"\"\n\n    #gatorObject = \"/Users/aj/Dropbox (Partners HealthCare)/Data/gator/data/ajn_training_data/GATOR/gatorObject/1_6_GatorOutput.h5ad\"\n    #gatorScore='gatorScore'; minAbundance=0.002; percentiles=[1, 20, 80, 99]; dropMarkers = None;leakData=False;rescaleMethod='sigmoid';verbose = False\n    #scaleData=False; log=True; x_coordinate='X_centroid'; y_coordinate='Y_centroid'; imageid='imageid'; random_state=0; label='gatorOutput'\n    #gatorObject = '/Users/aj/Dropbox (Partners HealthCare)/Data/gator/data/ajn_training_data/GATOR/gatorPredict/2_28_GatorOutput.h5ad'\n    #gatorObject = '/Users/aj/Dropbox (Partners HealthCare)/Data/gator/data/ajn_training_data/GATOR/gatorPredict/4_113_GatorOutput.h5ad'\n\n\n    # Load the andata object\n    if isinstance(gatorObject, str):\n        adata = ad.read(gatorObject)\n        gatorObject = [gatorObject]\n        gatorObjectPath = [pathlib.Path(p) for p in gatorObject]\n    else:\n        adata = gatorObject.copy()\n\n    # break the function if gatorScore is not detectable\n    def check_key_exists(dictionary, key):\n        try:\n            # Check if the key exists in the dictionary\n            value = dictionary[key]\n        except KeyError:\n            # Return an error if the key does not exist\n            return \"Error: \" + str(gatorScore) + \" does not exist, please check!\"\n    # Test\n    check_key_exists(dictionary=adata.uns, key=gatorScore)\n\n\n    ###########################################################################\n    # SOME GENERIC FUNCTIONS\n    ###########################################################################\n\n    # used in (step 1)\n    def get_columns_with_low_values(df, minAbundance):\n        columns_to_keep = []\n        for column in df.columns:\n            num_rows_with_high_values = len(df[df[column] &gt; 0.6])\n            if num_rows_with_high_values / len(df) &lt; minAbundance:\n                columns_to_keep.append(column)\n        return columns_to_keep\n\n    # count the number of pos and neg elements in a list\n    def count_pos_neg(lst):\n        arr = np.array(lst)\n        result = {'pos': np.sum(arr == 'pos'), 'neg': np.sum(arr == 'neg')}\n        result['pos'] = result['pos'] if result['pos'] &gt; 0 else 0\n        result['neg'] = result['neg'] if result['neg'] &gt; 0 else 0\n        return result\n\n    # alternative to find if markers failed\n    def simpleGMM_failedMarkers (df, n_components, minAbundance, random_state):\n        # prepare data\n        columns_to_keep = []\n        for column in df.columns:\n            #print(str(column))\n            colValue = df[[column]].values  \n            colValue[0] = 0; colValue[1] = 1;   # force the model to converge from 0-1\n            gmm = GaussianMixture(n_components=n_components,  random_state=random_state)\n            gmm.fit(colValue)\n            predictions = gmm.predict(colValue)\n            # Get the mean of each Gaussian component\n            means = gmm.means_.flatten()\n            # Sort the mean values in ascending order\n            sorted_means = np.sort(means)\n            # Assign 'pos' to rows with higher mean distribution and 'neg' to rows with lower mean distribution\n            labels = np.where(predictions == np.argmax(means), 'pos', 'neg')\n            # count pos and neg\n            counts = count_pos_neg(labels)\n            # find if the postive cells is less than the user defined min abundance\n            if counts['pos'] / len(df)  &lt; minAbundance:\n                columns_to_keep.append(column)\n        return columns_to_keep\n\n\n    # preprocess data (step-4)\n    def pre_process (data, log=log):\n        # clip outliers\n        def clipping (x):\n            clip = x.clip(lower =np.percentile(x,0.01), upper=np.percentile(x,99.99)).tolist()\n            return clip\n        processsed_data = data.apply(clipping)\n        if log is True:\n            processsed_data = np.log1p(processsed_data)\n        return processsed_data\n    # preprocess data (step-5)\n    def apply_transformation (data):\n        # rescale the data\n        transformer = RobustScaler().fit(data)\n        processsed_data = pd.DataFrame(transformer.transform(data), columns = data.columns, index=data.index)\n        return processsed_data\n\n    # GMM\n    def simpleGMM (data, n_components, means_init, random_state):\n        gmm = GaussianMixture(n_components=n_components, means_init=means_init,  random_state=random_state)\n        gmm.fit(data)\n        # Predict the class labels for each sample\n        predictions = gmm.predict(data)\n        # Get the mean of each Gaussian component\n        means = gmm.means_.flatten()\n        # Sort the mean values in ascending order\n        sorted_means = np.sort(means)\n        # Assign 'pos' to rows with higher mean distribution and 'neg' to rows with lower mean distribution\n        labels = np.where(predictions == np.argmax(means), 'pos', 'neg')\n\n        return labels, sorted_means \n\n    # take in two list (ccategorical and numerical) and return mean values\n    def array_mean (labels, values):\n        # Create a defaultdict with an empty list as the default value\n        result = defaultdict(list)\n        # Iterate over the labels and values arrays\n        for label, value in zip(labels, values):\n            # Add the value to the list for the corresponding label\n            result[label].append(value)\n        # Calculate the mean for each label and store it in the dictionary\n        for label, value_list in result.items():\n            result[label] = np.mean(value_list)\n        return result\n\n    # match two arrays and return seperate lists\n    def array_match (labels, names):\n        # Create a defaultdict with an empty list as the default value\n        result = defaultdict(list)\n        # Iterate over the labels and names arrays\n        for label, name in zip(labels, names):\n            # Add the name to the list for the corresponding label\n            result[label].append(name)\n        return result\n\n    # return the mean between two percentiles\n    def meanPercentile (values, lowPercentile, highPercentile):\n        # Calculate the 1st percentile value\n        p1 = np.percentile(values, lowPercentile)\n        # Calculate the 20th percentile value\n        p20 = np.percentile(values, highPercentile)\n        # Select the values between the 1st and 20th percentile using numpy.where()\n        filtered_values = np.where((values &gt;= p1) &amp; (values &lt;= p20))\n        # Calculate the mean of the filtered values\n        meanVal = np.mean(values[filtered_values])\n        return meanVal\n\n    # return the mean between two percentiles\n    def indexPercentile (processed_data, marker, lowPercentile, highPercentile):\n        values = processed_data[marker].values\n        # Calculate the 1st percentile value\n        p1 = np.percentile(values, lowPercentile)\n        # Calculate the 20th percentile value\n        p20 = np.percentile(values, highPercentile)\n        # Select the values between the 1st and 20th percentile using numpy.where()\n        filtered_values = np.where((values &gt;= p1) &amp; (values &lt;= p20))\n        # Calculate the mean of the filtered values\n        idx = processed_data[marker].iloc[filtered_values].index\n        return idx\n\n    # Used for rescaling data\n    # used to find the mid point of GMM mixtures\n    def find_midpoint(data, labels):\n      # Convert data and labels to NumPy arrays\n      data = np.array(data)\n      labels = np.array(labels)\n      # Get the indices that would sort the data and labels arrays\n      sort_indices = np.argsort(data)\n      # Sort the data and labels arrays using the sort indices\n      sorted_data = data[sort_indices]\n      sorted_labels = labels[sort_indices]\n      # Find the index where the 'neg' and 'pos' labels meet\n      midpoint_index = np.argmax(sorted_labels == 'pos')\n      # Return the value at the midpoint index\n      return sorted_data[midpoint_index]\n\n    # Used for reassigning some of the wrong 'nes' and 'pos' within data given a midpoint\n    def modify_negatives_vectorized(data, labels, midpoint):\n      # Convert data and labels to NumPy arrays\n      data = np.array(data)\n      labels = np.array(labels)\n      # Get the indices that would sort the data and labels arrays\n      sort_indices = np.argsort(data)\n      # Sort the data and labels arrays using the sort indices\n      sorted_data = data[sort_indices]\n      sorted_labels = labels[sort_indices]\n      # Find the index where the sorted data is greater than or equal to the midpoint value\n      midpoint_index = np.argmax(sorted_data &gt;= midpoint)\n      # Find all the elements in the sorted labels array with a value of 'neg' after the midpoint index\n      neg_mask = np.logical_and(sorted_labels == 'neg', np.arange(len(sorted_data)) &gt;= midpoint_index)\n      # Modify the value of the elements to be equal to the midpoint value\n      sorted_data[neg_mask] = midpoint\n      # Find all the elements in the sorted labels array with a value of 'pos' before the midpoint index\n      pos_mask = np.logical_and(sorted_labels == 'pos', np.arange(len(sorted_data)) &lt; midpoint_index)\n      # Modify the value of the elements to be equal to the midpoint value plus 0.1\n      sorted_data[pos_mask] = midpoint + 0.1\n      # Reorder the data array to the original order\n      reordered_data = sorted_data[np.argsort(sort_indices)]\n      # Return the modified data\n      return reordered_data\n\n# =============================================================================\n#     def modify_prediction_results(rawData, prediction_results, failedMarkersinData):\n#         # Identify the index of the maximum value for each column in rawData\n#         max_index = rawData.idxmax()\n#         # Iterate through the specified columns of rawData\n#         for col in failedMarkersinData:\n#             # Get the index of the maximum value\n#             max_row = max_index[col]\n#             # Modify the corresponding index in prediction_results\n#             prediction_results[col].at[max_row] = 'pos'\n# =============================================================================\n\n    def get_second_highest_values(df, failedMarkersinData):\n        # get the second largest value for each column in the list\n        second_highest_values = df[failedMarkersinData].max()\n        # convert the series to a dictionary\n        second_highest_values_dict = second_highest_values.to_dict()\n        return second_highest_values_dict\n\n\n    # sigmoid scaling to convert the data between 0-1 based on the midpoint\n    def sigmoid(x, midpoint):\n        return 1 / (1 + np.exp(-(x - midpoint)))\n\n    # rescale based on min-max neg -&gt; 0-4.9 and pos -&gt; 0.5-1\n    def scale_data(data, midpoint):\n        below_midpoint = data[data &lt;= midpoint]\n        above_midpoint = data[data &gt; midpoint]\n        indices_below = np.where(data &lt;= midpoint)[0]\n        indices_above = np.where(data &gt; midpoint)[0]\n\n        # Scale the group below the midpoint\n        min_below = below_midpoint.min()\n        max_below = below_midpoint.max()\n        range_below = max_below - min_below\n        below_midpoint = (below_midpoint - min_below) / range_below\n\n        # Scale the group above the midpoint\n        if len(above_midpoint) &gt; 0:\n            min_above = above_midpoint.min()\n            max_above = above_midpoint.max()\n            range_above = max_above - min_above\n            above_midpoint = (above_midpoint - min_above) / range_above\n        else:\n            above_midpoint = []\n\n        # Re-assemble the data in the original order by using the indices of the values in each group\n        result = np.empty(len(data))\n        result[indices_below] = below_midpoint * 0.499999999\n        if len(above_midpoint) &gt; 0:\n            result[indices_above] = above_midpoint * 0.50 + 0.50\n        return result\n\n    # classifies data based on a given midpoint\n    def classify_data(data, sorted_means):\n        data = np.array(data)\n        low = sorted_means[0]\n        high = sorted_means[1]\n        return np.where(data &lt; low, 'neg', np.where(data &gt; high, 'pos', 'unknown'))\n\n\n\n    ###########################################################################\n    # step-1 : Identify markers that have failed in this dataset\n    ###########################################################################\n    # 0ld thresholding method\n    #failed_markers = get_columns_with_low_values (df=adata.uns[gatorScore],minAbundance=minAbundance)\n\n    # New GMM method\n    failed_markers = simpleGMM_failedMarkers (df=adata.uns[gatorScore], \n                                              n_components=2, \n                                              minAbundance=minAbundance, \n                                              random_state=random_state)\n\n    # to store in adata\n    failed_markers_dict = {adata.obs[imageid].unique()[0] : failed_markers}\n\n    if verbose is True:\n        print('Failed Markers are: ' + \", \".join(str(x) for x in failed_markers))\n\n    ###########################################################################\n    # step-2 : Prepare DATA\n    ###########################################################################\n\n    rawData = pd.DataFrame(adata.raw.X, columns= adata.var.index, index = adata.obs.index)\n    rawprocessed = pre_process (rawData, log=log)\n    # drop user defined markers; note if a marker is dropped it will not be part of the\n    # final prediction too. Markers that failed although removed from prediction will\n    # still be included in the final predicted output as all negative.\n    if dropMarkers is not None:\n        if isinstance(dropMarkers, str):\n            dropMarkers = [dropMarkers]\n        pre_processed_data = rawprocessed.drop(columns=dropMarkers)\n    else:\n        pre_processed_data = rawprocessed.copy()\n\n    # also drop failed markers\n    failedMarkersinData = list(set(pre_processed_data.columns).intersection(failed_markers))\n\n    # final dataset that will be used for prediction\n    pre_processed_data = pre_processed_data.drop(columns=failedMarkersinData)\n\n    # isolate the unet probabilities\n    probQuant_data = adata.uns[gatorScore]\n\n    # list of markers to process: (combined should match data)\n    expression_unet_common = list(set(pre_processed_data.columns).intersection(set(probQuant_data.columns)))\n    only_expression = list(set(pre_processed_data.columns).difference(set(probQuant_data.columns)))\n\n\n    ###########################################################################\n    # step-4 : Identify a subset of true positive and negative cells\n    ###########################################################################\n\n    # marker = 'CD4'\n    def bonafide_cells (marker,\n                        expression_unet_common, only_expression,\n                        pre_processed_data, probQuant_data, random_state,\n                        percentiles):\n\n\n        if marker in expression_unet_common:\n            if verbose is True:\n                print(\"NN marker: \" + str(marker))\n            # run GMM on probQuant_data\n            X = probQuant_data[marker].values.reshape(-1,1)\n            # Fit the GMM model to the data\n            labels, sorted_means = simpleGMM (data=X, n_components=2, means_init=None, random_state=random_state)\n\n            # Identify cells that are above a certain threshold in the probability maps\n            if stringentThreshold is True:\n                labels = classify_data (data=probQuant_data[marker], sorted_means=sorted_means)\n\n            # find the mean of the pos and neg cells in expression data given the labels\n            values = pre_processed_data [marker].values\n            Pmeans = array_mean (labels, values)\n            # Format mean to pass into next GMM\n            Pmean = np.array([[ Pmeans.get('neg')], [Pmeans.get('pos')]])\n\n            # Now run GMM on the expression data\n            Y = pre_processed_data[marker].values.reshape(-1,1)\n            labelsE, sorted_meansE = simpleGMM (data=Y, n_components=2, means_init=Pmean, random_state=random_state)\n\n            # Match the labels and index names to identify which cells are pos and neg\n            expCells = array_match (labels=labels, names=pre_processed_data.index)\n            probCells = array_match (labels=labelsE, names=pre_processed_data.index)\n            # split it\n            expCellsPos = expCells.get('pos', []) ; expCellsNeg = expCells.get('neg', [])\n            probCellsPos = probCells.get('pos', []) ; probCellsNeg = probCells.get('neg', [])\n            # find common elements\n            pos = list(set(expCellsPos).intersection(set(probCellsPos)))\n            neg = list(set(expCellsNeg).intersection(set(probCellsNeg)))\n\n            # print no of cells\n            if verbose is True:\n                print(\"POS cells: {} and NEG cells: {}.\".format(len(pos), len(neg)))\n\n            # check if the length is less than 20 cells and if so add the marker to only_expression\n            if len(pos) &lt; 20 or len(neg) &lt; 20: ## CHECK!\n                only_expression.append(marker)\n                if verbose is True:\n                    print (\"As the number of POS/NEG cells is low for \" + str(marker) + \", GMM will fitted using only expression values.\")\n\n\n        if marker in only_expression:\n            if verbose is True:\n                print(\"Expression marker: \" + str(marker))\n            # Run GMM only on the expression data\n            Z = pre_processed_data[marker].values.reshape(-1,1)\n            # if user provides manual percentile, use it to intialize the GMM\n            if percentiles is not None:\n                percentiles.sort()\n                F = pre_processed_data[marker].values\n                # mean of cells within defined threshold\n                lowerPercent = meanPercentile (values=F, lowPercentile=percentiles[0], highPercentile=percentiles[1])\n                higherPercent = meanPercentile (values=F, lowPercentile=percentiles[2], highPercentile=percentiles[3])\n                # Format mean to pass into next GMM\n                Pmean = np.array([[lowerPercent], [higherPercent]])\n                labelsOE, sorted_meansOE = simpleGMM (data=Z, n_components=2, means_init=Pmean, random_state=random_state)\n            else:\n                labelsOE, sorted_meansOE = simpleGMM (data=Z, n_components=2, means_init=None, random_state=random_state)\n            # match labels with indexname\n            OEcells = array_match (labels=labelsOE, names=pre_processed_data.index)\n            # split it\n            pos = OEcells.get('pos', []) ; neg = OEcells.get('neg', [])\n\n            # randomly subset 70% of the data to return\n            random.seed(random_state); pos = random.sample(pos, k=int(len(pos) * 0.7))\n            random.seed(random_state); neg = random.sample(neg, k=int(len(neg) * 0.7))\n\n            # print no of cells\n            if verbose is True:\n                print(\"Defined POS cells is {} and NEG cells is {}.\".format(len(pos), len(neg)))\n\n            # What happens of POS/NEG is less than 20\n            # check if the length is less than 20 cells and if so add the marker to only_expression\n            if len(pos) &lt; 20 or len(neg) &lt; 20:  ## CHECK!\n                if percentiles is None:\n                    percentiles = [1,20,80,99]\n                neg = list(indexPercentile (pre_processed_data, marker, lowPercentile=percentiles[0], highPercentile=percentiles[1]))\n                pos = list(indexPercentile (pre_processed_data, marker, lowPercentile=percentiles[2], highPercentile=percentiles[3]))\n                if verbose is True:\n                    print (\"As the number of POS/NEG cells is low for \" + str(marker) + \", cells falling within the given percentile \" + str(percentiles) + ' was used.')\n\n        # return the output\n        return marker, pos, neg\n\n    # Run the function on all markers\n    if verbose is True:\n        print(\"Intial GMM Fitting\")\n    r_bonafide_cells = lambda x: bonafide_cells (marker=x,\n                                                expression_unet_common=expression_unet_common,\n                                                only_expression=only_expression,\n                                                pre_processed_data=pre_processed_data,\n                                                probQuant_data=probQuant_data,\n                                                random_state=random_state,\n                                                percentiles=percentiles)\n    bonafide_cells_result = list(map(r_bonafide_cells,  pre_processed_data.columns)) # Apply function\n\n\n\n    ###########################################################################\n    # step-5 : Generate training data for the Gradient Boost Classifier\n    ###########################################################################\n\n    # bonafide_cells_result = bonafide_cells_result[2]\n    def trainingData (bonafide_cells_result, pre_processed_data, RobustScale):\n        # uravel the data\n        marker = bonafide_cells_result[0]\n        pos = bonafide_cells_result[1]\n        neg = bonafide_cells_result[2]\n        PD = pre_processed_data.copy()\n\n        if verbose is True:\n            print('Processing: ' + str(marker))\n\n        # class balance the number of pos and neg cells based on the lowest denominator\n        if len(neg) &lt; len(pos):\n            pos = random.sample(pos, len(neg))\n        else:\n            neg = random.sample(neg, len(pos))\n\n        # processed data with pos and neg info\n\n\n        #PD['label'] = ['pos' if index in pos else 'neg' if index in neg else 'other' for index in PD.index]\n        PD['label'] = np.where(PD.index.isin(pos), 'pos', np.where(PD.index.isin(neg), 'neg', 'other'))\n        combined_data = PD.copy()\n\n        # scale data if requested\n        if RobustScale is True:\n            combined_data_labels = combined_data[['label']]\n            combined_data = combined_data.drop('label', axis=1)\n            combined_data = apply_transformation(combined_data)\n            combined_data = pd.concat ([combined_data, combined_data_labels], axis=1)\n\n        # return final output\n        return marker, combined_data\n\n    # Run the function\n    if verbose is True:\n        print(\"Building the Training Data\")\n    r_trainingData = lambda x: trainingData (bonafide_cells_result=x,\n                                                 pre_processed_data=pre_processed_data,\n                                                 RobustScale=RobustScale)\n    trainingData_result = list(map(r_trainingData, bonafide_cells_result)) # Apply function\n\n\n    ###########################################################################\n    # step-6 : Train and Predict on all cells\n    ###########################################################################\n\n    # trainingData_result = trainingData_result[2]\n    def gatorClassifier (trainingData_result,random_state):\n\n        #unravel data\n        marker = trainingData_result[0]\n        combined_data = trainingData_result[1]\n\n        # prepare the data for predicition\n        index_names_to_drop = [index for index in combined_data.index if 'npu' in index or 'nnu' in index]\n        predictionData = combined_data.drop(index=index_names_to_drop, inplace=False)\n        predictionData = predictionData.drop('label', axis=1)\n\n        if verbose is True:\n            print('classifying: ' + str(marker))\n\n        # shuffle the data\n        combined_data = combined_data.sample(frac=1) # shuffle it\n\n        # prepare the training data and training labels\n        to_train = combined_data.loc[combined_data['label'].isin(['pos', 'neg'])]\n        training_data = to_train.drop('label', axis=1)\n        training_labels = to_train[['label']]\n        trainD = training_data.values\n        trainL = training_labels.values\n        trainL = [item for sublist in trainL for item in sublist]\n\n\n        #start = time.time()\n\n        # Function for the classifier\n        #mlp = MLPClassifier(**kwargs) # CHECK\n        #model = GradientBoostingClassifier()\n\n        model = HistGradientBoostingClassifier(random_state=random_state, **kwargs)\n        model.fit(trainD, trainL)\n        # predict\n        pred = model.predict(predictionData.values)\n        prob = model.predict_proba(predictionData.values)\n        prob = [item[0] for item in prob]\n\n        #end = time.time()\n        #print(end - start)\n\n        # find the mid point based on the predictions (used for rescaling data later)\n        midpoint = find_midpoint(data=predictionData[marker].values, labels=pred)\n\n        # return\n        return marker, pred, prob, midpoint\n\n    # Run the function\n    if verbose is True:\n        print(\"Fitting model for classification:\")\n    r_gatorClassifier = lambda x: gatorClassifier (trainingData_result=x,random_state=random_state)\n    gatorClassifier_result = list(map(r_gatorClassifier, trainingData_result))\n\n    ###########################################################################\n    # step-7 : Consolidate the results into a dataframe\n    ###########################################################################\n\n    # consolidate results\n    markerOrder = []\n    for i in range(len(gatorClassifier_result)):\n        markerOrder.append(gatorClassifier_result[i][0])\n\n    prediction_results = []\n    for i in range(len(gatorClassifier_result)):\n        prediction_results.append(gatorClassifier_result[i][1])\n    prediction_results = pd.DataFrame(prediction_results, index=markerOrder, columns=pre_processed_data.index).T\n\n    probability_results = []\n    for i in range(len(gatorClassifier_result)):\n        probability_results.append(gatorClassifier_result[i][2])\n    probability_results = pd.DataFrame(probability_results, index=markerOrder, columns=pre_processed_data.index).T\n\n    midpoints_dict = {}\n    for i in range(len(gatorClassifier_result)):\n        midpoints_dict[markerOrder[i]] = gatorClassifier_result[i][3]\n\n    ###########################################################################\n    # step-8 : Final cleaning of predicted results with UNET results\n    ###########################################################################\n\n    # bonafide_cells_result_copy = bonafide_cells_result.copy()\n    # bonafide_cells_result = bonafide_cells_result[0]\n\n    def anomalyDetector (pre_processed_data, bonafide_cells_result, prediction_results):\n        # unravel data\n        marker = bonafide_cells_result[0]\n        pos = bonafide_cells_result[1]\n        neg = bonafide_cells_result[2]\n\n        if verbose is True:\n            print(\"Processing: \" + str(marker))\n        # prepare data\n        X = pre_processed_data.drop(marker, axis=1)\n        # scale data\n        scaler = StandardScaler()\n        X_scaled = scaler.fit_transform(X)\n        # model data\n        model = LocalOutlierFactor(n_neighbors=20)\n        model.fit(X_scaled)\n        outlier_scores = model.negative_outlier_factor_\n        outliers = pre_processed_data[outlier_scores &lt; -1].index\n\n        # common elements betwenn outliers and true neg\n        posttoneg = list(set(outliers).intersection(set(neg)))\n        # similarly is there any cells in negative that needs to be relocated to positive?\n        negtopos = list(set(pos).intersection(set(prediction_results[prediction_results[marker]=='neg'].index)))\n\n        # mutate the prediction results\n        prediction_results.loc[posttoneg, marker] = 'neg'\n        prediction_results.loc[negtopos, marker] = 'pos'\n\n        # results\n        results = prediction_results[[marker]]\n        return results\n\n    # Run the function\n    if verbose is True:\n        print(\"Running Anomaly Detection\")\n    r_anomalyDetector = lambda x: anomalyDetector (bonafide_cells_result = x,\n                                                   pre_processed_data = pre_processed_data,\n                                                   prediction_results = prediction_results)\n\n    # as the Anomaly Detection uses the rest of the data it cannot be run on 1 marker\n    if len(bonafide_cells_result) &gt; 1:\n        anomalyDetector_result = list(map(r_anomalyDetector, bonafide_cells_result))\n        # final prediction\n        prediction_results = pd.concat(anomalyDetector_result, axis=1)\n\n\n    ###########################################################################\n    # step-9 : Reorganizing all predictions into a final dataframe\n    ###########################################################################\n\n    # re introduce failed markers\n    if len(failedMarkersinData) &gt; 0 :\n        for name in failedMarkersinData:\n            prediction_results[name] = 'neg'\n\n        # modify the highest value element to be pos\n        #modify_prediction_results(rawprocessed, prediction_results, failedMarkersinData)\n\n        # identify midpoints for the failed markers (second largest element)\n        max_values_dict = get_second_highest_values (rawprocessed, failedMarkersinData)\n\n        # update midpoints_dict\n        midpoints_dict.update(max_values_dict)\n\n        # add the column to pre_processed data for rescaling\n        columns_to_concat = rawprocessed[failedMarkersinData]\n        pre_processed_data = pd.concat([pre_processed_data, columns_to_concat], axis=1)\n\n\n    ###########################################################################\n    # step-10 : Rescale data\n    ###########################################################################\n\n    # marker = 'ECAD'\n    def rescaleData (marker, pre_processed_data, prediction_results, midpoints_dict):\n        if verbose is True:\n            print(\"Processing: \" + str(marker))\n        # unravel data\n        data = pre_processed_data[marker].values\n        labels = prediction_results[marker].values\n        midpoint = midpoints_dict.get(marker)\n\n        # reformat data such that all negs and pos are sorted based on the midpoint\n        rescaled = modify_negatives_vectorized(data,\n                                               labels,\n                                               midpoint)\n\n        # sigmoid scaling to convert the data between 0-1 based on the midpoint\n        if rescaleMethod == 'sigmoid':\n            rescaled_data = sigmoid (rescaled, midpoint=midpoint)\n\n        if rescaleMethod == 'minmax':\n            rescaled_data = scale_data(rescaled, midpoint=midpoint)\n\n        # return\n        return rescaled_data\n\n    # Run the function\n    if verbose is True:\n        print(\"Rescaling the raw data\")\n    r_rescaleData = lambda x: rescaleData (marker=x,\n                                           pre_processed_data=pre_processed_data,\n                                           prediction_results=prediction_results,\n                                           midpoints_dict=midpoints_dict)\n    rescaleData_result = list(map(r_rescaleData, pre_processed_data.columns))\n    rescaledData = pd.DataFrame(rescaleData_result, index=pre_processed_data.columns, columns=pre_processed_data.index).T\n\n\n\n    ###########################################################################\n    # step-8 : create a new adata object with the results\n    ###########################################################################\n\n\n    final_markers = pre_processed_data.columns\n    intial_markers = rawData.columns\n    ordered_final_markers = [marker for marker in intial_markers if marker in final_markers]\n    # final raw data\n    rd = rawData[ordered_final_markers].reindex(adata.obs.index)\n    # final scaled data\n    rescaledData = rescaledData[ordered_final_markers].reindex(adata.obs.index)\n    # final pre-processed data\n    pre_processed_data = pre_processed_data[ordered_final_markers].reindex(adata.obs.index)\n\n\n    # reindex prediction results\n    prediction_results = prediction_results.reindex(adata.obs.index)\n    #probability_results = probability_results.reindex(adata.obs.index)\n\n    # create AnnData object\n    bdata = ad.AnnData(rd, dtype=np.float64)\n    bdata.obs = adata.obs\n    bdata.raw = bdata\n    bdata.X = rescaledData\n    # add the pre-processed data as a layer\n    bdata.layers[\"preProcessed\"] = pre_processed_data\n    bdata.uns = adata.uns\n    bdata.uns['failedMarkers'] = failed_markers_dict\n\n    # save the prediction results in anndata object\n    bdata.uns[str(label)] = prediction_results\n    #bdata.uns[str(label)] = probability_results\n\n    # Save data if requested\n    if projectDir is not None:\n        finalPath = pathlib.Path(projectDir + '/GATOR/gatorOutput')\n        if not os.path.exists(finalPath):\n            os.makedirs(finalPath)\n        if len(gatorObjectPath) &gt; 1:\n            imid = 'gatorOutput'\n        else:\n            imid = gatorObjectPath[0].stem\n        bdata.write(finalPath / f'{imid}.h5ad')\n\n    # Finish Job\n    if verbose is True:\n        print('Gator ran successfully, head over to \"' + str(projectDir) + '/GATOR/gatorOutput\" to view results')\n\n    return bdata\n</code></pre>"},{"location":"Functions/gatorExport/","title":"gatorExport","text":"<p>Short Description</p> <p>Users can utilize the <code>gatorExport</code> function to store the contents of the gatorObject to a <code>.CSV</code> file. </p> <p>Keep in mind that the presence of multiple intermediate files in the object will result in the production of several CSV files.</p>"},{"location":"Functions/gatorExport/#gatorpy.gatorExport--function","title":"Function","text":""},{"location":"Functions/gatorExport/#gatorpy.gatorExport.gatorExport","title":"<code>gatorExport(gatorObject, projectDir, fileName=None, raw=False, CellID='CellID', verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gatorObject</code> <code>anndata</code> <p>Pass the <code>gatorObject</code> loaded into memory or a path to the <code>gatorObject</code>  file (.h5ad).</p> required <code>projectDir</code> <code>str</code> <p>Provide the path to the output directory. The result will be located at <code>projectDir/GATOR/gatorExport/</code>. </p> required <code>fileName</code> <code>str</code> <p>Specify the name of the CSV output file. If you don't provide a file name, t he default name <code>gatorExport.csv</code> will be assigned.</p> <code>None</code> <code>raw</code> <code>bool</code> <p>If <code>True</code> raw data will be returned instead of the gator scaled data.</p> <code>False</code> <code>CellId</code> <code>str</code> <p>Specify the column name that holds the cell ID (a unique name given to each cell).</p> required <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <p>Returns:</p> Type Description <p>CSV files (.csv): The <code>.csv</code> files can be found under <code>projectDir/GATOR/gatorExport/</code></p> Example <pre><code># path to files\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\ngatorObject = projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\nga.gatorExport (gatorObject, \n                 projectDir, \n                 fileName=None, \n                 raw=False, \n                 CellID='CellID',\n                 verbose=True)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorExport.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/gatorExport.py</code> <pre><code>def gatorExport (gatorObject, \n                 projectDir, \n                 fileName=None, \n                 raw=False, \n                 CellID='CellID',\n                 verbose=True):\n\"\"\"\nParameters:\n    gatorObject (anndata):\n        Pass the `gatorObject` loaded into memory or a path to the `gatorObject` \n        file (.h5ad).\n\n    projectDir (str, optional):\n        Provide the path to the output directory. The result will be located at\n        `projectDir/GATOR/gatorExport/`. \n\n    fileName (str, optional):\n        Specify the name of the CSV output file. If you don't provide a file name, t\n        he default name `gatorExport.csv` will be assigned.\n\n    raw (bool, optional):\n        If `True` raw data will be returned instead of the gator scaled data.\n\n    CellId (str, optional):\n        Specify the column name that holds the cell ID (a unique name given to each cell).\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\nReturns:\n    CSV files (.csv):\n        The `.csv` files can be found under `projectDir/GATOR/gatorExport/`\n\nExample:\n\n        ```python\n        # path to files\n        projectDir = '/Users/aj/Desktop/gatorExampleData'\n        gatorObject = projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\n        ga.gatorExport (gatorObject, \n                         projectDir, \n                         fileName=None, \n                         raw=False, \n                         CellID='CellID',\n                         verbose=True)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gatorExport.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n\n        ```\n\n    \"\"\"\n\n\n    # projectDir = '/Users/aj/Desktop/gatorExampleData'\n    # gatorObject='/Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad' \n    # data_type='raw'; output_dir=None; fileName=None; CellID='CellID'\n\n    # Load the andata object    \n    if isinstance(gatorObject, str):\n        if fileName is None:\n            imid = pathlib.Path(gatorObject).stem\n        else: \n            imid = str(fileName)\n        gatorObject = ad.read(gatorObject)\n    else:\n        if fileName is None:\n            imid = \"gatorExport.csv\"\n        else: \n            imid = str(fileName)\n        gatorObject = gatorObject\n\n    # Expression matrix &amp; obs data\n    if raw is True:\n        data = pd.DataFrame(gatorObject.raw.X, index=gatorObject.obs.index, columns=gatorObject.var.index)\n    else:\n        data = pd.DataFrame(gatorObject.X, index=gatorObject.obs.index, columns=gatorObject.var.index)\n    meta = pd.DataFrame(gatorObject.obs)\n    # Merge the two dataframes\n    merged = pd.concat([data, meta], axis=1, sort=False)\n\n\n    # Add a column to save cell-id\n    # make cellID the first column\n    if CellID in merged.columns:\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n    else:\n        merged['CellID'] = merged.index\n        first_column = merged.pop(CellID)\n        merged.insert(0, CellID, first_column)\n\n    # reset index\n    merged = merged.reset_index(drop=True)\n\n    # create a folder to hold the results\n    folderPath = pathlib.Path(projectDir + '/GATOR/gatorExport/')\n    folderPath.mkdir(exist_ok=True, parents=True)\n\n\n    # extract some of the data stored in .uns and save\n    if hasattr(gatorObject, 'uns') and 'gatorOutput' in gatorObject.uns:\n        gatorOutput = gatorObject.uns['gatorOutput']\n        gatorOutput.index = merged['CellID']\n        gatorOutput.to_csv(folderPath / 'gatorOutput.csv')\n    if hasattr(gatorObject, 'uns') and 'gatorScore' in gatorObject.uns:    \n        gatorScore = gatorObject.uns['gatorScore']\n        gatorScore.index = merged['CellID']\n        gatorScore.to_csv(folderPath / 'gatorScore.csv')\n\n    # scaled data\n    merged.to_csv(folderPath / f'{imid}.csv', index=False)\n\n    # Finish Job\n    if verbose is True:\n        print('Contents of the gatorObject have been exported to \"' + str(projectDir) + '/GATOR/gatorExport\"')\n</code></pre>"},{"location":"Functions/gatorObject/","title":"gatorObject","text":"<p>Short Description</p> <p>The <code>gatorObject</code> function creates a gator object using the anndata  framework by inputting gatorScore and a pre-calculated single-cell spatial table.  This centralizes all information into one file, streamlining the data analysis  process and reducing the risk of losing data.</p>"},{"location":"Functions/gatorObject/#gatorpy.gatorObject--function","title":"Function","text":""},{"location":"Functions/gatorObject/#gatorpy.gatorObject.gatorObject","title":"<code>gatorObject(spatialTablePath, gatorScorePath, CellId='CellID', uniqueCellId=True, split='X_centroid', removeDNA=True, remove_string_from_name=None, log=True, dropMarkers=None, verbose=True, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>spatialTablePath</code> <code>list</code> <p>Provide a list of paths to the single-cell spatial feature tables, ensuring each image has a unique path specified.</p> required <code>gatorScorePath</code> <code>list</code> <p>Supply a list of paths to the DL score tables created using generateGatorScore, ensuring they correspond to the image paths specified.</p> required <code>CellId</code> <code>str</code> <p>Specify the column name that holds the cell ID (a unique name given to each cell).</p> <code>'CellID'</code> <code>uniqueCellId</code> <code>bool</code> <p>The function generates a unique name for each cell by combining the CellId and imageid. If you don't want this, pass False. In such case the function will default to using just the CellId. However, make sure CellId is unique especially when loading multiple images together.</p> <code>True</code> <code>split</code> <code>string</code> <p>The spatial feature table generally includes single cell expression data and meta data such as X, Y coordinates, and cell shape size. The Gator object separates them. Ensure that the expression data columns come first, followed by meta data columns. Provide the column name that marks the split, i.e the column name immediately following the expression data.</p> <code>'X_centroid'</code> <code>removeDNA</code> <code>bool</code> <p>Exclude DNA channels from the final output. The function searches for column names containing the string <code>dna</code> or <code>dapi</code>. </p> <code>True</code> <code>remove_string_from_name</code> <code>string</code> <p>Cleans up channel names by removing user specified string from all marker names. </p> <code>None</code> <code>log</code> <code>bool</code> <p>Apply log1p transformation to log the data. </p> <code>True</code> <code>dropMarkers</code> <code>list</code> <p>Specify a list of markers to be removed from the analysis, for example: [\"background_channel\", \"CD20\"]. </p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>projectDir</code> <code>string</code> <p>Provide the path to the output directory. The result will be located at <code>projectDir/GATOR/gatorObject/</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>gatorObject</code> <code>anndata</code> <p>If projectDir is provided the Gator Object will be saved as a <code>.h5ad</code> file in the provided directory.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\n\n# Module specific paths\nspatialTablePath = cwd + '/quantification/exampleSpatialTable.csv'\ngatorScorePath = cwd + '/GATOR/gatorScore/exampleImage_gatorPredict.ome.csv'\n\n# please note that there are a number of defaults in the below function that assumes certain structure within the spatialTable.\n# Please confirm it is similar with user data or modifiy the parameters accordingly\n# check out the documentation for further details\nadata = ga.gatorObject (spatialTablePath=spatialTablePath,\n                gatorScorePath=gatorScorePath,\n                CellId='CellID',\n                uniqueCellId=True,\n                split='X_centroid',\n                removeDNA=True,\n                remove_string_from_name=None,\n                log=True,\n                dropMarkers=None,\n                verbose=True,\n                projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorObject.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv --gatorScorePath /Users/aj/Desktop/gatorExampleData/GATOR/gatorScore/exampleProbabiltyMap.ome.csv --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/gatorObject.py</code> <pre><code>def gatorObject (spatialTablePath,\n                 gatorScorePath,\n                 CellId='CellID',\n                 uniqueCellId=True,\n                 split='X_centroid',\n                 removeDNA=True,\n                 remove_string_from_name=None,\n                 log=True,\n                 dropMarkers=None,\n                 verbose=True,\n                 projectDir=None):\n\"\"\"\nParameters:\n    spatialTablePath (list):\n        Provide a list of paths to the single-cell spatial feature tables, ensuring each image has a unique path specified.\n\n    gatorScorePath (list):\n        Supply a list of paths to the DL score tables created using generateGatorScore,\n        ensuring they correspond to the image paths specified.\n\n    CellId (str, optional):\n        Specify the column name that holds the cell ID (a unique name given to each cell).\n\n    uniqueCellId (bool, optional):\n        The function generates a unique name for each cell by combining the CellId and imageid.\n        If you don't want this, pass False. In such case the function will default to using just the CellId.\n        However, make sure CellId is unique especially when loading multiple images together.\n\n    split (string, optional):\n        The spatial feature table generally includes single cell expression data\n        and meta data such as X, Y coordinates, and cell shape size. The Gator\n        object separates them. Ensure that the expression data columns come first,\n        followed by meta data columns. Provide the column name that marks the split,\n        i.e the column name immediately following the expression data.\n\n    removeDNA (bool, optional):\n        Exclude DNA channels from the final output. The function searches for\n        column names containing the string `dna` or `dapi`. \n\n    remove_string_from_name (string, optional):\n        Cleans up channel names by removing user specified string from all marker\n        names. \n\n    log (bool, optional):\n        Apply log1p transformation to log the data. \n\n    dropMarkers (list, optional):\n        Specify a list of markers to be removed from the analysis, for\n        example: [\"background_channel\", \"CD20\"]. \n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    projectDir (string, optional):\n        Provide the path to the output directory. The result will be located at\n        `projectDir/GATOR/gatorObject/`.\n\nReturns:\n    gatorObject (anndata):\n        If projectDir is provided the Gator Object will be saved as a\n        `.h5ad` file in the provided directory.\n\nExample:\n\n        ```python\n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n\n        # Module specific paths\n        spatialTablePath = cwd + '/quantification/exampleSpatialTable.csv'\n        gatorScorePath = cwd + '/GATOR/gatorScore/exampleImage_gatorPredict.ome.csv'\n\n        # please note that there are a number of defaults in the below function that assumes certain structure within the spatialTable.\n        # Please confirm it is similar with user data or modifiy the parameters accordingly\n        # check out the documentation for further details\n        adata = ga.gatorObject (spatialTablePath=spatialTablePath,\n                        gatorScorePath=gatorScorePath,\n                        CellId='CellID',\n                        uniqueCellId=True,\n                        split='X_centroid',\n                        removeDNA=True,\n                        remove_string_from_name=None,\n                        log=True,\n                        dropMarkers=None,\n                        verbose=True,\n                        projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gatorObject.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv --gatorScorePath /Users/aj/Desktop/gatorExampleData/GATOR/gatorScore/exampleProbabiltyMap.ome.csv --projectDir /Users/aj/Desktop/gatorExampleData\n\n        ```\n\n    \"\"\"\n#spatialTablePath = r\"C:\\Users\\ajn16\\Dropbox (Partners HealthCare)\\Data\\gator\\data\\Exemplar\\modified_dearray\\quantification\\unmicst-113_cellMask.csv\"\n#probTablePath = r\"C:\\Users\\ajn16\\Dropbox (Partners HealthCare)\\Data\\gator\\data\\ajn_training_data\\GATOR\\probQuant\\113_GatorOutput.csv\"\n#dropMarkers = ['bg2b', 'bg3b', 'bg4b', 'ECAD_2']\n\n#projectDir = 'C:/Users/ajn16/Dropbox (Partners HealthCare)/Data/gator/data/ajn_training_data'\n#gatorObject (spatialTablePath=spatialTablePath, probTablePath=probTablePath, projectDir=projectDir, dropMarkers=dropMarkers)\n\n    # spatialTablePath list or string\n    if isinstance(spatialTablePath, str):\n        spatialTablePath = [spatialTablePath]\n    spatialTablePath = [pathlib.Path(p) for p in spatialTablePath]\n    # gatorScorePath list or string\n    if isinstance(gatorScorePath, str):\n        gatorScorePath = [gatorScorePath]\n    gatorScorePath = [pathlib.Path(p) for p in gatorScorePath]\n\n    # Import spatialTablePath\n    def load_process_data (image):\n        # Print the data that is being processed\n        if verbose is True:\n            print(f\"Loading {image.name}\")\n        d = pd.read_csv(image)\n        # If the data does not have a unique image ID column, add one.\n        if 'imageid' not in d.columns:\n            imid = image.stem\n            d['imageid'] = imid\n        # Unique name for the data\n        if uniqueCellId is True:\n            d.index = d['imageid'].astype(str)+'_'+d[CellId].astype(str)\n        else:\n            d.index = d[CellId]\n\n        # move image id and cellID column to end\n        cellid_col = [col for col in d.columns if col != CellId] + [CellId]; d = d[cellid_col]\n        imageid_col = [col for col in d.columns if col != 'imageid'] + ['imageid']; d = d[imageid_col]\n        # If there is INF replace with zero\n        d = d.replace([np.inf, -np.inf], 0)\n        # Return data\n        return d\n\n    # Import gatorScorePath\n    def load_process_probTable (image):\n        d = pd.read_csv(image, index_col=0)\n        # Return data\n        return d\n\n    # Apply function to all spatialTablePath and create a master dataframe\n    r_load_process_data = lambda x: load_process_data(image=x) # Create lamda function\n    all_spatialTable = list(map(r_load_process_data, list(spatialTablePath))) # Apply function\n    # Merge all the spatialTablePath into a single large dataframe\n    for i in range(len(all_spatialTable)):\n        all_spatialTable[i].columns = all_spatialTable[0].columns\n    entire_spatialTable = pd.concat(all_spatialTable, axis=0, sort=False)\n\n    # Apply function to all gatorScorePath and create a master dataframe\n    r_load_process_probTable = lambda x: load_process_probTable(image=x) # Create lamda function\n    all_probTable = list(map(r_load_process_probTable, list(gatorScorePath))) # Apply function\n    # Merge all the gatorScorePath into a single large dataframe\n    for i in range(len(all_probTable)):\n        all_probTable[i].columns = all_probTable[0].columns\n    entire_probTable = pd.concat(all_probTable, axis=0, sort=False)\n    # make the index of entire_probTable same as all_probTable\n    ## NOTE THIS IS A HARD COPY WITHOUT ANY CHECKS! ASSUMES BOTH ARE IN SAME ORDER\n    entire_probTable.index = entire_spatialTable.index\n\n\n    # Split the data into expression data and meta data\n    # Step-1 (Find the index of the column with name X_centroid)\n    split_idx = entire_spatialTable.columns.get_loc(split)\n    meta = entire_spatialTable.iloc [:,split_idx:]\n    # Step-2 (select only the expression values)\n    entire_spatialTable = entire_spatialTable.iloc [:,:split_idx]\n\n    # Rename the columns of the data\n    if remove_string_from_name is not None:\n        entire_spatialTable.columns = entire_spatialTable.columns.str.replace(remove_string_from_name, '')\n\n    # Save a copy of the column names in the uns space of ANNDATA\n    markers = list(entire_spatialTable.columns)\n\n    # Remove DNA channels\n    if removeDNA is True:\n        entire_spatialTable = entire_spatialTable.loc[:,~entire_spatialTable.columns.str.contains('dna', case=False)]\n        entire_spatialTable = entire_spatialTable.loc[:,~entire_spatialTable.columns.str.contains('dapi', case=False)]\n\n    # Drop unnecessary markers\n    if dropMarkers is not None:\n        if isinstance(dropMarkers, str):\n            dropMarkers = [dropMarkers]\n        dropMarkers = list(set(dropMarkers).intersection(entire_spatialTable.columns))\n        entire_spatialTable = entire_spatialTable.drop(columns=dropMarkers)\n\n    # Create an anndata object\n    adata = ad.AnnData(entire_spatialTable, dtype=np.float64)\n    adata.obs = meta\n    adata.uns['all_markers'] = markers\n    adata.uns['gatorScore'] = entire_probTable\n\n    # Add log data\n    if log is True:\n        adata.raw = adata\n        adata.X = np.log1p(adata.X)\n\n    # Save data if requested\n    if projectDir is not None:\n        finalPath = pathlib.Path(projectDir + '/GATOR/gatorObject')\n        if not os.path.exists(finalPath):\n            os.makedirs(finalPath)\n        if len(spatialTablePath) &gt; 1:\n            imid = 'gatorObject'\n        else:\n            imid = gatorScorePath[0].stem\n        adata.write(finalPath / f'{imid}.h5ad')\n        # Finish Job\n        if verbose is True:\n            print('Gator Object has been created, head over to'+ str(projectDir) + '/GATOR/gatorObject\" to view results')\n    else:\n        # Return data\n        if verbose is True:\n            print('Gator Object has been created')\n        return adata\n</code></pre>"},{"location":"Functions/gatorPhenotype/","title":"gatorPhenotype","text":"<p>Short Description</p> <p>The gatorPhenotype function requires a phenotype workflow document to guide  the algorithm in performing classification.  </p> <p>The phenotype workflow document is imported as a <code>dataframe</code> and passed to the  <code>phenotype</code> argument. It should follow the following structure:  </p> <p>(1) The <code>first column</code> has to contain the cell that are to be classified. (2) The <code>second column</code> indicates the phenotype a particular cell will be assigned  if it satifies the conditions in the row. (3) <code>Column three</code> and onward represent protein markers. If the protein marker  is known to be expressed for that cell type, then it is denoted by either <code>pos</code>,  <code>allpos</code>. If the protein marker is known to not express for a cell type it  can be denoted by <code>neg</code>, <code>allneg</code>. If the protein marker is irrelevant or  uncertain to express for a cell type, then it is left empty. <code>anypos</code> and  <code>anyneg</code> are options for using a set of markers and if any of the marker is  positive or negative, the cell type is denoted accordingly.  </p> <p>To give users maximum flexibility in identifying desired cell types,  we have implemented various classification arguments as described above  for strategical classification. They include  </p> <ul> <li>allpos</li> <li>allneg</li> <li>anypos</li> <li>anyneg</li> <li>pos</li> <li>neg</li> </ul> <p><code>pos</code> : \"Pos\" looks for cells positive for a given marker. If multiple  markers are annotated as <code>pos</code>, all must be positive to denote the cell type.  For example, a Regulatory T cell can be defined as <code>CD3+CD4+FOXP3+</code> by passing  <code>pos</code> to each marker. If one or more markers don't meet the criteria (e.g. CD4-),  the program will classify it as <code>Likely-Regulatory-T cell</code>, pending user  confirmation. This is useful in cases of technical artifacts or when cell  types (such as cancer cells) are defined by marker loss (e.g. T-cell Lymphomas).  </p> <p><code>neg</code> : Same as <code>pos</code> but looks for negativity of the defined markers.  </p> <p><code>allpos</code> : \"Allpos\" requires all defined markers to be positive. Unlike  <code>pos</code>, it doesn't classify cells as <code>Likely-cellType</code>, but strictly annotates  cells positive for all defined markers.  </p> <p><code>allneg</code> : Same as <code>allpos</code> but looks for negativity of the defined markers.  </p> <p><code>anypos</code> : \"Anypos\" requires only one of the defined markers to be positive.  For example, to define macrophages, a cell could be designated as such if  any of <code>CD68</code>, <code>CD163</code>, or <code>CD206</code> is positive.  </p> <p><code>anyneg</code> : Same as <code>anyneg</code> but looks for negativity of the defined markers. </p>"},{"location":"Functions/gatorPhenotype/#gatorpy.gatorPhenotype--function","title":"Function","text":""},{"location":"Functions/gatorPhenotype/#gatorpy.gatorPhenotype.gatorPhenotype","title":"<code>gatorPhenotype(gatorObject, phenotype, midpoint=0.5, label='phenotype', imageid='imageid', pheno_threshold_percent=None, pheno_threshold_abs=None, fileName=None, verbose=True, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gatorObject</code> <code>anndata</code> <p>Single or combined Gator object.</p> required <code>phenotype</code> <code>dataframe, str</code> <p>A phenotyping workflow strategy either as a <code>dataframe</code> loaded into memory or  a path to the <code>.csv</code> file. </p> required <code>midpoint</code> <code>float</code> <p>By default, Gator normalizes the data in a way that cells with a value above 0.5 are considered positive. However, if you desire more selective threshold, the parameter can be adjusted accordingly. </p> <code>0.5</code> <code>label</code> <code>str</code> <p>Specify the column name under which the final phenotype classification will be saved. </p> <code>'phenotype'</code> <code>imageid</code> <code>str</code> <p>The name of the column that holds the unique image ID. </p> <code>'imageid'</code> <code>pheno_threshold_percent</code> <code>float</code> <p>The user-defined threshold, which can be set between 0-100, is used to recategorize any phenotype that falls below it as 'unknown'. This function is commonly used to address low background false positives.</p> <code>None</code> <code>pheno_threshold_abs</code> <code>int</code> <p>This function serves a similar purpose as the <code>pheno_threshold_percent</code>, but it accepts an absolute number as input. For example, if the user inputs 10, any phenotype that contains less than 10 cells will be recategorized as 'unknown'. </p> <code>None</code> <code>fileName</code> <code>string</code> <p>File Name to be used while saving the gator object.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>projectDir</code> <code>string</code> <p>Provide the path to the output directory.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>gatorObject</code> <code>anndata</code> <p>Modified Gator object with the Phenotypes is returned. If <code>projectDir</code> is  provided, it will be saved in the defined directory.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\n# Module specific paths\ngatorObject = cwd + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n\n# load the phenotyping workflow\nphenotype = cwd + '/phenotype_workflow.csv'\n\n# Run Function\nadata = ga.gatorPhenotype ( gatorObject=gatorObject,\n                    phenotype=phenotype,\n                    midpoint = 0.5,\n                    label=\"phenotype\",\n                    imageid='imageid',\n                    pheno_threshold_percent=None,\n                    pheno_threshold_abs=None,\n                    fileName=None,\n                    projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorPhenotype.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad --phenotype /Users/aj/Desktop/gatorExampleData/phenotype_workflow.csv --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/gatorPhenotype.py</code> <pre><code>def gatorPhenotype (gatorObject,\n                    phenotype,\n                    midpoint = 0.5,\n                    label=\"phenotype\",\n                    imageid='imageid',\n                    pheno_threshold_percent=None,\n                    pheno_threshold_abs=None,\n                    fileName=None,\n                    verbose=True,\n                    projectDir=None):\n\"\"\"\nParameters:\n    gatorObject (anndata):\n        Single or combined Gator object.\n\n    phenotype (dataframe, str):\n        A phenotyping workflow strategy either as a `dataframe` loaded into memory or \n        a path to the `.csv` file. \n\n    midpoint (float, optional):\n        By default, Gator normalizes the data in a way that cells with a value\n        above 0.5 are considered positive. However, if you desire more selective\n        threshold, the parameter can be adjusted accordingly. \n\n    label (str, optional):\n        Specify the column name under which the final phenotype classification\n        will be saved. \n\n    imageid (str, optional):\n        The name of the column that holds the unique image ID. \n\n    pheno_threshold_percent (float, optional):\n        The user-defined threshold, which can be set between 0-100, is used to\n        recategorize any phenotype that falls below it as 'unknown'.\n        This function is commonly used to address low background false positives.\n\n    pheno_threshold_abs (int, optional):\n        This function serves a similar purpose as the `pheno_threshold_percent`,\n        but it accepts an absolute number as input. For example, if the user\n        inputs 10, any phenotype that contains less than 10 cells will be\n        recategorized as 'unknown'. \n\n    fileName (string, optional):\n        File Name to be used while saving the gator object.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    projectDir (string, optional):\n        Provide the path to the output directory.\n\nReturns:\n    gatorObject (anndata):\n        Modified Gator object with the Phenotypes is returned. If `projectDir` is \n        provided, it will be saved in the defined directory.\n\nExample:\n\n        ```python\n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n        # Module specific paths\n        gatorObject = cwd + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n\n        # load the phenotyping workflow\n        phenotype = cwd + '/phenotype_workflow.csv'\n\n        # Run Function\n        adata = ga.gatorPhenotype ( gatorObject=gatorObject,\n                            phenotype=phenotype,\n                            midpoint = 0.5,\n                            label=\"phenotype\",\n                            imageid='imageid',\n                            pheno_threshold_percent=None,\n                            pheno_threshold_abs=None,\n                            fileName=None,\n                            projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gatorPhenotype.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad --phenotype /Users/aj/Desktop/gatorExampleData/phenotype_workflow.csv --projectDir /Users/aj/Desktop/gatorExampleData\n\n\n        ```\n\n    \"\"\"\n\n    # Load data\n    if isinstance(gatorObject, str):\n        adata = ad.read(gatorObject)\n    else:\n        adata = gatorObject.copy()\n\n    # load phenotype\n    if isinstance(phenotype, pd.DataFrame):\n        phenotype = phenotype\n    else:\n        phenotype = pd.read_csv(pathlib.Path(phenotype))\n\n    # Create a dataframe from the adata object\n    data = pd.DataFrame(adata.X, columns = adata.var.index, index= adata.obs.index)\n\n    # Function to calculate the phenotype scores\n    def phenotype_cells (data,phenotype,midpoint,group):\n\n        # Subset the phenotype based on the group\n        phenotype = phenotype[phenotype.iloc[:,0] == group]\n\n        # Parser to parse the CSV file into four categories\n        def phenotype_parser (p, cell):\n            # Get the index and subset the phenotype row being passed in\n            location = p.iloc[:,1] == cell\n            idx = [i for i, x in enumerate(location) if x][0]\n            phenotype = p.iloc[idx,:]\n            # Calculate\n            pos = phenotype[phenotype == 'pos'].index.tolist()\n            neg = phenotype[phenotype == 'neg'].index.tolist()\n            anypos = phenotype[phenotype == 'anypos'].index.tolist()\n            anyneg = phenotype[phenotype == 'anyneg'].index.tolist()\n            allpos = phenotype[phenotype == 'allpos'].index.tolist()\n            allneg = phenotype[phenotype == 'allneg'].index.tolist()\n            return {'pos': pos, 'neg': neg ,'anypos': anypos, 'anyneg': anyneg, 'allpos': allpos, 'allneg': allneg}\n            #return pos, neg, anypos, anyneg\n\n        # Run the phenotype_parser function on all rows\n        p_list = phenotype.iloc[:,1].tolist()\n        r_phenotype = lambda x: phenotype_parser(cell=x, p=phenotype) # Create lamda function\n        all_phenotype = list(map(r_phenotype, p_list)) # Apply function\n        all_phenotype = dict(zip(p_list, all_phenotype)) # Name the lists\n\n        # Define function to check if there is any marker that does not satisfy the midpoint\n        def gate_satisfation_lessthan (marker, data, midpoint):\n            fail = np.where(data[marker] &lt; midpoint, 1, 0) # 1 is fail\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_lessthan = lambda x: gate_satisfation_lessthan(marker=x, data=data, midpoint=midpoint)\n\n        # Define function to check if there is any marker that does not satisfy the midpoint\n        def gate_satisfation_morethan (marker, data, midpoint):\n            fail = np.where(data[marker] &gt; midpoint, 1, 0)\n            return fail\n        # Corresponding lamda function\n        r_gate_satisfation_morethan = lambda x: gate_satisfation_morethan(marker=x, data=data, midpoint=midpoint)\n\n        def prob_mapper (data, all_phenotype, cell, midpoint):\n            if verbose is True:\n                print(\"Phenotyping \" + str(cell))\n\n            # Get the appropriate dict from all_phenotype\n            p = all_phenotype[cell]\n\n            # Identiy the marker used in each category\n            pos = p.get('pos')\n            neg = p.get('neg')\n            anypos = p.get('anypos')\n            anyneg = p.get('anyneg')\n            allpos = p.get('allpos')\n            allneg = p.get('allneg')\n\n            # Perform computation for each group independently\n            # Positive marker score\n            if len(pos) != 0:\n                pos_score = data[pos].mean(axis=1).values\n                pos_fail = list(map(r_gate_satisfation_lessthan, pos)) if len(pos) &gt; 1 else []\n                pos_fail = np.amax(pos_fail, axis=0) if len(pos) &gt; 1 else []\n            else:\n                pos_score = np.repeat(0, len(data))\n                pos_fail = []\n\n            # Negative marker score\n            if len(neg) != 0:\n                neg_score = (1-data[neg]).mean(axis=1).values\n                neg_fail = list(map(r_gate_satisfation_morethan, neg)) if len(neg) &gt; 1 else []\n                neg_fail = np.amax(neg_fail, axis=0) if len(neg) &gt; 1 else []\n            else:\n                neg_score = np.repeat(0, len(data))\n                neg_fail = []\n\n            # Any positive score\n            anypos_score = np.repeat(0, len(data)) if len(anypos) == 0 else data[anypos].max(axis=1).values\n\n            # Any negative score\n            anyneg_score = np.repeat(0, len(data)) if len(anyneg) == 0 else (1-data[anyneg]).max(axis=1).values\n\n            # All positive score\n            if len(allpos) != 0:\n                allpos_score = data[allpos]\n                allpos_score['score'] = allpos_score.max(axis=1)\n                allpos_score.loc[(allpos_score &lt; midpoint).any(axis = 1), 'score'] = 0\n                allpos_score = allpos_score['score'].values + 0.01 # A small value is added to give an edge over the matching positive cell\n            else:\n                allpos_score = np.repeat(0, len(data))\n\n\n            # All negative score\n            if len(allneg) != 0:\n                allneg_score = 1- data[allneg]\n                allneg_score['score'] = allneg_score.max(axis=1)\n                allneg_score.loc[(allneg_score &lt; midpoint).any(axis = 1), 'score'] = 0\n                allneg_score = allneg_score['score'].values + 0.01\n            else:\n                allneg_score = np.repeat(0, len(data))\n\n\n            # Total score calculation\n            # Account for differences in the number of categories used for calculation of the final score\n            number_of_non_empty_features = np.sum([len(pos) != 0,\n                                                len(neg) != 0,\n                                                len(anypos) != 0,\n                                                len(anyneg) != 0,\n                                                len(allpos) != 0,\n                                                len(allneg) != 0])\n\n            total_score = (pos_score + neg_score + anypos_score + anyneg_score + allpos_score + allneg_score) / number_of_non_empty_features\n\n            return {cell: total_score, 'pos_fail': pos_fail ,'neg_fail': neg_fail}\n            #return total_score, pos_fail, neg_fail\n\n\n        # Apply the fuction to get the total score for all cell types\n        r_prob_mapper = lambda x: prob_mapper (data=data, all_phenotype=all_phenotype, cell=x, midpoint=midpoint) # Create lamda function\n        final_scores = list(map(r_prob_mapper, [*all_phenotype])) # Apply function\n        final_scores = dict(zip([*all_phenotype], final_scores)) # Name the lists\n\n        # Combine the final score to annotate the cells with a label\n        final_score_df = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i][i])\n            final_score_df= pd.concat([final_score_df, df], axis=1)\n        # Name the columns\n        final_score_df.columns = [*final_scores]\n        final_score_df.index = data.index\n        # Add a column called unknown if all markers have a value less than the midpoint (0.5)\n        unknown = group + str('-rest')\n        final_score_df[unknown] = (final_score_df &lt; midpoint).all(axis=1).astype(int)\n\n        # Name each cell\n        labels = final_score_df.idxmax(axis=1)\n\n        # Group all failed instances (i.e. when multiple markers were given\n        # any one of the marker fell into neg or pos zones of the midpoint)\n        pos_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['pos_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            pos_fail_all= pd.concat([pos_fail_all, df], axis=1)\n        pos_fail_all.index = data.index if len(pos_fail_all) != 0 else []\n        # Same for Neg\n        neg_fail_all = pd.DataFrame()\n        for i in [*final_scores]:\n            df = pd.DataFrame(final_scores[i]['neg_fail'])\n            df.columns = [i] if len(df) != 0 else []\n            neg_fail_all= pd.concat([neg_fail_all, df], axis=1)\n        neg_fail_all.index = data.index if len(neg_fail_all) != 0 else []\n\n\n        # Modify the labels with the failed annotations\n        if len(pos_fail_all) != 0:\n            for i in pos_fail_all.columns:\n                labels[(labels == i) &amp; (pos_fail_all[i] == 1)] = 'likely-' + i\n        # Do the same for negative\n        if len(neg_fail_all) != 0:\n            for i in neg_fail_all.columns:\n                labels[(labels == i) &amp; (neg_fail_all[i] == 1)] = 'likely-' + i\n\n        # Retun the labels\n        return labels\n\n    # Create an empty dataframe to hold the labeles from each group\n    phenotype_labels = pd.DataFrame()\n\n    # Loop through the groups to apply the phenotype_cells function\n    for i in phenotype.iloc[:,0].unique():\n\n        if phenotype_labels.empty:\n            phenotype_labels = pd.DataFrame(phenotype_cells(data = data, group = i, phenotype=phenotype, midpoint=midpoint))\n            phenotype_labels.columns = [i]\n\n        else:\n            # Find the column with the cell-type of interest\n            column_of_interest = [] # Empty list to hold the column name\n            try:\n                column_of_interest = phenotype_labels.columns[phenotype_labels.eq(i).any()]\n            except:\n                pass\n            # If the cell-type of interest was not found just add NA\n            if len(column_of_interest) == 0:\n                phenotype_labels[i] = np.nan\n            else:\n                #cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest] == i].index\n                cells_of_interest = phenotype_labels[phenotype_labels[column_of_interest].eq(i).any(axis=1)].index\n                d = data.loc[cells_of_interest]\n                if verbose is True:\n                    print(\"-- Subsetting \" + str(i))\n                phenotype_l = pd.DataFrame(phenotype_cells(data = d, group = i, phenotype=phenotype, midpoint=midpoint), columns = [i])\n                phenotype_labels = phenotype_labels.merge(phenotype_l, how='outer', left_index=True, right_index=True)\n\n    # Rearrange the rows back to original\n    phenotype_labels = phenotype_labels.reindex(data.index)\n    phenotype_labels = phenotype_labels.replace('-rest', np.nan, regex=True)\n    if verbose is True:\n        print(\"Consolidating the phenotypes across all groups\")\n        phenotype_labels_Consolidated = phenotype_labels.fillna(method='ffill', axis = 1)\n    phenotype_labels[label] = phenotype_labels_Consolidated.iloc[:,-1].values\n\n    # replace nan to 'other cells'\n    phenotype_labels[label] = phenotype_labels[label].fillna('Unknown')\n\n    # Apply the phenotype threshold if given\n    if pheno_threshold_percent or pheno_threshold_abs is not None:\n        p = pd.DataFrame(phenotype_labels[label])\n        q = pd.DataFrame(adata.obs[imageid])\n        p = q.merge(p, how='outer', left_index=True, right_index=True)\n\n        # Function to remove phenotypes that are less than the given threshold\n        def remove_phenotype(p, ID, pheno_threshold_percent, pheno_threshold_abs):\n            d = p[p[imageid] == ID]\n            x = pd.DataFrame(d.groupby([label]).size())\n            x.columns = ['val']\n            # FInd the phenotypes that are less than the given threshold\n            if pheno_threshold_percent is not None:\n                fail = list(x.loc[x['val'] &lt; x['val'].sum() * pheno_threshold_percent/100].index)\n            if pheno_threshold_abs is not None:\n                fail = list(x.loc[x['val'] &lt; pheno_threshold_abs].index)\n            d[label] = d[label].replace(dict(zip(fail, np.repeat('Unknown',len(fail)))))\n            # Return\n            return d\n\n        # Apply function to all images\n        r_remove_phenotype = lambda x: remove_phenotype (p=p, ID=x,\n                                                         pheno_threshold_percent=pheno_threshold_percent,\n                                                         pheno_threshold_abs=pheno_threshold_abs) # Create lamda function\n        final_phrnotypes= list(map(r_remove_phenotype, list(p[imageid].unique()))) # Apply function\n\n        final_phrnotypes = pd.concat(final_phrnotypes, join='outer')\n        phenotype_labels = final_phrnotypes.reindex(adata.obs.index)\n\n\n    # Return to adata\n    adata.obs[label] = phenotype_labels[label]\n\n    # Save data if requested\n    if projectDir is not None:\n\n        finalPath = pathlib.Path(projectDir + '/GATOR/gatorPhenotyped/')\n        if not os.path.exists(finalPath):\n            os.makedirs(finalPath)\n        # determine file name\n        if fileName is None:\n            if isinstance (gatorObject, str):\n                imid = pathlib.Path(gatorObject).stem\n            else:\n                imid = 'gatorPhenotyped'\n        else:\n            imid = fileName\n\n        adata.write(finalPath / f'{imid}.h5ad')\n        # Print\n        if verbose is True:\n            print('Modified gatorObjects is stored at \"' + str(projectDir) + '/GATOR/gatorPhenotyped')\n\n    else:\n        # Return data\n        return adata\n    return adata\n</code></pre>"},{"location":"Functions/gatorPipeline/","title":"gatorPipeline","text":"<p>Short Description</p> <p>The gatorPipeline function is simply a wrapper for the following functions: - gatorPredict - generateGatorScore - gatorObject - gator  </p> <p>Typically, in production settings, <code>gatorPipeline</code> would be utilized, whereas  step-by-step analysis would be employed for troubleshooting, model validation,  and similar tasks that necessitate greater granularity or control.</p> <p>Please refer to the individual function documentation for parameter tuning.</p>"},{"location":"Functions/gatorPipeline/#gatorpy.gatorPipeline--function","title":"Function","text":""},{"location":"Functions/gatorPipeline/#gatorpy.gatorPipeline.gatorPipeline","title":"<code>gatorPipeline(**kwargs)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>imagePath</code> <code>str</code> <p>The path to the .tif file that needs to be processed. </p> required <code>gatorModelPath</code> <code>str</code> <p>The path to the <code>gatorModel</code> folder. </p> required <code>markerChannelMapPath</code> <code>str</code> <p>The path to the marker panel list, which contains information about the markers used in the image. This argument is required.</p> required <code>segmentationMaskPath</code> <code>str</code> <p>Supply the path of the pre-computed segmentation mask.</p> required <code>spatialTablePath</code> <code>list</code> <p>Provide a list of paths to the single-cell spatial feature tables, ensuring each image has a unique path specified.</p> required <code>projectDir</code> <code>str</code> <p>The path to the output directory where the processed images (<code>probabilityMasks</code>) will be saved.</p> required <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> required <code>markerColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the marker names. The default value is 'marker'.</p> required <code>channelColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the channel names. The default value is 'channel'.</p> required <code>modelColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the model names. The default value is 'gatormodel'.</p> required <code>GPU</code> <code>int</code> <p>An optional argument to explicitly select the GPU to use. The default value is -1, meaning that the GPU will be selected automatically.</p> required <code>feature</code> <code>str</code> <p>Calculates the <code>mean</code> or <code>median</code> Gator Score for each cell.</p> required <code>markerNames</code> <code>list</code> <p>The program searches for marker names in the meta data (description section) of the tiff files created by <code>gatorPredict</code> by default. If the meta data is lost due to user modifications, provide the marker names for each channel/layer in the <code>probabilityMaskPath</code> here.</p> required <code>CellId</code> <code>str</code> <p>Specify the column name that holds the cell ID (a unique name given to each cell).</p> required <code>uniqueCellId</code> <code>bool</code> <p>The function generates a unique name for each cell by combining the CellId and imageid. If you don't want this, pass False. In such case the function will default to using just the CellId. However, make sure CellId is unique especially when loading multiple images together.</p> required <code>split</code> <code>string</code> <p>The spatial feature table generally includes single cell expression data and meta data such as X, Y coordinates, and cell shape size. The Gator object separates them. Ensure that the expression data columns come first, followed by meta data columns. Provide the column name that marks the split, i.e the column name immediately following the expression data.</p> required <code>removeDNA</code> <code>bool</code> <p>Exclude DNA channels from the final output. The function searches for column names containing the string <code>dna</code> or <code>dapi</code>. </p> required <code>remove_string_from_name</code> <code>string</code> <p>Cleans up channel names by removing user specified string from all marker names.</p> required <code>gatorScore</code> <code>str</code> <p>Include the label used for saving the <code>gatorScore</code> within the Gator object.</p> required <code>minAbundance</code> <code>float</code> <p>Specify the minimum percentage of cells that should express a specific marker in order to determine if the marker is considered a failure. A good approach is to consider the lowest percentage of rare cells expected within the dataset.</p> required <code>percentiles</code> <code>list</code> <p>Specify the interval of percentile levels of the expression utilized to intialize the GMM. The cells falling within these percentiles are utilized to distinguish between negative cells (first two values) and positive cells (last two values).</p> required <code>dropMarkers</code> <code>list</code> <p>Specify a list of markers to be removed from the analysis, for example: <code>[\"background_channel1\", \"background_channel2\"]</code>. </p> required <code>RobustScale</code> <code>bool</code> <p>When set to True, the data will be subject to Robust Scaling before the Gradient Boosting Classifier is trained. </p> required <code>log</code> <code>bool</code> <p>Apply <code>log1p</code> transformation on the data, unless it has already been log transformed in which case set it to <code>False</code>. </p> required <code>stringentThreshold</code> <code>bool</code> <p>The Gaussian Mixture Model (GMM) is utilized to distinguish positive and  negative cells by utilizing gatorScores. The stringentThreshold can be utilized  to further refine the classification of positive and negative cells.  By setting it to True, cells with gatorScore below the mean of the negative  distribution and above the mean of the positive distribution will be  labeled as true negative and positive, respectively.</p> required <code>x_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the X coordinates for each cell. </p> required <code>y_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the Y coordinates for each cell.</p> required <code>imageid</code> <code>str</code> <p>The name of the column that holds the unique image ID. </p> required <code>random_state</code> <code>int</code> <p>Seed used by the random number generator. </p> required <code>rescaleMethod</code> <code>string</code> <p>Choose between <code>sigmoid</code> and <code>minmax</code>.</p> required <code>label</code> <code>str</code> <p>Assign a label for the object within <code>adata.uns</code> where the predictions from Gator will be stored. </p> required <p>Returns:</p> Name Type Description <code>gatorObject</code> <code>anndata</code> <p>Returns a gatorObject with predictions of all positve and negative cells. </p> Example <pre><code># Path to all the files that are necessary files for running the \nGator Prediction Algorithm (broken down based on sub functions)\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\n\n# gatorPredict related paths\nimagePath = projectDir + '/image/exampleImage.tif'\nmarkerChannelMapPath = projectDir + '/markers.csv'\ngatorModelPath = projectDir + '/GATOR/gatorModel/'\n\n# Generate generateGatorScore related paths\nsegmentationPath = projectDir + '/segmentation/exampleSegmentationMask.tif'\n\n# gatorObject related paths\nspatialTablePath = projectDir + '/quantification/exampleSpatialTable.csv'\n\n# Run the pipeline\nga.gatorPipeline(   \n            # parameters for gatorPredict function\n            imagePath=imagePath,\n            gatorModelPath=gatorModelPath,\n            markerChannelMapPath=markerChannelMapPath,\n\n            # parameters for generateGatorScore function\n            segmentationMaskPath=segmentationPath,\n\n            # parameters for gatorObject function\n            spatialTablePath=spatialTablePath,\n\n            # parameters to run gator function\n            # ..\n\n            # common parameters\n            verbose=False,\n            projectDir=projectDir)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorPipeline.py                 --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif                 --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/                 --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv                 --segmentationMaskPath /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif                 --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv                 --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/gatorPipeline.py</code> <pre><code>def gatorPipeline (**kwargs):   \n\"\"\"\nParameters:\n    imagePath (str):  \n        The path to the .tif file that needs to be processed. \n\n    gatorModelPath (str):  \n        The path to the `gatorModel` folder. \n\n    markerChannelMapPath (str, optional):  \n        The path to the marker panel list, which contains information about the markers used in the image. This argument is required.\n\n    segmentationMaskPath (str):\n        Supply the path of the pre-computed segmentation mask.\n\n    spatialTablePath (list):\n        Provide a list of paths to the single-cell spatial feature tables, ensuring each image has a unique path specified.\n\n    projectDir (str):  \n        The path to the output directory where the processed images (`probabilityMasks`) will be saved.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n\n\n\n    markerColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the marker names. The default value is 'marker'.\n\n    channelColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the channel names. The default value is 'channel'.\n\n    modelColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the model names. The default value is 'gatormodel'.\n\n    GPU (int, optional):  \n        An optional argument to explicitly select the GPU to use. The default value is -1, meaning that the GPU will be selected automatically.\n\n\n\n\n\n    feature (str, optional):\n        Calculates the `mean` or `median` Gator Score for each cell.\n\n    markerNames (list, optional):\n        The program searches for marker names in the meta data (description section)\n        of the tiff files created by `gatorPredict` by default. If the meta data\n        is lost due to user modifications, provide the marker names for each\n        channel/layer in the `probabilityMaskPath` here.\n\n\n\n\n\n    CellId (str, optional):\n        Specify the column name that holds the cell ID (a unique name given to each cell).\n\n    uniqueCellId (bool, optional):\n        The function generates a unique name for each cell by combining the CellId and imageid.\n        If you don't want this, pass False. In such case the function will default to using just the CellId.\n        However, make sure CellId is unique especially when loading multiple images together.\n\n    split (string, optional):\n        The spatial feature table generally includes single cell expression data\n        and meta data such as X, Y coordinates, and cell shape size. The Gator\n        object separates them. Ensure that the expression data columns come first,\n        followed by meta data columns. Provide the column name that marks the split,\n        i.e the column name immediately following the expression data.\n\n    removeDNA (bool, optional):\n        Exclude DNA channels from the final output. The function searches for\n        column names containing the string `dna` or `dapi`. \n\n    remove_string_from_name (string, optional):\n        Cleans up channel names by removing user specified string from all marker\n        names.\n\n    gatorScore (str, optional):\n        Include the label used for saving the `gatorScore` within the Gator object.\n\n    minAbundance (float, optional):\n        Specify the minimum percentage of cells that should express a specific\n        marker in order to determine if the marker is considered a failure.\n        A good approach is to consider the lowest percentage of rare cells\n        expected within the dataset.\n\n    percentiles (list, optional):\n        Specify the interval of percentile levels of the expression utilized to intialize\n        the GMM. The cells falling within these percentiles are utilized to distinguish\n        between negative cells (first two values) and positive cells (last two values).\n\n    dropMarkers (list, optional):\n        Specify a list of markers to be removed from the analysis, for\n        example: `[\"background_channel1\", \"background_channel2\"]`. \n\n    RobustScale (bool, optional):\n        When set to True, the data will be subject to Robust Scaling before the\n        Gradient Boosting Classifier is trained. \n\n    log (bool, optional):\n        Apply `log1p` transformation on the data, unless it has already been log\n        transformed in which case set it to `False`. \n\n    stringentThreshold (bool, optional):\n        The Gaussian Mixture Model (GMM) is utilized to distinguish positive and \n        negative cells by utilizing gatorScores. The stringentThreshold can be utilized \n        to further refine the classification of positive and negative cells. \n        By setting it to True, cells with gatorScore below the mean of the negative \n        distribution and above the mean of the positive distribution will be \n        labeled as true negative and positive, respectively.\n\n    x_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        X coordinates for each cell. \n\n    y_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        Y coordinates for each cell.\n\n    imageid (str, optional):\n        The name of the column that holds the unique image ID. \n\n    random_state (int, optional):\n        Seed used by the random number generator. \n\n    rescaleMethod (string, optional):\n        Choose between `sigmoid` and `minmax`.\n\n    label (str, optional):\n        Assign a label for the object within `adata.uns` where the predictions\n        from Gator will be stored. \n\n\nReturns:\n    gatorObject (anndata):\n        Returns a gatorObject with predictions of all positve and negative cells. \n\nExample:\n\n        ```python\n\n        # Path to all the files that are necessary files for running the \n        Gator Prediction Algorithm (broken down based on sub functions)\n        projectDir = '/Users/aj/Desktop/gatorExampleData'\n\n        # gatorPredict related paths\n        imagePath = projectDir + '/image/exampleImage.tif'\n        markerChannelMapPath = projectDir + '/markers.csv'\n        gatorModelPath = projectDir + '/GATOR/gatorModel/'\n\n        # Generate generateGatorScore related paths\n        segmentationPath = projectDir + '/segmentation/exampleSegmentationMask.tif'\n\n        # gatorObject related paths\n        spatialTablePath = projectDir + '/quantification/exampleSpatialTable.csv'\n\n        # Run the pipeline\n        ga.gatorPipeline(   \n                    # parameters for gatorPredict function\n                    imagePath=imagePath,\n                    gatorModelPath=gatorModelPath,\n                    markerChannelMapPath=markerChannelMapPath,\n\n                    # parameters for generateGatorScore function\n                    segmentationMaskPath=segmentationPath,\n\n                    # parameters for gatorObject function\n                    spatialTablePath=spatialTablePath,\n\n                    # parameters to run gator function\n                    # ..\n\n                    # common parameters\n                    verbose=False,\n                    projectDir=projectDir)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gatorPipeline.py \\\n                --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif \\\n                --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ \\\n                --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv \\\n                --segmentationMaskPath /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif \\\n                --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv \\\n                --projectDir /Users/aj/Desktop/gatorExampleData\n        ```\n\n\n    \"\"\"\n\n    ##########################################################################\n    # STEP: 1 :- PREDICT\n    ##########################################################################\n    function1_args = inspect.signature(gatorPredict).parameters.keys()\n    # Extract only the arguments that gatorPredict expects from the keyword arguments\n    function1_kwargs = {k: kwargs[k] for k in kwargs if k in function1_args}\n    # Call gatorPredict with the extracted arguments\n    gatorPredict (**function1_kwargs)\n\n\n    ##########################################################################\n    # STEP: 2 :- generateGatorScore\n    ##########################################################################\n\n    # derive the probability mask path\n    probPath = pathlib.Path(kwargs['projectDir'] + '/GATOR/gatorPredict/')\n    fileName = os.path.basename(kwargs['imagePath'])\n    fileNamePrefix = fileName.split(os.extsep, 1)\n    probabilityMaskPath = str(probPath / (fileNamePrefix[0] + '_gatorPredict.ome.tif'))\n\n    # extract key words for generateGatorScore\n    function2_args = inspect.signature(generateGatorScore).parameters.keys()\n    function2_kwargs = {k: kwargs[k] for k in kwargs if k in function2_args}\n    generateGatorScore (probabilityMaskPath=probabilityMaskPath, **function2_kwargs)\n\n\n    ##########################################################################\n    # STEP: 3 :- Generate gatorObject\n    ##########################################################################\n\n    # derive the path to Gator scores\n    gPath = pathlib.Path(kwargs['projectDir'] + '/GATOR/gatorScore/')\n    file_name = pathlib.Path(probabilityMaskPath).stem + '.csv'\n    gatorScorePath = str(gPath / file_name)\n\n    # extract key words for gatorObject\n    function3_args = inspect.signature(gatorObject).parameters.keys()\n    function3_kwargs = {k: kwargs[k] for k in kwargs if k in function3_args}\n    gatorObject (gatorScorePath=gatorScorePath, **function3_kwargs)\n\n    ##########################################################################\n    # STEP: 4 :- Run Gator Algorithm\n    ##########################################################################\n\n    # derive the path to Gator object\n    oPath = pathlib.Path(kwargs['projectDir'] + '/GATOR/gatorObject/')\n    file_name = pathlib.Path(gatorScorePath).stem + '.h5ad'\n    gatorObjectPath = str(oPath / file_name)\n\n    # extract key words for running gator\n    function4_args = inspect.signature(gator).parameters.keys()\n    function4_kwargs = {k: kwargs[k] for k in kwargs if k in function4_args}    \n    gator (gatorObject=gatorObjectPath, **function4_kwargs)\n</code></pre>"},{"location":"Functions/gatorPredict/","title":"gatorPredict","text":"<p>Short Description</p> <p>The function <code>gatorPredict</code> is employed to make predictions about the  expression of a specified marker on cells in new images using the models  generated by <code>gatorTrain</code>. This calculation is done at the pixel level,  resulting in an output image where the number of channels corresponds to  the number of models applied to the input image. The parameter <code>markerChannelMapPath</code>  is used to associate the image channel number with the relevant model to be applied.</p>"},{"location":"Functions/gatorPredict/#gatorpy.gatorPredict--function","title":"Function","text":""},{"location":"Functions/gatorPredict/#gatorpy.gatorPredict.gatorPredict","title":"<code>gatorPredict(imagePath, gatorModelPath, projectDir, markerChannelMapPath, markerColumnName='marker', channelColumnName='channel', modelColumnName='gatormodel', verbose=True, GPU=-1)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>imagePath</code> <code>str</code> <p>The path to the .tif file that needs to be processed. </p> required <code>gatorModelPath</code> <code>str</code> <p>The path to the <code>gatorModel</code> folder. </p> required <code>projectDir</code> <code>str</code> <p>The path to the output directory where the processed images (<code>probabilityMasks</code>) will be saved.</p> required <code>markerChannelMapPath</code> <code>str</code> <p>The path to the marker panel list, which contains information about the markers used in the image. This argument is required.</p> required <code>markerColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the marker names. The default value is 'marker'.</p> <code>'marker'</code> <code>channelColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the channel names. The default value is 'channel'.</p> <code>'channel'</code> <code>modelColumnName</code> <code>str</code> <p>The name of the column in the marker panel list that contains the model names. The default value is 'gatormodel'.</p> <code>'gatormodel'</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>GPU</code> <code>int</code> <p>An optional argument to explicitly select the GPU to use. The default value is -1, meaning that the GPU will be selected automatically.</p> <code>-1</code> <p>Returns:</p> Type Description <p>Predicted Probability Masks (images): The result will be located at <code>projectDir/GATOR/gatorPredict/</code>.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\nimagePath = cwd + '/image/exampleImage.tif'\ngatorModelPath = cwd + '/GATOR/gatorModel/'\nprojectDir = cwd\nmarkerChannelMapPath = cwd + '/markers.csv'\n\n# Run the function\nga.gatorPredict( imagePath=imagePath,\n                 gatorModelPath=gatorModelPath,\n                 projectDir=projectDir, \n                 markerChannelMapPath=markerChannelMapPath, \n                 markerColumnName='marker', \n                 channelColumnName='channel', \n                 modelColumnName='gatormodel', \n                 verbose=True,\n                 GPU=-1)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorPredict.py --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ --projectDir /Users/aj/Desktop/gatorExampleData --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv\n</code></pre> Source code in <code>gatorpy/gatorPredict.py</code> <pre><code>def gatorPredict (imagePath,\n                 gatorModelPath,\n                 projectDir, \n                 markerChannelMapPath, \n                 markerColumnName='marker', \n                 channelColumnName='channel', \n                 modelColumnName='gatormodel', \n                 verbose=True,\n                 GPU=-1):\n\n\"\"\"\nParameters:\n    imagePath (str):  \n        The path to the .tif file that needs to be processed. \n\n    gatorModelPath (str):  \n        The path to the `gatorModel` folder. \n\n    projectDir (str):  \n        The path to the output directory where the processed images (`probabilityMasks`) will be saved.\n\n    markerChannelMapPath (str, optional):  \n        The path to the marker panel list, which contains information about the markers used in the image. This argument is required.\n\n    markerColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the marker names. The default value is 'marker'.\n\n    channelColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the channel names. The default value is 'channel'.\n\n    modelColumnName (str, optional):  \n        The name of the column in the marker panel list that contains the model names. The default value is 'gatormodel'.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    GPU (int, optional):  \n        An optional argument to explicitly select the GPU to use. The default value is -1, meaning that the GPU will be selected automatically.\n\nReturns:\n    Predicted Probability Masks (images):  \n        The result will be located at `projectDir/GATOR/gatorPredict/`.\n\nExample:\n\n    \t```python    \n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n        imagePath = cwd + '/image/exampleImage.tif'\n        gatorModelPath = cwd + '/GATOR/gatorModel/'\n        projectDir = cwd\n        markerChannelMapPath = cwd + '/markers.csv'\n\n        # Run the function\n        ga.gatorPredict( imagePath=imagePath,\n                         gatorModelPath=gatorModelPath,\n                         projectDir=projectDir, \n                         markerChannelMapPath=markerChannelMapPath, \n                         markerColumnName='marker', \n                         channelColumnName='channel', \n                         modelColumnName='gatormodel', \n                         verbose=True,\n                         GPU=-1)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python gatorPredict.py --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ --projectDir /Users/aj/Desktop/gatorExampleData --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv\n\n    \t```\n\n     \"\"\"\n\n    fileName = pathlib.Path(imagePath).stem\n\n    # read the markers.csv\n    maper = pd.read_csv(pathlib.Path(markerChannelMapPath))\n    columnnames =  [word.lower() for word in maper.columns]\n    maper.columns = columnnames\n\n    # identify the marker column name (doing this to make it easier for people who confuse between marker and markers)\n    if markerColumnName not in columnnames:\n           if markerColumnName != 'marker':\n               raise ValueError('markerColumnName not found in markerChannelMap, please check')\n           if 'markers' in columnnames:\n               markerCol = 'markers'\n           else:\n               raise ValueError('markerColumnName not found in markerChannelMap, please check')\n    else:\n           markerCol = markerColumnName\n\n\n   # identify the channel column name (doing this to make it easier for people who confuse between channel and channels)\n    if channelColumnName not in columnnames:\n        if channelColumnName != 'channel':\n            raise ValueError('channelColumnName not found in markerChannelMap, please check')\n        if 'channels' in columnnames:\n            channelCol = 'channels'\n        else:\n            raise ValueError('channelColumnName not found in markerChannelMap, please check')\n    else:\n        channelCol = channelColumnName\n\n\n    # identify the gator model column name (doing this to make it easier for people who confuse between gatormodel and gatormodels)\n    if modelColumnName not in columnnames:\n        if modelColumnName != 'gatormodel':\n            raise ValueError('modelColumnName not found in markerChannelMap, please check')\n        if 'gatormodels' in columnnames:\n            channelCol = 'gatormodels'\n        else:\n            raise ValueError('modelColumnName not found in markerChannelMap, please check')\n    else:\n        modelCol = modelColumnName\n\n    # remove rowa that have nans in modelCol\n    runMenu = maper.dropna(subset=[modelCol], inplace=False)[[channelCol,markerCol,modelCol]]\n\n    # shortcuts\n    numMarkers = len(runMenu)\n    len(runMenu.columns)\n\n    I = skio.imread(imagePath, img_num=0, plugin='tifffile')\n\n\n    probPath = pathlib.Path(projectDir + '/GATOR/gatorPredict/')\n    modelPath = pathlib.Path(gatorModelPath)\n\n    if not os.path.exists(probPath):\n        os.makedirs(probPath,exist_ok=True)\n\n\n\n\n    def data(runMenu, \n             imagePath, \n             modelPath, \n             projectDir, \n             dsFactor=1, \n             GPU=0):\n\n        # Loop through the rows of the DataFrame\n        for index, row in runMenu.iterrows():\n            channel = row[channelColumnName]\n            markerName = row[markerColumnName]\n            gatormodel = row[modelColumnName]\n            if verbose is True:\n                print('Running gator model ' + str(gatormodel) + ' on channel ' + str(channel) + ' corresponding to marker ' + str(markerName) )\n\n\n            tf.reset_default_graph()\n            UNet2D.singleImageInferenceSetup(pathlib.Path(modelPath / gatormodel), GPU, -1, -1)\n\n            fileName = os.path.basename(imagePath)\n            fileNamePrefix = fileName.split(os.extsep, 1)\n            fileType = fileNamePrefix[1]\n            if fileType == 'ome.tif' or fileType == 'ome.tiff' or fileType == 'btf':\n                I = skio.imread(imagePath, img_num=int(channel-1), plugin='tifffile')\n            elif fileType == 'tif':\n                I = tifffile.imread(imagePath, key=int(channel-1))\n\n            if I.dtype == 'float32':\n                I=np.uint16(I)\n            rawVert = I.shape[0]\n            rawHorz = I.shape[1]\n            rawI = I\n\n            hsize = int(float(rawVert * float(dsFactor)))\n            vsize = int(float(rawHorz * float(dsFactor)))\n            # I = resize(I, (hsize, vsize))\n            cells = I\n            maxLimit = np.max(I)\n            I=I/65535*255\n\n            rawI = im2double(rawI) / np.max(im2double(rawI))\n\n            append_kwargs = {\n                'bigtiff': True,\n                'metadata': None,\n                'append': True,\n            }\n            save_kwargs = {\n                'bigtiff': True,\n                'metadata': None,\n                'append': False,\n            }\n\n            PM = np.uint8(255 * UNet2D.singleImageInference(I, 'accumulate',1))\n            PM = resize(PM, (rawVert, rawHorz))\n            yield np.uint8(255 * PM)\n\n    with tifffile.TiffWriter(probPath / (fileName + '_gatorPredict.ome.tif')) as tiff:\n        tiff.write(data(runMenu, imagePath, modelPath, probPath, dsFactor=1, GPU=0), shape=(numMarkers,I.shape[0],I.shape[1]), dtype='uint8', metadata={'Channel': {'Name': runMenu.marker.tolist()}, 'axes': 'CYX'})\n\n        UNet2D.singleImageInferenceCleanup()\n</code></pre>"},{"location":"Functions/gatorTrain/","title":"gatorTrain","text":"<p>Short Description</p> <p>The function trains a deep learning model for each marker in the provided  training data. To train the <code>gatorModel</code>, simply direct the function to the  <code>TrainingData</code> folder. To train only specific models, specify the folder names  using the <code>trainMarkers</code> parameter. The <code>projectDir</code> remains constant and the  program will automatically create subfolders to save the trained models.</p>"},{"location":"Functions/gatorTrain/#gatorpy.gatorTrain--function","title":"Function","text":""},{"location":"Functions/gatorTrain/#gatorpy.gatorTrain.gatorTrain","title":"<code>gatorTrain(trainingDataPath, projectDir, trainMarkers=None, artefactPath=None, imSize=64, nChannels=1, nClasses=2, nExtraConvs=0, nLayers=3, featMapsFact=2, downSampFact=2, ks=3, nOut0=16, stdDev0=0.03, batchSize=16, epochs=100, verbose=True)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>trainingDataPath</code> <code>str</code> <p>The file path leading to the directory that holds the training data.</p> required <code>projectDir</code> <code>str</code> <p>Path to output directory. The result will be located at <code>projectDir/GATOR/gatorModel/</code>.</p> required <code>trainMarkers</code> <code>list</code> <p>Generate models for a specified list of markers. By default, models are c reated for all data in the TrainingData folder. If the user wants to limit it to a specific list, they can pass in the folder names (e.g. ['CD3D', 'CD4'])</p> <code>None</code> <code>artefactPath</code> <code>str</code> <p>Path to the directory where the artefacts data is loaded from.</p> <code>None</code> <code>imSize</code> <code>int</code> <p>Image size (assumed to be square).</p> <code>64</code> <code>nChannels</code> <code>int</code> <p>Number of channels in the input image.</p> <code>1</code> <code>nClasses</code> <code>int</code> <p>Number of classes in the classification problem.</p> <code>2</code> <code>nExtraConvs</code> <code>int</code> <p>Number of extra convolutional layers to add to the model.</p> <code>0</code> <code>nLayers</code> <code>int</code> <p>Total number of layers in the model.</p> <code>3</code> <code>featMapsFact</code> <code>int</code> <p>Factor to multiply the number of feature maps by in each layer.</p> <code>2</code> <code>downSampFact</code> <code>int</code> <p>Factor to down-sample the feature maps by in each layer.</p> <code>2</code> <code>ks</code> <code>int</code> <p>Kernel size for the convolutional layers.</p> <code>3</code> <code>nOut0</code> <code>int</code> <p>Number of filters in the first layer.</p> <code>16</code> <code>stdDev0</code> <code>float</code> <p>Standard deviation for the initializer for the first layer.</p> <code>0.03</code> <code>batchSize</code> <code>int</code> <p>Batch size for training.</p> <code>16</code> <code>epochs</code> <code>int</code> <p>Number of training epochs.</p> <code>100</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <p>Returns:</p> Name Type Description <code>Model</code> <code>images and model</code> <p>The result will be located at <code>projectDir/GATOR/gatorModel/</code>.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\ntrainingDataPath = cwd + '/GATOR/TrainingData'\nprojectDir = cwd\n\n# Run the Function\nga.gatorTrain(trainingDataPath=trainingDataPath,\n               projectDir=projectDir,\n               trainMarkers=None,\n               artefactPath=None,\n               imSize=64,\n               nChannels=1,\n               nClasses=2,\n               nExtraConvs=0,\n               nLayers=3,\n               featMapsFact=2,\n               downSampFact=2,\n               ks=3,\n               nOut0=16,\n               stdDev0=0.03,\n               batchSize=16,\n               epochs=1)\n\n# Same function if the user wants to run it via Command Line Interface\npython gatorTrain.py --trainingDataPath /Users/aj/Desktop/gatorExampleData/GATOR/TrainingData --projectDir /Users/aj/Desktop/gatorExampleData/ --epochs 1\n</code></pre> Source code in <code>gatorpy/gatorTrain.py</code> <pre><code>def gatorTrain(trainingDataPath,\n               projectDir,\n               trainMarkers=None,\n               artefactPath=None,\n               imSize=64,\n               nChannels=1,\n               nClasses=2,\n               nExtraConvs=0,\n               nLayers=3,\n               featMapsFact=2,\n               downSampFact=2,\n               ks=3,\n               nOut0=16,\n               stdDev0=0.03,\n               batchSize=16,\n               epochs=100,\n               verbose=True):\n\"\"\"\n\nParameters:\n    trainingDataPath (str):\n        The file path leading to the directory that holds the training data.\n\n    projectDir (str):\n        Path to output directory. The result will be located at `projectDir/GATOR/gatorModel/`.\n\n    trainMarkers (list):\n        Generate models for a specified list of markers. By default, models are c\n        reated for all data in the TrainingData folder. If the user wants to\n        limit it to a specific list, they can pass in the folder names (e.g. ['CD3D', 'CD4'])\n\n    artefactPath (str):\n        Path to the directory where the artefacts data is loaded from.\n\n    imSize (int, optional):\n        Image size (assumed to be square).\n\n    nChannels (int, optional):\n        Number of channels in the input image.\n\n    nClasses (int, optional):\n        Number of classes in the classification problem.\n\n    nExtraConvs (int, optional):\n        Number of extra convolutional layers to add to the model.\n\n    nLayers (int, optional):\n        Total number of layers in the model.\n\n    featMapsFact (int, optional):\n        Factor to multiply the number of feature maps by in each layer.\n\n    downSampFact (int, optional):\n        Factor to down-sample the feature maps by in each layer.\n\n    ks (int, optional):\n        Kernel size for the convolutional layers.\n\n    nOut0 (int, optional):\n        Number of filters in the first layer.\n\n    stdDev0 (float, optional):\n        Standard deviation for the initializer for the first layer.\n\n    batchSize (int, optional):\n        Batch size for training.\n\n    epochs (int, optional):\n        Number of training epochs.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\nReturns:\n\n    Model (images and model):  \n        The result will be located at `projectDir/GATOR/gatorModel/`.\n\n\nExample:\n\n    ```python\n\n    # set the working directory &amp; set paths to the example data\n    cwd = '/Users/aj/Desktop/gatorExampleData'\n    trainingDataPath = cwd + '/GATOR/TrainingData'\n    projectDir = cwd\n\n    # Run the Function\n    ga.gatorTrain(trainingDataPath=trainingDataPath,\n                   projectDir=projectDir,\n                   trainMarkers=None,\n                   artefactPath=None,\n                   imSize=64,\n                   nChannels=1,\n                   nClasses=2,\n                   nExtraConvs=0,\n                   nLayers=3,\n                   featMapsFact=2,\n                   downSampFact=2,\n                   ks=3,\n                   nOut0=16,\n                   stdDev0=0.03,\n                   batchSize=16,\n                   epochs=1)\n\n    # Same function if the user wants to run it via Command Line Interface\n    python gatorTrain.py --trainingDataPath /Users/aj/Desktop/gatorExampleData/GATOR/TrainingData --projectDir /Users/aj/Desktop/gatorExampleData/ --epochs 1\n\n    ```\n\n\n    \"\"\"\n\n    # Start here\n    # convert to path\n    trainingDataPath = pathlib.Path(trainingDataPath)\n    # identify all the data folders within the given TrainingData folder\n    directories = [x for x in trainingDataPath.iterdir() if x.is_dir()]\n    # keep only folders that the user have requested\n    if trainMarkers is not None:\n        if isinstance(trainMarkers, str):\n            trainMarkers = [trainMarkers]\n        directories = [x for x in directories if x.stem in trainMarkers]\n\n    # optional artifacts\n    if artefactPath is not None:\n        artefactPath = pathlib.Path(artefactPath)\n        artefactTrainPath = pathlib.Path(artefactPath / 'training')\n        artefactValidPath = pathlib.Path(artefactPath / 'validation')\n    else:\n        artefactPath = ''\n        artefactTrainPath = ''\n        artefactValidPath = ''\n    # Need to run the training for each marker\n\n    def gatorTrainInternal(trainingDataPath,\n                           projectDir,\n                           artefactPath,\n                           imSize,\n                           nChannels,\n                           nClasses,\n                           nExtraConvs,\n                           nLayers,\n                           featMapsFact,\n                           downSampFact,\n                           ks,\n                           nOut0,\n                           stdDev0,\n                           batchSize,\n                           epochs):\n        # process the file name\n        finalName = trainingDataPath.stem\n\n        # paths for loading data\n        trainPath = pathlib.Path(trainingDataPath / 'training')\n        validPath = pathlib.Path(trainingDataPath / 'validation')\n        testPath = pathlib.Path(trainingDataPath / 'test')\n\n        # Paths for saving data\n        logPath = pathlib.Path(\n            projectDir + '/GATOR/gatorTrain/' + finalName + '/tempTFLogs/')\n        modelPath = pathlib.Path(projectDir + '/GATOR/gatorModel/' + finalName)\n        pmPath = pathlib.Path(projectDir + '/GATOR/gatorTrain/' +\n                              finalName + '/TFprobMaps/')\n\n        # set up the model\n        UNet2D.setup(imSize=imSize,\n                     nClasses=nClasses,\n                     nChannels=nChannels,\n                     nExtraConvs=nExtraConvs,\n                     nDownSampLayers=nLayers,\n                     featMapsFact=featMapsFact,\n                     downSampFact=downSampFact,\n                     kernelSize=ks,\n                     nOut0=nOut0,\n                     stdDev0=stdDev0,\n                     batchSize=batchSize)\n\n        # train the model\n        UNet2D.train(trainPath=trainPath,\n                     validPath=validPath,\n                     testPath=testPath,\n                     artTrainPath=artefactTrainPath,\n                     artValidPath=artefactValidPath,\n                     logPath=logPath,\n                     modelPath=modelPath,\n                     pmPath=pmPath,\n                     restoreVariables=False,\n                     nSteps=epochs,\n                     gpuIndex=0,\n                     testPMIndex=2)\n\n    # Run the function on all markers\n    def r_gatorTrainInternal(x): return gatorTrainInternal(trainingDataPath=x,\n                                                           projectDir=projectDir,\n                                                           artefactPath=artefactPath,\n                                                           imSize=imSize,\n                                                           nChannels=nChannels,\n                                                           nClasses=nClasses,\n                                                           nExtraConvs=nExtraConvs,\n                                                           nLayers=nLayers,\n                                                           featMapsFact=featMapsFact,\n                                                           downSampFact=downSampFact,\n                                                           ks=ks,\n                                                           nOut0=nOut0,\n                                                           stdDev0=stdDev0,\n                                                           batchSize=batchSize,\n                                                           epochs=epochs)\n\n    gatorTrainInternal_result = list(\n        map(r_gatorTrainInternal,  directories))  # Apply function\n\n    # Finish Job\n    if verbose is True:\n        print('Gator Models have been generated, head over to \"' + str(projectDir) + '/GATOR/gatorModel\" to view results')\n</code></pre>"},{"location":"Functions/generateGatorScore/","title":"generateGatorScore","text":"<p>Short Description</p> <p>The <code>generateGatorScore</code> function calculates <code>Gator Score</code> for each cell by using  both the generated probability masks and pre-computed segmentation masks as inputs</p>"},{"location":"Functions/generateGatorScore/#gatorpy.generateGatorScore--function","title":"Function","text":""},{"location":"Functions/generateGatorScore/#gatorpy.generateGatorScore.generateGatorScore","title":"<code>generateGatorScore(probabilityMaskPath, segmentationMaskPath, feature='median', verbose=True, markerNames=None, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>probabilityMaskPath</code> <code>str</code> <p>Supply the path of the probability map image produced by <code>dlModelPredict</code>.</p> required <code>segmentationMaskPath</code> <code>str</code> <p>Supply the path of the pre-computed segmentation mask.</p> required <code>feature</code> <code>str</code> <p>Calculates the <code>mean</code> or <code>median</code> Gator Score for each cell.</p> <code>'median'</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>markerNames</code> <code>list</code> <p>The program searches for marker names in the meta data (description section) of the tiff files created by <code>gatorPredict</code> by default. If the meta data is lost due to user modifications, provide the marker names for each channel/layer in the <code>probabilityMaskPath</code> here.</p> <code>None</code> <code>projectDir</code> <code>str</code> <p>Provide the path to the output directory. The result will be located at <code>projectDir/GATOR/gatorScore/</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>CSV</code> <code>dataframe</code> <p>The <code>.csv</code> file containing the <code>gatorScore</code> is stored in the provided projectDir.</p> Example <pre><code># global path\ncwd = '/Users/aj/Desktop/gatorExampleData'\n\n# function specific paths\nprobabilityMaskPath = cwd + '/GATOR/gatorPredict/exampleImage_gatorPredict.ome.tif'\nsegmentationPath = cwd + '/segmentation/exampleSegmentationMask.tif'\n\nga.generateGatorScore (probabilityMaskPath=probabilityMaskPath,\n             segmentationMaskPath=segmentationPath,\n             feature='median',\n             verbose=True,\n             projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython generateGatorScore.py --probabilityMaskPath /Users/aj/Desktop/gatorExampleData/dlPredict/exampleProbabiltyMap.ome.tif --segmentationMaskPath /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif --markerNames ECAD CD45 CD4 CD3D CD8A CD45R Ki67 --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre> Source code in <code>gatorpy/generateGatorScore.py</code> <pre><code>def generateGatorScore (probabilityMaskPath,\n                         segmentationMaskPath,\n                         feature='median',\n                         verbose=True,\n                         markerNames=None,\n                         projectDir=None):\n\n\"\"\"\nParameters:\n    probabilityMaskPath (str):\n        Supply the path of the probability map image produced by `dlModelPredict`.\n\n    segmentationMaskPath (str):\n        Supply the path of the pre-computed segmentation mask.\n\n    feature (str, optional):\n        Calculates the `mean` or `median` Gator Score for each cell.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    markerNames (list, optional):\n        The program searches for marker names in the meta data (description section)\n        of the tiff files created by `gatorPredict` by default. If the meta data\n        is lost due to user modifications, provide the marker names for each\n        channel/layer in the `probabilityMaskPath` here.\n\n    projectDir (str, optional):\n        Provide the path to the output directory. The result will be located at\n        `projectDir/GATOR/gatorScore/`.\n\nReturns:\n    CSV (dataframe):\n        The `.csv` file containing the `gatorScore` is stored in the provided projectDir.\n\nExample:\n\n        ```python\n\n        # global path\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n\n        # function specific paths\n        probabilityMaskPath = cwd + '/GATOR/gatorPredict/exampleImage_gatorPredict.ome.tif'\n        segmentationPath = cwd + '/segmentation/exampleSegmentationMask.tif'\n\n        ga.generateGatorScore (probabilityMaskPath=probabilityMaskPath,\n                     segmentationMaskPath=segmentationPath,\n                     feature='median',\n                     verbose=True,\n                     projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python generateGatorScore.py --probabilityMaskPath /Users/aj/Desktop/gatorExampleData/dlPredict/exampleProbabiltyMap.ome.tif --segmentationMaskPath /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif --markerNames ECAD CD45 CD4 CD3D CD8A CD45R Ki67 --projectDir /Users/aj/Desktop/gatorExampleData/\n\n        ```\n\n    \"\"\"\n\n\n    #probabilityMask = '/Users/aj/Dropbox (Partners HealthCare)/Data/gator/data/ajn_training_data/GATOR/dlPredict/6_GatorOutput.ome.tif'\n    #segmentationMaskPath = '/Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif'\n    #projectDir = '/Users/aj/Desktop/gatorExampleData'\n    #markerNames = ['ECAD', 'CD45', 'CD4', 'CD3D', 'CD8A', 'CD45_2', 'KI67']\n    #probQuant (probabilityMask, segmentationMaskPath,  feature='median', markerNames=markerNames, projectDir=projectDir)\n\n    # read the seg mask\n    segM = tifffile.imread(pathlib.Path(segmentationMaskPath))\n    probM = tifffile.imread(pathlib.Path(probabilityMaskPath))\n\n    #probs = []\n    #for i in range(len(probM)):\n    #    pospix = len(probM[i][(probM[i] / 255) &gt; 0.5]) / (probM[i].shape[0] * probM[i].shape[1])\n    #    probs.append(pospix)\n\n    if len(probM.shape) &gt; 2:\n        probM = np.moveaxis(probM, 0, -1)\n\n    def median_intensity(mask, img):\n        return np.median(img[mask])\n\n    # quantify\n    if verbose is True:\n        print(\"Quantifying the probability masks\")\n    quantTable = pd.DataFrame(measure.regionprops_table(segM, intensity_image=probM,\n                                                        properties=['label','mean_intensity'],\n                                                        extra_properties=[median_intensity])).set_index('label')\n\n    # keep only median\n    if feature == 'median':\n        quantTable = quantTable.filter(regex='median')\n    if feature == 'mean':\n        quantTable = quantTable.filter(regex='mean')\n\n    # read the channel names from the tiffile\n    tiff = tifffile.TiffFile(probabilityMaskPath)\n    try:\n        root = ET.fromstring(tiff.pages[0].description)\n        # parse the ome XML\n        namespace = None\n        for elem in root.iter():\n            if \"Channel\" in elem.tag:\n                namespace = {\"ome\": elem.tag.split(\"}\")[0][1:]}\n                break\n        channel_names = [channel.get(\"Name\") for channel in root.findall(\".//ome:Channel\", namespace)]\n        quantTable.columns = channel_names\n        #omexml_string = ast.literal_eval(tiff.pages[0].description)\n        #channel_names = omexml_string['Channel']['Name']\n    except:\n        pass\n    if markerNames is not None:\n        channel_names = markerNames\n    else:\n        channel_names = list(quantTable.columns)\n\n    # assign channel names\n    quantTable.columns = channel_names\n\n    # build a division vector\n    # this is to make sure the low probs are not amplified; chosing 154 as it is 0.6P\n    #div_val = []\n    #for i in quantTable.columns:\n    #    div_val.append(255 if quantTable[i].max() &lt; 154 else  quantTable[i].max())\n\n    # conver to prob\n    #quantTable = quantTable / div_val\n    quantTable = quantTable / 255\n\n    # identify markers that failed\n    #sns.distplot(quantTable['ECAD'])\n\n\n    # if projectDir is given\n    if projectDir is None:\n        projectDir = os.getcwd()\n\n    # final path to save results\n    finalPath = pathlib.Path(projectDir + '/GATOR/gatorScore/')\n    if not os.path.exists(finalPath):\n        os.makedirs(finalPath)\n\n    # file name\n    file_name = pathlib.Path(probabilityMaskPath).stem + '.csv'\n    quantTable.to_csv(finalPath / file_name)\n\n    # Finish Job\n    if verbose is True:\n        print('gatorScore is ready, head over to' + str(projectDir) + '/GATOR/gatorScore\" to view results')\n</code></pre>"},{"location":"Functions/generateThumbnails/","title":"generateThumbnails","text":"<p>Short Description</p> <p>The <code>generateThumbnails</code> function generates Thumbnails of positive and  negative cells for a specified marker. The Thumbnails will be used to train a deep learning model. Make sure to have  the raw image, computed single-cell spatial table, and markers.csv file  ready for input.</p>"},{"location":"Functions/generateThumbnails/#gatorpy.generateThumbnails--function","title":"Function","text":""},{"location":"Functions/generateThumbnails/#gatorpy.generateThumbnails.generateThumbnails","title":"<code>generateThumbnails(spatialTablePath, imagePath, markerChannelMapPath, markers, markerColumnName='marker', channelColumnName='channel', transformation=True, maxThumbnails=2000, random_state=0, localNorm=True, globalNorm=False, x_coordinate='X_centroid', y_coordinate='Y_centroid', percentiles=[2, 12, 88, 98], windowSize=64, restrictDensity=True, restrictDensityNumber=None, verbose=True, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>spatialTablePath</code> <code>str</code> <p>Path to the single-cell spatial feature matrix.</p> required <code>imagePath</code> <code>str</code> <p>Path to the image file. Recognizes <code>.ome.tif</code> image file.</p> required <code>markerChannelMapPath</code> <code>str</code> <p>Path to a <code>markers.csv</code> file that maps the channel number with the marker information.  Create a .csv file with at least two columns named 'channel' and 'marker' that  map the channel numbers to their corresponding markers. The channel number  should use 1-based indexing.</p> required <code>markers</code> <code>list</code> <p>Markers for which <code>Thumbnails</code> need to be generated. The function looks for these listed names in the <code>single-cell spatial Table</code>.</p> required <code>markerColumnName</code> <code>str</code> <p>The name of the column in the <code>markers.csv</code> file that holds the marker information. </p> <code>'marker'</code> <code>channelColumnName</code> <code>str</code> <p>The name of the column in the <code>markers.csv</code> file that holds the channel information.  </p> <code>'channel'</code> <code>transformation</code> <code>bool</code> <p>Performs <code>arcsinh</code> transformation on the data. If the <code>single-cell spatial table</code> is already transformed (like log transformation), set this to <code>False</code>.</p> <code>True</code> <code>maxThumbnails</code> <code>int</code> <p>Maximum number of Thumbnails to generate. </p> <code>2000</code> <code>random_state</code> <code>int</code> <p>Seed used by the random number generator.</p> <code>0</code> <code>localNorm</code> <code>bool</code> <p>It creates a duplicate folder of the Thumbnails, with local normalization performed on the images. Local normalization is the process of dividing each pixel in a thumbnail by the maximum value across the entire thumbnail. This is helpful for visual supervised sorting of the Thumbnails.</p> <code>True</code> <code>globalNorm</code> <code>bool</code> <p>It creates a duplicate folder of the Thumbnails, with global normalization performed on the images. Global normalization is the process of dividing each pixel in a thumbnail by the maximum value of the given marker across the entire image.</p> <code>False</code> <code>x_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the X coordinates for each cell.</p> <code>'X_centroid'</code> <code>y_coordinate</code> <code>str</code> <p>The column name in <code>single-cell spatial table</code> that records the Y coordinates for each cell.</p> <code>'Y_centroid'</code> <code>percentiles</code> <code>list</code> <p>Specify the interval of percentile levels of the expression utilized to intialize the GMM. The cells falling within these percentiles are utilized to distinguish between negative cells (first two values) and positive cells (last two values).</p> <code>[2, 12, 88, 98]</code> <code>windowSize</code> <code>int</code> <p>Size of the Thumbnails.</p> <code>64</code> <code>restrictDensity</code> <code>bool</code> <p>This parameter is utilized to regulate the number of positive cells  observed in a given field of view. In the case of markers that do not  exhibit a distinct spatial pattern, such as immune cells, it is  recommended to train the model using sparse cells in the field of view.</p> <code>True</code> <code>restrictDensityNumber</code> <code>int</code> <p>This parameter is employed in conjunction with <code>restrictDensity</code>.  By default, the program attempts to automatically identify less dense  regions when restrictDensity is set to <code>True</code> using a GMM approach.  However, <code>restrictDensityNumber</code> can be utilized to exert greater  control over the process, allowing the user to limit the number of  positive cells they wish to observe within the field of view.  This parameter requires integers.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console.  </p> <code>True</code> <code>projectDir</code> <code>string</code> <p>Path to output directory. The result will be located at <code>projectDir/GATOR/Thumbnails/</code>.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Thumbnails</code> <code>image</code> <p>Saves Thumbnails of auto identified postive and negative cells the designated output directory.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\nimagePath = cwd + '/image/exampleImage.tif'\nspatialTablePath = cwd + '/quantification/exampleSpatialTable.csv'\nmarkerChannelMapPath = cwd + '/markers.csv'\n\n# Run the function\nga.generateThumbnails ( spatialTablePath=spatialTablePath, \n                imagePath=imagePath, \n                markerChannelMapPath=markerChannelMapPath,\n                markers=[\"ECAD\", \"CD3D\"], \n                markerColumnName='marker',\n                channelColumnName='channel',\n                transformation=True, \n                maxThumbnails=100, \n                random_state=0,\n                localNorm=True, \n                globalNorm=False,\n                x_coordinate='X_centroid', \n                y_coordinate='Y_centroid',\n                percentiles=[2, 12, 88, 98], \n                windowSize=64,\n                restrictDensity=True,\n                restrictDensityNumber=None,\n                verbose=True,\n                projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython generateThumbnails.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv --markers ECAD CD3D --maxThumbnails 100 --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre> Source code in <code>gatorpy/generateThumbnails.py</code> <pre><code>def generateThumbnails (spatialTablePath, \n                        imagePath, \n                        markerChannelMapPath,\n                        markers, \n                        markerColumnName='marker',\n                        channelColumnName='channel',\n                        transformation=True, \n                        maxThumbnails=2000, \n                        random_state=0,\n                        localNorm=True, \n                        globalNorm=False,\n                        x_coordinate='X_centroid', \n                        y_coordinate='Y_centroid',\n                        percentiles=[2, 12, 88, 98], \n                        windowSize=64,\n                        restrictDensity=True,\n                        restrictDensityNumber=None,\n                        verbose=True,\n                        projectDir=None):\n\"\"\"\nParameters:\n\n    spatialTablePath (str):\n        Path to the single-cell spatial feature matrix.\n\n    imagePath (str):\n        Path to the image file. Recognizes `.ome.tif` image file.\n\n    markerChannelMapPath (str):\n        Path to a `markers.csv` file that maps the channel number with the marker information. \n        Create a .csv file with at least two columns named 'channel' and 'marker' that \n        map the channel numbers to their corresponding markers. The channel number \n        should use 1-based indexing.\n\n    markers (list):\n        Markers for which `Thumbnails` need to be generated. The function looks for\n        these listed names in the `single-cell spatial Table`.\n\n    markerColumnName (str):\n        The name of the column in the `markers.csv` file that holds the marker information. \n\n    channelColumnName (str):\n        The name of the column in the `markers.csv` file that holds the channel information.  \n\n    transformation (bool, optional):\n        Performs `arcsinh` transformation on the data. If the `single-cell spatial table`\n        is already transformed (like log transformation), set this to `False`.\n\n    maxThumbnails (int, optional):\n        Maximum number of Thumbnails to generate. \n\n    random_state (int, optional):\n        Seed used by the random number generator.\n\n    localNorm (bool, optional):\n        It creates a duplicate folder of the Thumbnails, with local normalization\n        performed on the images. Local normalization is the process of dividing\n        each pixel in a thumbnail by the maximum value across the entire thumbnail.\n        This is helpful for visual supervised sorting of the Thumbnails.\n\n    globalNorm (bool, optional):\n        It creates a duplicate folder of the Thumbnails, with global normalization\n        performed on the images. Global normalization is the process of dividing\n        each pixel in a thumbnail by the maximum value of the given marker across\n        the entire image.\n\n    x_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        X coordinates for each cell.\n\n    y_coordinate (str, optional):\n        The column name in `single-cell spatial table` that records the\n        Y coordinates for each cell.\n\n    percentiles (list, optional):\n        Specify the interval of percentile levels of the expression utilized to intialize\n        the GMM. The cells falling within these percentiles are utilized to distinguish\n        between negative cells (first two values) and positive cells (last two values).\n\n    windowSize (int, optional):\n        Size of the Thumbnails.\n\n    restrictDensity (bool, optional):\n        This parameter is utilized to regulate the number of positive cells \n        observed in a given field of view. In the case of markers that do not \n        exhibit a distinct spatial pattern, such as immune cells, it is \n        recommended to train the model using sparse cells in the field of view.\n\n    restrictDensityNumber (int, optional):\n        This parameter is employed in conjunction with `restrictDensity`. \n        By default, the program attempts to automatically identify less dense \n        regions when restrictDensity is set to `True` using a GMM approach. \n        However, `restrictDensityNumber` can be utilized to exert greater \n        control over the process, allowing the user to limit the number of \n        positive cells they wish to observe within the field of view. \n        This parameter requires integers.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console.  \n\n    projectDir (string, optional):\n        Path to output directory. The result will be located at\n        `projectDir/GATOR/Thumbnails/`.\n\nReturns:\n    Thumbnails (image):\n        Saves Thumbnails of auto identified postive and negative cells the\n        designated output directory.\n\nExample:\n\n        ```python\n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n        imagePath = cwd + '/image/exampleImage.tif'\n        spatialTablePath = cwd + '/quantification/exampleSpatialTable.csv'\n        markerChannelMapPath = cwd + '/markers.csv'\n\n        # Run the function\n        ga.generateThumbnails ( spatialTablePath=spatialTablePath, \n                        imagePath=imagePath, \n                        markerChannelMapPath=markerChannelMapPath,\n                        markers=[\"ECAD\", \"CD3D\"], \n                        markerColumnName='marker',\n                        channelColumnName='channel',\n                        transformation=True, \n                        maxThumbnails=100, \n                        random_state=0,\n                        localNorm=True, \n                        globalNorm=False,\n                        x_coordinate='X_centroid', \n                        y_coordinate='Y_centroid',\n                        percentiles=[2, 12, 88, 98], \n                        windowSize=64,\n                        restrictDensity=True,\n                        restrictDensityNumber=None,\n                        verbose=True,\n                        projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python generateThumbnails.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv --markers ECAD CD3D --maxThumbnails 100 --projectDir /Users/aj/Desktop/gatorExampleData/\n\n        ```\n    \"\"\"\n\n    # transformation=True; maxThumbnails=100; x_coordinate='X_centroid'; y_coordinate='Y_centroid'; percentiles=[2, 12, 88, 98]; windowSize=64; random_state=0; localNorm=True; globalNorm=False; markerColumnName='marker'; channelColumnName='channel';projectDir=cwd; restrictDensity=True;restrictDensityNumber=None;verbose=True;\n    # markers = ['CD3D', 'CD8A']\n    # marker = 'CD3D';\n    # imagePath = '/Users/aj/Desktop/gatorExampleData/image/exampleImage.tif'\n    # spatialTablePath = '/Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv'\n    # markerChannelMapPath = '/Users/aj/Desktop/gatorExampleData/markers.csv'\n    # projectDir = '/Users/aj/Desktop/gatorExampleData/'\n\n    # read the markers.csv\n    maper = pd.read_csv(pathlib.Path(markerChannelMapPath))\n    columnnames =  [word.lower() for word in maper.columns]\n    maper.columns = columnnames\n\n    # identify the marker column name (doing this to make it easier for people who confuse between marker and markers)\n    if markerColumnName not in columnnames:\n        if markerColumnName != 'marker':\n            raise ValueError('markerColumnName not found in markerChannelMap, please check')\n        if 'markers' in columnnames:\n            markerCol = 'markers'\n        else:\n            raise ValueError('markerColumnName not found in markerChannelMap, please check')\n    else: \n        markerCol = markerColumnName\n\n    # identify the channel column name (doing this to make it easier for people who confuse between channel and channels)\n    if channelColumnName not in columnnames:\n        if channelColumnName != 'channel':\n            raise ValueError('channelColumnName not found in markerChannelMap, please check')\n        if 'channels' in columnnames:\n            channelCol = 'channels'\n        else:\n            raise ValueError('channelColumnName not found in markerChannelMap, please check')\n    else: \n        channelCol = channelColumnName\n\n    # map the marker and channels\n    chmamap = dict(zip(maper[markerCol], maper[channelCol]))\n\n    # load the CSV to identify potential thumbnails\n    data = pd.read_csv(pathlib.Path(spatialTablePath))\n    #data.index = data.index.astype(str)\n\n    # subset the markers of interest\n    if isinstance (markers, str):\n        markers = [markers]\n\n    # find the corresponding channel names\n    markerChannels = [chmamap[key] for key in markers if key in chmamap]\n    # convert markerChannels to zero indexing\n    markerChannels = [x-1 for x in markerChannels]\n\n    # creat a dict of marker and corresponding marker channel\n    marker_map = dict(zip(markers,markerChannels))\n\n    # create folders if it does not exist\n    if projectDir is None:\n        projectDir = os.getcwd()\n\n    # TruePos folders\n    for i in markers:\n        pos_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(i) + '/TruePos')\n        neg_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(i) + '/TrueNeg')\n        pos2neg_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(i) + '/PosToNeg')\n        neg2pos_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(i) + '/NegToPos')\n        if not os.path.exists(pos_path):\n            os.makedirs(pos_path)\n        if not os.path.exists(neg_path):\n            os.makedirs(neg_path)\n        if not os.path.exists(pos2neg_path):\n            os.makedirs(pos2neg_path)\n        if not os.path.exists(neg2pos_path):\n            os.makedirs(neg2pos_path)\n        if localNorm is True:\n            local_pos_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(i) + '/TruePos')\n            local_neg_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(i) + '/TrueNeg')\n            local_pos2neg_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(i) + '/PosToNeg')\n            local_neg2pos_path = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(i) + '/NegToPos')\n            if not os.path.exists(local_pos_path):\n                os.makedirs(local_pos_path)\n            if not os.path.exists(local_neg_path):\n                os.makedirs(local_neg_path)\n            if not os.path.exists(local_pos2neg_path):\n                os.makedirs(local_pos2neg_path)\n            if not os.path.exists(local_neg2pos_path):\n                os.makedirs(local_neg2pos_path)\n\n    marker_data = data[markers]\n    location = data[[x_coordinate,y_coordinate]]\n\n    # clip the data to drop outliers\n    def clipping (x):\n        clip = x.clip(lower =np.percentile(x,0.01), upper=np.percentile(x,99.99)).tolist()\n        return clip\n\n    # return the mean between two percentiles\n    def meanPercentile (values, lowPercentile, highPercentile):\n        # Calculate the 1st percentile value\n        p1 = np.percentile(values, lowPercentile)\n        # Calculate the 20th percentile value\n        p20 = np.percentile(values, highPercentile)\n        # Select the values between the 1st and 20th percentile using numpy.where()\n        filtered_values = np.where((values &gt;= p1) &amp; (values &lt;= p20))\n        # Calculate the mean of the filtered values\n        meanVal = np.mean(values[filtered_values])\n        return meanVal\n\n    # Function for GMM\n    def simpleGMM (data, n_components, means_init, random_state):\n        gmm = GaussianMixture(n_components=n_components, means_init=means_init,  random_state=random_state)\n        gmm.fit(data)\n        # Predict the class labels for each sample\n        predictions = gmm.predict(data)\n        # Get the mean of each Gaussian component\n        means = gmm.means_.flatten()\n        # Sort the mean values in ascending order\n        sorted_means = np.sort(means)\n        # Assign 'pos' to rows with higher mean distribution and 'neg' to rows with lower mean distribution\n        labels = np.where(predictions == np.argmax(means), 'pos', 'neg')\n        return labels\n\n    # match two arrays and return seperate lists\n    def array_match (labels, names):\n        # Create a defaultdict with an empty list as the default value\n        result = defaultdict(list)\n        # Iterate over the labels and names arrays\n        for label, name in zip(labels, names):\n            # Add the name to the list for the corresponding label\n            result[label].append(name)\n        return result\n\n\n\n    # clip data\n    marker_data = marker_data.apply(clipping)\n\n    # apply transformation if requested\n    if transformation is True:\n        marker_data = np.arcsinh(marker_data)\n        #marker_data = np.log1p(marker_data)\n\n    # combine data\n    combined_data = pd.concat([marker_data, location], axis=1)\n\n    # intialize the percentiles values\n    percentiles.sort()\n\n    # function to identify the corner of the thumbnails\n    def cornerFinder (centroid):\n        row_start = int(centroid - windowSize // 2)\n        row_end = row_start + windowSize\n        return [row_start, row_end]\n\n    # function to crop the image and save the image\n    def cropImage (rowIndex, corners, imgType, zimg, npercentile, m, maxpercentile, imname):\n        #print(str(rowIndex))\n        x_start = corners.loc[rowIndex]['x_start']; x_end = corners.loc[rowIndex]['x_end']\n        y_start = corners.loc[rowIndex]['y_start']; y_end = corners.loc[rowIndex]['y_end']\n        # cropping image\n        crop = zimg[y_start:y_end, x_start:x_end]\n        # convert the image to unit8\n        if globalNorm is True:\n            fullN = ((crop/npercentile)*255).clip(0, 255).astype('uint8')\n        else:\n            fullN = ((crop/maxpercentile)*255).clip(0, 255).astype('uint8')\n        # save the cropped image\n        if imgType == 'pos':\n            path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(m) + '/TruePos/' + str(rowIndex) + \"_\" + str(imname) + '.tif')\n        elif imgType == 'neg':\n            path = pathlib.Path(projectDir + '/GATOR/Thumbnails/' + str(m) + '/TrueNeg/' + str(rowIndex) + \"_\" + str(imname) + '.tif')\n        # write file\n        tifffile.imwrite(path,fullN)\n        # local normalization if requested\n        if localNorm is True:\n            localN = ((crop/(np.percentile(crop.compute(), 99.99)))*255).clip(0, 255).astype('uint8')\n            # save image\n            if imgType == 'pos':\n                Lpath = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(m) + '/TruePos/' + str(rowIndex) + \"_\" + str(imname) + '.tif')\n            elif imgType == 'neg':\n                Lpath = pathlib.Path(projectDir + '/GATOR/Thumbnails/localNorm/' + str(m) + '/TrueNeg/' + str(rowIndex) + \"_\" + str(imname) + '.tif')\n            # write file\n            tifffile.imwrite(Lpath,localN)\n\n    # identify the cells of interest\n    def processMarker (marker):\n        if verbose is True:\n            print('Processing Marker: ' + str(marker))\n\n        moi = combined_data[marker].values\n\n        # figure out marker index or channel in image\n        markerIndex = marker_map[marker]\n\n        # mean of cells within defined threshold\n        lowerPercent = meanPercentile (values=moi, lowPercentile=percentiles[0], highPercentile=percentiles[1])\n        higherPercent = meanPercentile (values=moi, lowPercentile=percentiles[2], highPercentile=percentiles[3])\n        # Format mean to pass into next GMM\n        Pmean = np.array([[lowerPercent], [higherPercent]])\n\n        # perform GMM\n        labels = simpleGMM (data=moi.reshape(-1, 1), n_components=2, means_init=Pmean,  random_state=random_state)\n        # Match the labels and index names to identify which cells are pos and neg\n        expCells = array_match (labels=labels, names=data.index)\n        # split it\n        pos = expCells.get('pos', []) ; neg = expCells.get('neg', [])\n\n\n        # determine the percentiles value for the marker of interest\n        #low_a = np.percentile(moi, percentiles[0]); low_b = np.percentile(moi, percentiles[1])\n        #high_a = np.percentile(moi, percentiles[2]); high_b = np.percentile(moi, percentiles[3])\n\n        # identify the cells that fall within the determined range\n        #neg = np.where(moi.between(low_a, low_b))[0]\n        #pos = np.where(moi.between(high_a, high_b))[0]\n\n        # shuffle the cells\n        random.Random(random_state).shuffle(neg); random.Random(random_state).shuffle(pos)\n\n        # identify the location of pos and neg cells\n        neg_location_i = location.iloc[neg]\n        pos_location_i = location.iloc[pos]\n\n        # divide the pos cells into two bins based on the number of neighbours\n        # assumption is that we will find cells that are dense and sparse\n        if restrictDensity is True:\n            # identify postive cells that are densly packed if user requests\n            kdt = BallTree(pos_location_i[[x_coordinate,y_coordinate]], metric='euclidean') \n            ind = kdt.query_radius(pos_location_i[[x_coordinate,y_coordinate]], r=windowSize+5, return_distance=False)\n            for i in range(0, len(ind)): ind[i] = np.delete(ind[i], np.argwhere(ind[i] == i))#remove self\n            neigh_length = [len(subarray) for subarray in ind]\n            if restrictDensityNumber is None:\n                # GMM for auto detection\n                X = np.array(neigh_length).reshape(-1, 1)\n                gmm_neigh = GaussianMixture(n_components=2)\n                gmm_neigh.fit(X)\n                means = gmm_neigh.means_\n                index = np.argmin(means)\n                labels_neigh = gmm_neigh.predict(X)\n                lower_mean_indices = np.where(labels_neigh == index)[0]\n                # subset the postive cells based on the index\n                pos_location_i = pos_location_i.iloc[lower_mean_indices]\n            else:\n                lower_mean_indices = [i for i, x in enumerate(neigh_length) if x &lt; restrictDensityNumber]\n                pos_location_i = pos_location_i.iloc[lower_mean_indices]\n\n        # Find corner\n        # Negative cells\n        r_cornerFinder = lambda x: cornerFinder (centroid=x)\n        neg_x = pd.DataFrame(list(map(r_cornerFinder, neg_location_i[x_coordinate].values))) # x direction\n        neg_y = pd.DataFrame(list(map(r_cornerFinder, neg_location_i[y_coordinate].values))) # y direction\n        neg_x.columns = [\"x_start\", \"x_end\"]; neg_y.columns = [\"y_start\", \"y_end\"]\n        neg_location = pd.concat([neg_x, neg_y], axis=1)\n        neg_location.index = neg_location_i.index\n\n        # Positive cells\n        r_cornerFinder = lambda x: cornerFinder (centroid=x)\n        pos_x = pd.DataFrame(list(map(r_cornerFinder, pos_location_i[x_coordinate].values))) # x direction\n        pos_y = pd.DataFrame(list(map(r_cornerFinder, pos_location_i[y_coordinate].values))) # y direction\n        pos_x.columns = [\"x_start\", \"x_end\"]; pos_y.columns = [\"y_start\", \"y_end\"]\n        pos_location = pd.concat([pos_x, pos_y], axis=1)\n        pos_location.index = pos_location_i.index\n\n        # drop all coordinates with neg values (essentially edges of slide)\n        neg_location = neg_location[(neg_location &gt; 0).all(1)]\n        pos_location = pos_location[(pos_location &gt; 0).all(1)]\n\n        # subset max number of cells\n        if len(neg_location) &gt; maxThumbnails:\n            neg_location = neg_location[:maxThumbnails]\n        if len(pos_location) &gt; maxThumbnails:\n            pos_location = pos_location[:maxThumbnails]\n\n        # identify image name\n        imname = pathlib.Path(imagePath).stem\n\n        # load the image\n        zimg = da.from_zarr(tifffile.imread(pathlib.Path(imagePath), aszarr=True, level=0, key=markerIndex))\n        npercentile = np.percentile(zimg.compute(), 99.99)\n        maxpercentile = zimg.max().compute()\n\n        # for older version f tifffile\n        #zimg = zarr.open(tifffile.imread(pathlib.Path(imagePath), aszarr=True, level=0, key=markerIndex))\n        # = np.percentile(zimg,  99.99)\n\n        # Cut images and write it out\n        # neg\n        r_cropImage = lambda x: cropImage (rowIndex=x, corners=neg_location, imgType='neg', zimg=zimg, npercentile=npercentile, maxpercentile=maxpercentile, m=marker, imname=imname)\n        process_neg = list(map(r_cropImage, list(neg_location.index)))\n        # pos\n        r_cropImage = lambda x: cropImage (rowIndex=x, corners=pos_location, imgType='pos', zimg=zimg, npercentile=npercentile, maxpercentile=maxpercentile, m=marker, imname=imname)\n        process_neg = list(map(r_cropImage, list(pos_location.index)))\n\n\n    # Run the function for each marker\n    r_processMarker = lambda x: processMarker (marker=x)\n    final = list(map(r_processMarker, markers))\n\n    # Finish Job\n    if verbose is True:\n        print('Thumbnails have been generated, head over to \"' + str(projectDir) + '/GATOR/Thumbnails\" to view results')\n</code></pre>"},{"location":"Functions/generateTrainTestSplit/","title":"generateTrainTestSplit","text":"<p>Short Description</p> <p>The function generates a mask for the deep learning model training, using  automated approaches. Splitting the data into training, validation and  test sets is also included in the function, making it easier to feed the  data directly into the deep learning algorithm. Note that manually drawing  the mask on thumbnails is the ideal approach, however for scalability  purposes, automation is used.</p>"},{"location":"Functions/generateTrainTestSplit/#gatorpy.generateTrainTestSplit--function","title":"Function","text":""},{"location":"Functions/generateTrainTestSplit/#gatorpy.generateTrainTestSplit.generateTrainTestSplit","title":"<code>generateTrainTestSplit(thumbnailFolder, projectDir, file_extension=None, verbose=True, TruePos='TruePos', NegToPos='NegToPos', TrueNeg='TrueNeg', PosToNeg='PosToNeg')</code>","text":"<p>Parameters:</p> Name Type Description Default <code>thumbnailFolder</code> <code>list</code> <p>List of folders that contains the human sorted Thumbnails that is to be used for generating training data and split them train test and validation cohorts.</p> required <code>projectDir</code> <code>str</code> <p>Path to output directory.</p> required <code>file_extension</code> <code>str</code> <p>If there are non-image files in the thumbnailFolder, the user can specify a file extension to only select those files for processing. The default is None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console. </p> <code>True</code> <code>TruePos</code> <code>str</code> <p>Name of the folder that holds the Thumbnails classified as True Positive. The default is 'TruePos'.</p> <code>'TruePos'</code> <code>NegToPos</code> <code>str</code> <p>Name of the folder that holds the Thumbnails classified as True Negative. The default is 'NegToPos'.</p> <code>'NegToPos'</code> <code>TrueNeg</code> <code>str</code> <p>Name of the folder that holds the Thumbnails that were moved from <code>True Positive</code> to <code>True Negative</code>. The default is 'TrueNeg'.</p> <code>'TrueNeg'</code> <code>PosToNeg</code> <code>str</code> <p>Name of the folder that holds the Thumbnails that were moved from <code>True Negative</code> to <code>True Positive</code>. The default is 'PosToNeg'.</p> <code>'PosToNeg'</code> <p>Returns:</p> Name Type Description <code>masks</code> <code>images</code> <p>Segmentation masks are generated for every Thumbnail and split into Train, Test and Validation cohorts.</p> Example <pre><code># High level working directory\ncwd = '/Users/aj/Desktop/gatorExampleData'\n\n# Folder where the raw Thumbnails are stored\nthumbnailFolder = [cwd + '/GATOR/Thumbnails/CD3D',\n                   cwd + '/GATOR/Thumbnails/ECAD']\nprojectDir = cwd\n\n# The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\n# If you had deleted any of the folders and are not using them, replace the folder name with `None` in the parameter.\nga.generateTrainTestSplit ( thumbnailFolder, \n                            projectDir, \n                            file_extension=None,\n                            verbose=True,\n                            TruePos='TruePos', NegToPos='NegToPos',\n                            TrueNeg='TrueNeg', PosToNeg='PosToNeg')\n\n# Same function if the user wants to run it via Command Line Interface\npython generateTrainTestSplit.py --thumbnailFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre> Source code in <code>gatorpy/generateTrainTestSplit.py</code> <pre><code>def generateTrainTestSplit (thumbnailFolder, \n                            projectDir, \n                            file_extension=None,\n                            verbose=True,\n                            TruePos='TruePos', NegToPos='NegToPos',\n                            TrueNeg='TrueNeg', PosToNeg='PosToNeg'):\n\"\"\"\nParameters:\n    thumbnailFolder (list):\n        List of folders that contains the human sorted Thumbnails that is to be used\n        for generating training data and split them train test and validation cohorts.\n\n    projectDir (str):\n        Path to output directory.\n\n    file_extension (str, optional):\n        If there are non-image files in the thumbnailFolder, the user can specify\n        a file extension to only select those files for processing. The default is None.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console. \n\n    TruePos (str, optional):\n        Name of the folder that holds the Thumbnails classified as True Positive.\n        The default is 'TruePos'.\n\n    NegToPos (str, optional):\n        Name of the folder that holds the Thumbnails classified as True Negative.\n        The default is 'NegToPos'.\n\n    TrueNeg (str, optional):\n        Name of the folder that holds the Thumbnails that were moved from `True Positive`\n        to `True Negative`. The default is 'TrueNeg'.\n\n    PosToNeg (str, optional):\n        Name of the folder that holds the Thumbnails that were moved from `True Negative`\n        to `True Positive`. The default is 'PosToNeg'.\n\nReturns:\n    masks (images):\n        Segmentation masks are generated for every Thumbnail and split into Train,\n        Test and Validation cohorts.\n\nExample:\n\n        ```python\n\n        # High level working directory\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n\n        # Folder where the raw Thumbnails are stored\n        thumbnailFolder = [cwd + '/GATOR/Thumbnails/CD3D',\n                           cwd + '/GATOR/Thumbnails/ECAD']\n        projectDir = cwd\n\n        # The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\n        # If you had deleted any of the folders and are not using them, replace the folder name with `None` in the parameter.\n        ga.generateTrainTestSplit ( thumbnailFolder, \n                                    projectDir, \n                                    file_extension=None,\n                                    verbose=True,\n                                    TruePos='TruePos', NegToPos='NegToPos',\n                                    TrueNeg='TrueNeg', PosToNeg='PosToNeg')\n\n        # Same function if the user wants to run it via Command Line Interface\n        python generateTrainTestSplit.py --thumbnailFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD --projectDir /Users/aj/Desktop/gatorExampleData/\n\n        ```\n\n    \"\"\"\n\n    # Function takes in path to two folders, processes the images in those folders,\n    # and saves them into a different folder that contains Train, Validation and Test samples\n    #TruePos='TruePos'; NegToPos='NegToPos'; TrueNeg='TrueNeg'; PosToNeg='PosToNeg'; verbose=True\n\n    # convert the folder into a list\n    if isinstance (thumbnailFolder, str):\n        thumbnailFolder = [thumbnailFolder]\n\n    # convert all path names to pathlib\n    thumbnailFolder = [pathlib.Path(p) for p in thumbnailFolder]\n    projectDir = pathlib.Path(projectDir)\n\n    # find all markers passed\n    all_markers = [i.stem for i in thumbnailFolder]\n\n    # create directories to save\n    for i in all_markers:\n        if not (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'training').exists ():\n            (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'training').mkdir(parents=True, exist_ok=True)\n\n        if not (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'validation').exists ():\n            (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'validation').mkdir(parents=True, exist_ok=True)\n\n        if not (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'test').exists ():\n            (projectDir / 'GATOR/TrainingData/' / f\"{i}\" /  'test').mkdir(parents=True, exist_ok=True)\n\n    # standard format\n    if file_extension is None:\n        file_extension = '*'\n    else:\n        file_extension = '*' + str(file_extension)\n\n    # Filter on pos cells\n    def pos_filter (path):\n        image = cv.imread(str(path.resolve()), cv.IMREAD_GRAYSCALE)\n        blur = cv.GaussianBlur(image, ksize=(3,3), sigmaX=1, sigmaY=1)\n        ret3,th3 = cv.threshold(blur,0,1,cv.THRESH_OTSU)\n        mask = th3 + 1\n        return [mask, image]\n\n    # Filter on neg cells\n    def neg_filter (path):\n        image = cv.imread(str(path.resolve()), cv.IMREAD_GRAYSCALE)\n        mask = np.ones(image.shape, dtype=np.uint8)\n        return [mask, image]\n\n    # identify the files within all the 4 folders\n    def findFiles (folderIndex):\n        if verbose is True:\n            print ('Processing: ' + str(thumbnailFolder[folderIndex].stem))\n        marker_name = str(thumbnailFolder[folderIndex].stem)\n\n        baseFolder = thumbnailFolder[folderIndex]\n\n        if TruePos is not None:\n            pos = list(pathlib.Path.glob(baseFolder / TruePos, file_extension))\n        if NegToPos is not None:\n            negtopos = list(pathlib.Path.glob(baseFolder / NegToPos, file_extension))\n        positive_cells = pos + negtopos\n\n        if TrueNeg is not None:\n            neg = list(pathlib.Path.glob(baseFolder / TrueNeg, file_extension))\n        if PosToNeg is not None:\n            postoneg = list(pathlib.Path.glob(baseFolder / PosToNeg, file_extension))\n        negative_cells = neg + postoneg\n\n        # prepare the Training, Validataion and Test Cohorts\n        if len(positive_cells) &gt; 0:\n            train_pos = random.sample(positive_cells, round(len(positive_cells) * 0.6))\n            remanining_pos = list(set(positive_cells) - set(train_pos))\n            val_pos = random.sample(remanining_pos, round(len(remanining_pos) * 0.5)) # validation\n            test_pos = list(set(remanining_pos) - set(val_pos)) # test\n        if len(negative_cells) &gt; 0:\n            train_neg = random.sample(negative_cells, round(len(negative_cells) * 0.6))\n            remanining_neg = list(set(negative_cells) - set(train_neg))\n            val_neg = random.sample(remanining_neg, round(len(remanining_neg) * 0.5))\n            test_neg = list(set(remanining_neg) - set(val_neg))\n\n\n        # loop through training dataset and save images and masks\n        newname_train = list(range(len(train_pos) + len(train_neg))); random.shuffle(newname_train)\n        train_pos_name = newname_train[:len(train_pos)]; train_neg_name = newname_train[len(train_pos):]\n\n        if len (train_pos_name) &gt; 0:\n            for i, j in zip( train_pos_name, train_pos):\n                m, im = pos_filter (j)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'training' / f\"{i}_img.tif\"\n                tifffile.imwrite(fPath,im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'training' / f\"{i}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n        if len (train_neg_name) &gt; 0:\n            for k, l in zip( train_neg_name, train_neg):\n                m, im = neg_filter (l)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'training' / f\"{k}_img.tif\"\n                tifffile.imwrite(fPath, im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'training' / f\"{k}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n\n        # loop through validation dataset and save images and masks\n        newname_train = list(range(len(val_pos) + len(val_neg))); random.shuffle(newname_train)\n        train_pos_name = newname_train[:len(val_pos)]; train_neg_name = newname_train[len(val_pos):]\n\n        if len (train_pos_name) &gt; 0:\n            for i, j in zip( train_pos_name, val_pos):\n                m, im = pos_filter (j)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'validation' / f\"{i}_img.tif\"\n                tifffile.imwrite(fPath, im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'validation' / f\"{i}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n        if len (train_neg_name) &gt; 0:\n            for k, l in zip( train_neg_name, val_neg):\n                m, im = neg_filter (l)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'validation' / f\"{k}_img.tif\"\n                tifffile.imwrite(fPath, im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'validation' / f\"{k}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n\n        # loop through test dataset and save images and masks\n        newname_train = list(range(len(test_pos) + len(test_neg))); random.shuffle(newname_train)\n        train_pos_name = newname_train[:len(test_pos)]; train_neg_name = newname_train[len(test_pos):]\n\n        if len (train_pos_name) &gt; 0:\n            for i, j in zip( train_pos_name, test_pos):\n                m, im = pos_filter (j)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'test' / f\"{i}_img.tif\"\n                tifffile.imwrite(fPath, im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'test' / f\"{i}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n        if len (train_neg_name) &gt; 0:\n            for k, l in zip( train_neg_name, test_neg):\n                m, im = neg_filter (l)\n                # save image\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'test' / f\"{k}_img.tif\"\n                tifffile.imwrite(fPath, im)\n                # associated mask\n                fPath = projectDir / 'GATOR/TrainingData/' / f\"{marker_name}\" / 'test' / f\"{k}_mask.tif\"\n                tifffile.imwrite(fPath, m)\n\n    # apply function to all folders\n    r_findFiles = lambda x: findFiles (folderIndex=x)\n    process_folders = list(map(r_findFiles, list(range(len(thumbnailFolder)))))\n\n    # Print\n    if verbose is True:\n        print('Training data has been generated, head over to \"' + str(projectDir) + '/GATOR/TrainingData\" to view results')\n</code></pre>"},{"location":"Functions/mergeGatorObject/","title":"mergeGatorObject","text":"<p>Short Description</p> <p>Use <code>mergeGatorObject</code> to combine multiple gatorObjects into a dataset for  analysis when multiple images need to be analyzed.</p> <p>Note that merging <code>gatorObjects</code> requires merging multiple sections, not  simple concatenation. Use parameters to specify which parts of the  <code>gatorObjects</code> to merge.</p>"},{"location":"Functions/mergeGatorObject/#gatorpy.mergeGatorObject--function","title":"Function","text":""},{"location":"Functions/mergeGatorObject/#gatorpy.mergeGatorObject.mergeGatorObject","title":"<code>mergeGatorObject(gatorObjects, fileName='mergedGatorObject', layers=['preProcessed'], uns=['gatorOutput', 'gatorScore', 'failedMarkers'], verbose=True, projectDir=None)</code>","text":"<p>Parameters:</p> Name Type Description Default <code>gatorObjects</code> <code>list</code> <p>A collection of Gator Objects to combine into one object, which can include both Gator Objects stored in memory and those accessed via file path.</p> required <code>fileName</code> <code>str</code> <p>Designate a Name for the resulting combined Gator object.</p> <code>'mergedGatorObject'</code> <code>layers</code> <code>list</code> <p>The <code>.layers</code> section within the Gator Objects to be merged together.</p> <code>['preProcessed']</code> <code>uns</code> <code>list</code> <p>The <code>.uns</code> section within the Gator Objects to be merged together.</p> <code>['gatorOutput', 'gatorScore', 'failedMarkers']</code> <code>verbose</code> <code>bool</code> <p>If True, print detailed information about the process to the console. </p> <code>True</code> <code>projectDir</code> <code>str</code> <p>Provide the path to the output directory. The result will be located at <code>projectDir/GATOR/mergedGatorObject/</code>. </p> <code>None</code> <p>Returns:</p> Name Type Description <code>Gator</code> <code>anndata</code> <p>If <code>projectDir</code> is provided the merged Gator Object will saved within the provided projectDir.</p> Example <pre><code># set the working directory &amp; set paths to the example data\ncwd = '/Users/aj/Desktop/gatorExampleData'\ngatorObjects = [cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad',\n                cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad']\n\n# For this tutorial, supply the same gatorObject twice for merging, but multiple gatorObjects can be merged in ideal conditions.\nadata = ga.mergeGatorObject ( gatorObjects=gatorObjects,\n                              fileName='mergedGatorObject',\n                              layers=['preProcessed'],\n                              uns= ['gatorOutput','gatorScore'],\n                              projectDir=cwd)\n\n# Same function if the user wants to run it via Command Line Interface\npython mergeGatorObject.py --gatorObjects /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre> Source code in <code>gatorpy/mergeGatorObject.py</code> <pre><code>def mergeGatorObject (gatorObjects,\n                      fileName='mergedGatorObject',\n                      layers=['preProcessed'],\n                      uns= ['gatorOutput','gatorScore','failedMarkers'],\n                      verbose=True,\n                      projectDir=None):\n\"\"\"\nParameters:\n    gatorObjects (list):\n       A collection of Gator Objects to combine into one object, which can\n       include both Gator Objects stored in memory and those accessed\n       via file path.\n\n    fileName (str, optional):\n        Designate a Name for the resulting combined Gator object.\n\n    layers (list, optional):\n        The `.layers` section within the Gator Objects to be merged together.\n\n    uns (list, optional):\n        The `.uns` section within the Gator Objects to be merged together.\n\n    verbose (bool, optional):\n        If True, print detailed information about the process to the console. \n\n    projectDir (str, optional):\n        Provide the path to the output directory. The result will be located at\n        `projectDir/GATOR/mergedGatorObject/`. \n\nReturns:\n    Gator (anndata):\n        If `projectDir` is provided the merged Gator Object will saved within the\n        provided projectDir.\n\nExample:\n\n        ```python.\n\n        # set the working directory &amp; set paths to the example data\n        cwd = '/Users/aj/Desktop/gatorExampleData'\n        gatorObjects = [cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad',\n                        cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad']\n\n        # For this tutorial, supply the same gatorObject twice for merging, but multiple gatorObjects can be merged in ideal conditions.\n        adata = ga.mergeGatorObject ( gatorObjects=gatorObjects,\n                                      fileName='mergedGatorObject',\n                                      layers=['preProcessed'],\n                                      uns= ['gatorOutput','gatorScore'],\n                                      projectDir=cwd)\n\n        # Same function if the user wants to run it via Command Line Interface\n        python mergeGatorObject.py --gatorObjects /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n\n\n        ```\n    \"\"\"\n\n    # layers=['preProcessed']; uns= ['gatorPredict','probQuant']; fileName='gatorMerged'; projectDir=None\n\n    # Convert to list of anndata objects\n    if isinstance (gatorObjects, list):\n        gatorObjects = gatorObjects\n    else:\n        gatorObjects = [gatorObjects]\n\n    # converting other parameters to list\n    if isinstance (layers, str):\n        layers = [layers]\n    if isinstance (uns, str):\n        uns = [uns]\n\n    # Things to process\n    process_layers = ['rawData', 'scaledData', 'obs']\n    if layers is not None:\n        process_layers.extend(layers)\n    if uns is not None:\n        process_layers.extend(uns)\n\n\n    # for expression, uns and layers\n    def processX (gatorObject, process_layers):\n        if isinstance(gatorObject, str):\n            # start with raw data\n            adata = ad.read(gatorObject)\n        else:\n            adata = gatorObject.copy()\n\n        # print\n        if verbose is True:\n            print (\"Extracting data from: \" + str( adata.obs['imageid'].unique()[0]) )\n\n        # process the data\n        rawData = pd.DataFrame(adata.raw.X, index=adata.obs.index, columns=adata.var.index)\n\n        # scaled data\n        scaledData = pd.DataFrame(adata.X, index=adata.obs.index, columns=adata.var.index)\n\n        # obs\n        obs = adata.obs.copy()\n\n        # Process layers\n        if layers is not None:\n            for i in layers:\n                exec(f\"{i} = pd.DataFrame(adata.layers[i],index=adata.obs.index, columns=adata.var.index)\")\n\n        # Process uns\n        if uns is not None:\n            for j in uns:\n                exec(f\"{j} = adata.uns[j]\")\n\n        # return the results\n        objects = []\n        for name in process_layers:\n            exec(f\"objects.append({name})\")\n\n        return objects\n\n    # Run the function\n    # Run the function:\n    if verbose is True:\n        print(\"Extracting data\")\n    r_processX = lambda x: processX (gatorObject=x, process_layers=process_layers)\n    processX_result = list(map(r_processX, gatorObjects)) # Apply function\n\n    # combine all the data\n    # create a dictinoary between index and data type\n    mapping = {i: element for i, element in enumerate(process_layers)}\n\n\n    # create an empty dictionary to store the final dataframes\n    final_data = {}\n    # get the number of lists in the data list\n    num_lists = len(processX_result)\n    # iterate over the mapping dictionary\n    for key, value in mapping.items():\n        # create an empty list to store the dataframes\n        df_list = []\n        # iterate over the data lists\n        for i in range(num_lists):\n            # retrieve the dataframe from the current list\n            df = processX_result[i][key]\n            # resolve dict independently\n            if isinstance(df, dict):\n                df = pd.DataFrame.from_dict(df, orient='index', columns=df[list(df.keys())[0]]).applymap(lambda x: 1)   \n            # add the dataframe to the df_list\n            df_list.append(df)\n        # concatenate the dataframes in the df_list\n        df = pd.concat(df_list)\n        # add the resulting dataframe to the final_data dictionary\n        final_data[value] = df\n\n\n    # create the combined anndata object\n    bdata = ad.AnnData(final_data.get(\"rawData\"), dtype=np.float64)\n    bdata.obs = final_data.get(\"obs\")\n    bdata.raw = bdata\n    bdata.X = final_data.get(\"scaledData\")\n    # add layers\n    if layers is not None:\n        for i in layers:\n            tmp = final_data.get(i)\n            bdata.layers[i] = tmp\n    # add uns\n    if uns is not None:\n        for i in uns:\n            tmp = final_data.get(i)\n            bdata.uns[i] = tmp\n\n    # last resolve all_markers if it exisits\n    if isinstance(gatorObjects[0], str):\n        # start with raw data\n        adata = ad.read(gatorObjects[0])\n    else:\n        adata = gatorObjects[0].copy()\n    if hasattr(adata, 'uns') and 'all_markers' in adata.uns:\n        # the call to adata.uns['all_markers'] is valid\n        bdata.uns['all_markers'] = adata.uns['all_markers']\n\n    # write the output\n    if projectDir is not None:\n        finalPath = pathlib.Path(projectDir + '/GATOR/mergedGatorObject')\n        if not os.path.exists(finalPath):\n            os.makedirs(finalPath)\n        bdata.write(finalPath / f'{fileName}.h5ad')\n        # Print\n        if verbose is True:\n            print('Given gatorObjects have been merged, head over to \"' + str(projectDir) + '/GATOR/mergedGatorObject\" to view results')\n\n\n    # return data\n    return bdata\n</code></pre>"},{"location":"Tutorials/BuildGatorModels/","title":"\ud83d\udc0a Build a GATOR Model","text":"<p>The executable notebook can be downloaded here </p> <p>When following the tutorial, it is crucial to read the text as simply running the cells will not work!</p> <p>Please keep in mind that the sample data is used for demonstration purposes only and has been simplified and reduced in size. It is solely intended for educational purposes on how to execute <code>Gator</code> and will not yeild any meaningful results.</p> <p>Training a Gator Model involves the following steps: - For any given marker: Identify a image that could be used to generate postive and negative thumbnails - Run the <code>generateThumbnails</code> function on the image to auto generate postive and negative thumbnails - Go through the auto generated  thumbnails and remove any wrong assignments - On the user sorted set of thumbnails run the <code>generateTrainTestSplit</code> function to prepare the data for training a deep learning model - Lastly, run <code>gatorTrain</code> </p> <pre><code># import packages in jupyter notebook (not needed for command line interface users)\nimport gatorpy as ga\n</code></pre> <p>Gator auto generates subfolders and so always set a single folder as <code>projectDir</code> and Gator will use that for all subsequent steps. In this case we will set the downloaded sample data as our <code>projectDir</code>. My sample data is on my desktop as seen below.</p> <pre><code># set the working directory &amp; set paths to the example data\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\nimagePath = projectDir + '/image/exampleImage.tif'\nspatialTablePath = projectDir + '/quantification/exampleSpatialTable.csv'\nmarkerChannelMapPath = projectDir + '/markers.csv'\n</code></pre>"},{"location":"Tutorials/BuildGatorModels/#step-1-generate-thumbnails-for-training-data","title":"Step-1: Generate Thumbnails for Training Data","text":"<p>The first step would be to train a model to recognize the marker of interest. In this example the data contains 11 channels <code>DNA1, ECAD, CD45, CD4, CD3D, CD8A, CD45R, KI67</code> and as we are not interested in training a model to recognize DNA or background (<code>DNA1</code>), we will only need to generate training data for  <code>ECAD1, CD45, CD4, CD3D, CD8A &amp; KI67</code>. However for proof of concept, let us just train a model for <code>ECAD</code> and <code>CD3D</code>.</p> <p>To do so, the first step is to create examples of <code>postive</code> and <code>negative</code> examples for each marker of interest. To facilitate this process, we can use the <code>generateThumbnails</code> function in <code>GATOR</code>. Under the hood the function auto identifies the cells that has high and low expression of the marker of interest and cuts out small thumbnails from the image.</p> <pre><code>ga.generateThumbnails ( spatialTablePath=spatialTablePath, \n                        imagePath=imagePath, \n                        markerChannelMapPath=markerChannelMapPath,\n                        markers=[\"ECAD\", \"CD3D\"], \n                        markerColumnName='marker',\n                        channelColumnName='channel',\n                        transformation=True, \n                        maxThumbnails=100, \n                        random_state=0,\n                        localNorm=True, \n                        globalNorm=False,\n                        x_coordinate='X_centroid', \n                        y_coordinate='Y_centroid',\n                        percentiles=[2, 12, 88, 98], \n                        windowSize=64,\n                        projectDir=projectDir)\n</code></pre> <pre><code>Processing Marker: ECAD\nProcessing Marker: CD3D\nThumbnails have been generated, head over to \"/Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python generateThumbnails.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv /\n                            --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif /\n                            --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv /\n                            --markers ECAD CD3D /\n                            --maxThumbnails 100 /\n                            --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre></p> <p>The output from the above function will be stored under <code>GATOR/Thumbnails/</code>. </p> <p>There are a number of parameters that function need to provided as seen above. Detailed explanations are avaialable in the documentation. Briefly, the function takes in the single-cell table (<code>spatialTablePath</code>) with X and Y coordinates, the full image (<code>imagePath</code>) and lastly a list of <code>markers</code> for which thumbnails need to be generated. Please note as the program does not know which channels in the image corresponds to the <code>markers</code>, hence, the <code>markerChannelMapPath</code> is used to supply a <code>.csv</code> file that maps the channels to the marker information. The <code>markerChannelMap</code> follow 1-indexing convention- so the first channel is represented by the number <code>1</code>. </p> <p>You would have also notices that I have set <code>maxThumbnails=100</code>. This basically means that even if more than 100 cells are identified, only 100 random cells will be used to generate the thumbnails. I generally generate about <code>2000</code> cells, however based on our estimates about 250 postive and 250 negative examples should be suffcient. As this is for illustration purpose only, I have set it to <code>100</code>.  </p> <p>Now that the thumbnails are generated, one would manually go through the <code>TruePos</code> folder and <code>TrueNeg</code> folder and move files around as necessary. If there are any truly negative thumbnails in the <code>TruePos</code> folder, move it to <code>PosToNeg</code> folder. Similarly, if there are any truly positive thumbnails in <code>TrueNeg</code> folder, move it to <code>NegToPos</code> folder. You will often notice that imaging artifacts are captured in the <code>TruePos</code> folder and there will also likely be a number of true positives in the <code>TrueNeg</code> folder as the field of view (64x64) is larger than what the program used to identify those thumbnails (just the centroids of single cells at the center of that thumbnail).    </p> <p>While you are manually sorting the postives and negative thumbnails, please keep in mind that you are looking for high-confident positives and high-confident negatives. It is absolutely okay to delete off majority of the thumbnails that you are not confident about. This infact makes it easy and fast as you are looking to only keep only thumbnails that are readily sortable.  </p> <p>Lastly, I generally use a whole slide image to generate these thumbnails as there will be enough regions with high expression and no expression of the marker of interest. If you look at the thumbnails of this dummy example, you will notice that most thumbnails of <code>TrueNeg</code> for <code>ECAD</code> does contain some level of <code>ECAD</code> as there is not enough regions to sample from. </p>"},{"location":"Tutorials/BuildGatorModels/#step-1a-optional","title":"Step-1a (optional)","text":"<p>You might have noticed in the above example, I had set <code>localNorm=True</code>, which is on by default. This parameter essentially creates a mirror duplicate copy of all the thumbnails and saves it under a folder named <code>localNorm</code>. The difference being that each thumbnail is normalized to the maximum intensity pixel in that thumbnail. It helps to visually sort out the true positives and negatives faster and more reliably. As we will not use the thumbnails in the <code>localNorm</code> for training the deep learning model, we want to make sure all the manual sorting that we did in the <code>localNorm</code> folder is copied over to the real training data. I have written an additional function to help with this. Any moving or deleting of files that you did in the <code>localNorm</code> folder will be copied over to the real training data.  </p> <p>Randomly shift and delete some files from <code>TruePos</code> -&gt; <code>PosToNeg</code> and <code>TrueNeg</code> -&gt; <code>NegToPos</code>   for   <code>CD3D</code> for the purpose of illustration and run the  <code>cloneFolder</code> function to see what happens.</p> <pre><code># list of folders to copy settings from\ncopyFolder = [projectDir + '/GATOR/Thumbnails/localNorm/CD3D',\n              projectDir + '/GATOR/Thumbnails/localNorm/ECAD']\n# list of folders to apply setting to\napplyFolder = [projectDir + '/GATOR/Thumbnails/CD3D',\n               projectDir + '/GATOR/Thumbnails/ECAD']\n# note: Every copyFolder should have a corresponding applyFolder. The order matters! \n\n# The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\nga.cloneFolder (copyFolder, \n                applyFolder, \n                TruePos='TruePos', TrueNeg='TrueNeg', \n                PosToNeg='PosToNeg', NegToPos='NegToPos')\n</code></pre> <pre><code>Processing: CD3D\nProcessing: ECAD\nCloning Folder is complete, head over to /GATOR/Thumbnails\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python cloneFolder.py --copyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/localNorm/ECAD --applyFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD\n</code></pre></p> <p>If you head over to the training data thumbails you will notice that the files have been shifited around exactly as in the <code>localNorm</code> folder.</p>"},{"location":"Tutorials/BuildGatorModels/#step-2-generate-masks-for-training-data","title":"Step-2: Generate Masks for Training Data","text":"<p>To train the deep learning model, in addition to the raw thumbnails a mask is needed. The mask lets the model know where the cell is located. Ideally one would manually draw on the thumbnails to locate where the positive cells are, however for the pupose of scalability we will use automated approaches to generate the Mask for us. The following function will generate the mask and split the data into <code>training, validation and test</code> that can be directly fed into the deep learning algorithm.</p> <pre><code>thumbnailFolder = [projectDir + '/GATOR/Thumbnails/CD3D',\n                   projectDir + '/GATOR/Thumbnails/ECAD']\n\n# The function accepts the four pre-defined folders. If you had renamed them, please change it using the parameter below.\n# If you had deleted any of the folders and are not using them, replace the folder name with `None` in the parameter.\nga.generateTrainTestSplit ( thumbnailFolder, \n                            projectDir=projectDir,\n                            file_extension=None,\n                            TruePos='TruePos', NegToPos='NegToPos',\n                            TrueNeg='TrueNeg', PosToNeg='PosToNeg')\n</code></pre> <pre><code>Processing: CD3D\nProcessing: ECAD\nTraining data has been generated, head over to \"/Users/aj/Desktop/gatorExampleData/GATOR/TrainingData\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python generateTrainTestSplit.py --thumbnailFolder /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/CD3D /Users/aj/Desktop/gatorExampleData/GATOR/Thumbnails/ECAD --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre></p> <p>If you head over to <code>GATOR/TrainingData/</code>, you will notice that each of the supplied marker above will have a folder with the associated <code>training, validataion and test</code> data that is required by the deep-learning algorithm to generate the model. </p>"},{"location":"Tutorials/BuildGatorModels/#step-3-train-the-gator-model","title":"Step-3: Train the Gator Model","text":"<p>The function trains a deep learning model for each marker in the provided training data. To train the <code>gatorModel</code>, simply direct the function to the <code>TrainingData</code> folder. To train only specific models, specify the folder names using the <code>trainMarkers</code> parameter. The 'outputDir' remains constant and the program will automatically create subfolders to save the trained models.</p> <pre><code>trainingDataPath = projectDir + '/GATOR/TrainingData'\n\nga.gatorTrain(trainingDataPath=trainingDataPath,\n               projectDir=projectDir,\n               trainMarkers=None,\n               artefactPath=None,\n               imSize=64,\n               nChannels=1,\n               nClasses=2,\n               nExtraConvs=0,\n               nLayers=3,\n               featMapsFact=2,\n               downSampFact=2,\n               ks=3,\n               nOut0=16,\n               stdDev0=0.03,\n               batchSize=16,\n               epochs=1)\n</code></pre> <pre><code>/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/UNet.py:137: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n  bn = tf.nn.leaky_relu(tf.layers.batch_normalization(c00+shortcut, training=UNet2D.tfTraining))\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/UNet.py:159: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n  lbn = tf.nn.leaky_relu(tf.layers.batch_normalization(\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/UNet.py:162: UserWarning: `tf.layers.dropout` is deprecated and will be removed in a future version. Please use `tf.keras.layers.Dropout` instead.\n  return tf.layers.dropout(lbn, 0.15, training=UNet2D.tfTraining)\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/UNet.py:224: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n  tf.layers.batch_normalization(tf.nn.conv2d(cc, luXWeights2, strides=[1, 1, 1, 1], padding='SAME'),\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/UNet.py:245: UserWarning: `tf.layers.batch_normalization` is deprecated and will be removed in a future version. Please use `tf.keras.layers.BatchNormalization` instead. In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.BatchNormalization` documentation).\n  return tf.layers.batch_normalization(\n\n\n/Users/aj/Desktop/gatorExampleData/GATOR/TrainingData/CD3D/training\nTraining for 8 steps\nFound 120 training images\nFound 40 validation images\nFound 40 test images\nOf these, 0 are artefact training images\n and  0 artefact validation images\nUsing 0 and 1 for mean and standard deviation.\nsaving data\nsaving data\nUsing 18.0 and 0.0 for global max and min intensities.\nClass balance ratio is 20.28898128898129\nstep 00000, e: 0.515714, epoch: 1\nModel saved in file: /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/CD3D/model.ckpt\nstep 00001, e: 0.359827, epoch: 1\nstep 00002, e: 0.508145, epoch: 1\nstep 00003, e: 0.632633, epoch: 1\nstep 00004, e: 0.474240, epoch: 1\nstep 00005, e: 0.412801, epoch: 1\nstep 00006, e: 0.540362, epoch: 2\nstep 00007, e: 0.486726, epoch: 2\nsaving data\nloading data\nINFO:tensorflow:Restoring parameters from /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/CD3D/model.ckpt\nModel restored.\n/Users/aj/Desktop/gatorExampleData/GATOR/TrainingData/ECAD/training\nTraining for 8 steps\nFound 120 training images\nFound 40 validation images\nFound 40 test images\nOf these, 0 are artefact training images\n and  0 artefact validation images\nUsing 0 and 1 for mean and standard deviation.\nsaving data\nsaving data\nUsing 70.0 and 0.0 for global max and min intensities.\nClass balance ratio is 6.918801353310778\nstep 00000, e: 0.573542, epoch: 1\nModel saved in file: /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ECAD/model.ckpt\nstep 00001, e: 0.472750, epoch: 1\nstep 00002, e: 0.516162, epoch: 1\nstep 00003, e: 0.503170, epoch: 1\nstep 00004, e: 0.444074, epoch: 1\nstep 00005, e: 0.569520, epoch: 1\nstep 00006, e: 0.570594, epoch: 2\nstep 00007, e: 0.434399, epoch: 2\nsaving data\nloading data\nINFO:tensorflow:Restoring parameters from /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ECAD/model.ckpt\nModel restored.\nGator Models have been generated, head over to \"/Users/aj/Desktop/gatorExampleData/GATOR/gatorModel\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorTrain.py --trainingDataPath /Users/aj/Desktop/gatorExampleData/GATOR/TrainingData --projectDir /Users/aj/Desktop/gatorExampleData/ --epochs=1\n</code></pre></p> <pre><code># this tutorial ends here. Move to the Run Gator Algorithm Tutorial\n</code></pre>"},{"location":"Tutorials/CellPhenotyping/","title":"\ud83d\udc0a GATOR Phenotyping","text":"<p>Assign phenotypes to each cell. Clustering data may not always be ideal, so we developed a cell type assignment algorithm that does a hierarchical assignment process iteratively.</p> <p>Please keep in mind that the sample data is used for demonstration purposes only and has been simplified and reduced in size. It is solely intended for educational purposes on how to execute <code>Gator</code> and will not yeild any meaningful results.</p> <p>Download executable notebook here.</p> <p>Make sure you have completed <code>Build Gator Model</code> and <code>Run Gator Algorithm</code> Tutorial before you try to execute this Jupyter Notebook!</p> <pre><code># import packages\nimport gatorpy as ga\nimport pandas as pd\n</code></pre> <p>We need <code>two</code> basic inputs to perform phenotyping with Gator - The Gator Object - A Phenotyping workflow based on prior knowledge</p> <pre><code># set the Project directory\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\n# Path to the Gator Object\ngatorObject = projectDir + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n</code></pre> <pre><code># load the phenotyping workflow\nphenotype = pd.read_csv(str(projectDir) + '/phenotype_workflow.csv')\n# view the table:\nphenotype.style.format(na_rep='')\n</code></pre> Unnamed: 0 Unnamed: 1 ECAD CD45 CD4 CD3D CD8A KI67 0 all Immune anypos anypos anypos anypos 1 all ECAD+ pos 2 ECAD+ KI67+ ECAD+ pos 3 Immune CD4+ T allpos allpos 4 Immune CD8+ T allpos allpos 5 Immune Non T CD4+ cells pos neg <p>As it can be seen from the table above, (1) The <code>first column</code> has to contain the cell that are to be classified. (2) The <code>second column</code> indicates the phenotype a particular cell will be assigned if it satifies the conditions in the row. (3) <code>Column three</code> and onward represent protein markers. If the protein marker is known to be expressed for that cell type, then it is denoted by either <code>pos</code>, <code>allpos</code>. If the protein marker is known to not express for a cell type it can be denoted by <code>neg</code>, <code>allneg</code>. If the protein marker is irrelevant or uncertain to express for a cell type, then it is left empty. <code>anypos</code> and <code>anyneg</code> are options for using a set of markers and if any of the marker is positive or negative, the cell type is denoted accordingly.</p> <p>To give users maximum flexibility in identifying desired cell types, we have implemented various classification arguments as described above for strategical classification. They include</p> <ul> <li>allpos</li> <li>allneg</li> <li>anypos</li> <li>anyneg</li> <li>pos</li> <li>neg</li> </ul> <p><code>pos</code> : \"Pos\" looks for cells positive for a given marker. If multiple markers are annotated as <code>pos</code>, all must be positive to denote the cell type. For example, a Regulatory T cell can be defined as <code>CD3+CD4+FOXP3+</code> by passing <code>pos</code> to each marker. If one or more markers don't meet the criteria (e.g. CD4-), the program will classify it as <code>Likely-Regulatory-T cell</code>, pending user confirmation. This is useful in cases of technical artifacts or when cell types (such as cancer cells) are defined by marker loss (e.g. T-cell Lymphomas).</p> <p><code>neg</code> : Same as <code>pos</code> but looks for negativity of the defined markers. </p> <p><code>allpos</code> : \"Allpos\" requires all defined markers to be positive. Unlike <code>pos</code>, it doesn't classify cells as <code>Likely-cellType</code>, but strictly annotates cells positive for all defined markers.</p> <p><code>allneg</code> : Same as <code>allpos</code> but looks for negativity of the defined markers. </p> <p><code>anypos</code> : \"Anypos\" requires only one of the defined markers to be positive. For example, to define macrophages, a cell could be designated as such if any of <code>CD68</code>, <code>CD163</code>, or <code>CD206</code> is positive.</p> <p><code>anyneg</code> : Same as <code>anyneg</code> but looks for negativity of the defined markers. </p> <pre><code>adata = ga.gatorPhenotype ( gatorObject=gatorObject,\n                            phenotype=phenotype,\n                            midpoint = 0.5,\n                            label=\"phenotype\",\n                            imageid='imageid',\n                            pheno_threshold_percent=None,\n                            pheno_threshold_abs=None,\n                            fileName=None,\n                            projectDir=projectDir)\n</code></pre> <pre><code>Phenotyping Immune\nPhenotyping ECAD+\n-- Subsetting ECAD+\nPhenotyping KI67+ ECAD+\n-- Subsetting Immune\nPhenotyping CD4+ T\nPhenotyping CD8+ T\nPhenotyping Non T CD4+ cells\n\n\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/gatorPhenotype.py:259: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  allpos_score['score'] = allpos_score.max(axis=1)\n/Users/aj/Dropbox (Partners HealthCare)/nirmal lab/softwares/gatorpy/gatorpy/gatorPhenotype.py:259: SettingWithCopyWarning: \nA value is trying to be set on a copy of a slice from a DataFrame.\nTry using .loc[row_indexer,col_indexer] = value instead\n\nSee the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n  allpos_score['score'] = allpos_score.max(axis=1)\n\n\nConsolidating the phenotypes across all groups\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorPhenotype.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad \\\n                            --phenotype /Users/aj/Desktop/gatorExampleData/phenotype_workflow.csv \\\n                            --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre></p> <p>If you had provided <code>projectDir</code> the modified gatorObject would be stored in <code>GATOR/gatorPhenotyped/</code>, else, the object will be returned to memory.</p> <pre><code># check the identified phenotypes\nadata.obs['phenotype'].value_counts()\n</code></pre> <pre><code>KI67+ ECAD+    6159\nCD4+ T         5785\nCD8+ T          816\nName: phenotype, dtype: int64\n</code></pre> <pre><code># Tutorial Ends here (check out some of the helper functions!)\n</code></pre>"},{"location":"Tutorials/Docker/","title":"\ud83d\udc0a Run Gator with Docker","text":"<ol> <li>Install Docker on your local machine if you haven't already done so.</li> <li>Open a terminal or command prompt on your machine.</li> </ol>"},{"location":"Tutorials/Docker/#download-gator-from-docker-hub","title":"Download Gator from Docker Hub","text":"<pre><code>docker pull nirmallab/gatorpy:gatorpy\n</code></pre> <p>Run Docker Running Gator via docker follows the same principles as running Gator via Command Line Interface. </p> <p>If you are comfortable using Docker and would like to execute the commands in your preferred way, please feel free to do so. However, if you are new to Docker and would like step-by-step instructions, please follow the tutorial below.</p> <p>Download the sample data. Please keep in mind that the sample data is used for demonstration purposes only and has been simplified and reduced in size. It is solely intended for educational purposes on how to execute <code>Gator</code> and will not yeild any meaningful results.</p> <p>The purpose of this tutorial is solely to demonstrate how to run Gator using Docker. If you require detailed explanations of each step, please refer to the other tutorials.</p>"},{"location":"Tutorials/Docker/#step-1-generate-thumbnails-for-training-data","title":"Step-1: Generate Thumbnails for Training Data","text":"<p>To use your own data, it is recommended to follow the same folder structure as the sample data. However, if that is not possible, you should place all the required data within a single folder. This is because we need to tell Docker where to find all the raw data, and specifying a single directory makes it easier to manage the data within the container.</p> <pre><code># specify the directory where the sample data lives and Run the docker command\nexport projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                nirmallab/gatorpy:gatorpy \\\n                python /app/generateThumbnails.py \\\n                --spatialTablePath $projectDir/quantification/exampleSpatialTable.csv \\\n                --imagePath $projectDir/image/exampleImage.tif \\\n                --markerChannelMapPath $projectDir/markers.csv \\\n                --markers ECAD CD3D \\\n                --maxThumbnails 100 \\\n                --projectDir $projectDir\n</code></pre>"},{"location":"Tutorials/Docker/#step-2-generate-masks-for-training-data","title":"Step-2: Generate Masks for Training Data","text":"<pre><code>export projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                nirmallab/gatorpy:gatorpy \\\n                python /app/generateTrainTestSplit.py \\\n                --thumbnailFolder $projectDir/GATOR/Thumbnails/CD3D $projectDir/GATOR/Thumbnails/ECAD\\\n                --projectDir $projectDir\n</code></pre>"},{"location":"Tutorials/Docker/#step-3-train-the-gator-model","title":"Step-3: Train the Gator Model","text":"<pre><code>export projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                nirmallab/gatorpy:gatorpy \\\n                python /app/gatorTrain.py \\\n                --trainingDataPath $projectDir/GATOR/TrainingData \\\n                --projectDir $projectDir \\\n                --epochs=1\n</code></pre>"},{"location":"Tutorials/Docker/#step-4-run-the-gator-algorithm","title":"Step-4: Run the Gator Algorithm","text":"<p>Note that the <code>markers.csv</code> requests to predict on all markers and so replace the current <code>gatorModel</code> folder with these models that are available for download.   </p> <p>To keep things simple, we're running the entire pipeline with a single command instead of going through the step-by-step process. Nevertheless, you can apply the same principles to each function separately.</p> <pre><code>export projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                nirmallab/gatorpy:gatorpy \\\n                python /app/gatorPipeline.py \\\n                --imagePath $projectDir/image/exampleImage.tif \\\n                --gatorModelPath $projectDir/GATOR/gatorModel/ \\\n                --markerChannelMapPath $projectDir/markers.csv \\\n                --segmentationMaskPath $projectDir/segmentation/exampleSegmentationMask.tif \\\n                --spatialTablePath $projectDir/quantification/exampleSpatialTable.csv \\\n                --projectDir $projectDir \\\n                --verbose False\n</code></pre>"},{"location":"Tutorials/Docker/#step-5-merge-multiple-gator-objects-optional","title":"Step-5: Merge multiple Gator objects (optional)","text":"<pre><code>export projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                nirmallab/gatorpy:gatorpy \\\n                python /app/mergeGatorObject.py \\\n                --gatorObjects $projectDir/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad $projectDir/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad \\\n                --projectDir $projectDir\n</code></pre>"},{"location":"Tutorials/Docker/#step-6-gator-phenotyping","title":"Step-6: Gator Phenotyping","text":"<pre><code>export projectDir=\"/Users/aj/Desktop/gatorExampleData\"\ndocker run -it --mount type=bind,source=$projectDir,target=/$projectDir \\\n                            nirmallab/gatorpy:gatorpy \\\n                            python /app/gatorPhenotype.py \\\n                            --gatorObject $projectDir/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad \\\n                            --phenotype $projectDir/phenotype_workflow.csv \\\n                            --projectDir $projectDir\n</code></pre> <pre><code># Tutorial ends here. Refer to other tutorials for detailed explanation of each step!\n</code></pre>"},{"location":"Tutorials/HelperFunctions/","title":"\ud83d\udc0a GATOR Helper Functions","text":""},{"location":"Tutorials/HelperFunctions/#export-the-results-to-csv","title":"Export the results to <code>.csv</code>","text":"<p>Once the Gator pipeline has been executed, all the output is stored within the gatorObject. An efficient way to export the results of gatorScore, gatorOutput, and the rescaled data is by using a function that saves them as a CSV file. This allows for easy sharing and analysis of the data in other programs.</p> <pre><code># import packages\nimport gatorpy as ga\n</code></pre> <pre><code># path to files needed for gatorExport\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\ngatorObject = projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\n</code></pre> <pre><code>ga.gatorExport(gatorObject,\n               projectDir,\n               fileName=None,\n               raw=False,\n               CellID='CellID',\n               verbose=True)\n</code></pre> <pre><code>Contents of the gatorObject have been exported to \"/Users/aj/Desktop/gatorExampleData/GATOR/gatorExport\"\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorExport.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre></p>"},{"location":"Tutorials/HelperFunctions/#we-also-provide-a-helper-functions-to-vizualize-the-identified-postive-and-negative-cells-for-each-marker","title":"We also provide a helper functions to vizualize the identified postive and negative cells for each marker.","text":"<p>The <code>addPredictions</code> function serves as a link between <code>gatorpy</code> and <code>scimap</code> package. It's useful for evaluating model performance. The function transforms results stored in <code>anndata.uns</code> to <code>anndata.obs</code> so they can be visualized using the <code>scimap</code> package's <code>sm.pl.image viewer</code> function. This displays <code>positive</code> and <code>negative</code> cells overlaid on the raw image.</p> <p>The <code>addPredictions</code> function can take in two methods.  <code>gatorOutput</code> displays the result of running the <code>gator</code> function,  while <code>gatorScore</code> shows the raw output produced by the <code>gatorScore</code>  function, which returns a probability score. The <code>midpoint</code> parameter,  with a default value of 0.5, can be adjusted to define what is considered a <code>positive</code> result, when method is set to <code>gatorScore</code>.</p> <pre><code># Path to gatorObject\ngatorObject = projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\n\nadata = ga.addPredictions (gatorObject, \n                    method='gatorOutput',\n                    gatorOutput='gatorOutput',\n                    gatorScore='gatorScore', \n                    midpoint=0.5)\n</code></pre> <pre><code># check the results\nadata.obs.columns\n</code></pre> <pre><code>Index(['X_centroid', 'Y_centroid', 'Area', 'MajorAxisLength',\n       'MinorAxisLength', 'Eccentricity', 'Solidity', 'Extent', 'Orientation',\n       'CellID', 'imageid', 'p_p_CD45R', 'p_p_CD8A', 'p_p_CD4', 'p_p_KI67',\n       'p_p_ECAD', 'p_p_CD45', 'p_p_CD3D'],\n      dtype='object')\n</code></pre> <p>As it can be seen the addition of <code>p_CD45, p_CD4, p_CD8A, p_CD45R, p_KI67, p_ECAD, p_CD3D</code> to <code>adata.obs</code>. These columns can be vizualized with <code>scimap</code>. </p>"},{"location":"Tutorials/HelperFunctions/#we-recommend-creating-a-new-environment-to-install-scimap","title":"We recommend creating a new environment to install scimap","text":"<p>Download and install the scimap package. We recommend creating a new conda/python environment</p> <pre><code># create new conda env (assuming you have conda installed): executed in the conda command prompt or terminal\nconda create --name scimap -y python=3.8\nconda activate scimap\n</code></pre> <p>Install <code>scimap</code> within the conda environment.</p> <pre><code>pip install scimap\n\n# install jupyter notebook if you want to simply execute this notebook.\npip install notebook\n</code></pre> <p>Once <code>scimap</code> is installed the following function can be used to vizualize the results</p> <pre><code># import\nimport scimap as sm\nimport anndata as ad\n\n# import the gatorObject\ncwd = '/Users/aj/Desktop/gatorExampleData'\ngatorObject = cwd + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad'\nadata = ad.read(gatorObject)\n\n# Path to the raw image\nimage_path = '/Users/aj/Desktop/gatorExampleData/image/exampleImage.tif'\nsm.image_viewer(image_path, adata, overlay='p_CD45')\n</code></pre>"},{"location":"Tutorials/RunGatorAlgorithm/","title":"\ud83d\udc0a Run the GATOR Prediction Algorithm on new images","text":"<p>Download the executable notebook and trained models. For the purpose of this tutorial, replace the <code>gatorModel</code> folder within the exemplar data with the newly downloaded <code>gatorModel</code> directory. </p> <p>Make sure you have completed <code>BuildModels</code> Tutorial before you try to execute this Jupyter Notebook!</p> <p>Please keep in mind that the sample data is used for demonstration purposes only and has been simplified and reduced in size. It is solely intended for educational purposes on how to execute <code>Gator</code> and will not yeild any meaningful results.</p> <p>Running the Gator Prediction Algorithm involves the following steps: - Run the <code>gatorPredict</code> function on a new image. It will produce an image with probability masks - Run the <code>generateGatorScore</code> function on the probability masks to generate the <code>gatorScores</code> - Run the <code>gatorObject</code> to create an anndata object with the <code>gatorScores</code> and pre-computed <code>single-cell table</code> - Lastly, run <code>gator</code>  on the gatorObject</p> <p>Note: To make things easy, all of the above steps can be run with a single command <code>gatorPipeline</code>. Typically, in production settings, <code>gatorPipeline</code> would be utilized, whereas step-by-step analysis would be employed for troubleshooting, model validation, and similar tasks that necessitate greater granularity or control.</p>"},{"location":"Tutorials/RunGatorAlgorithm/#single-command-execution-of-the-entire-gator-prediction-algorithm-using-the-gatorpipeline-function","title":"Single command execution of the entire Gator Prediction Algorithm using the <code>gatorPipeline</code> function","text":"<pre><code># import packages in jupyter notebook (not needed for command line interface users)\nimport gatorpy as ga\n</code></pre> <pre><code># Path to all the files that are necessary files for running the Gator Prediction Algorithm (broken down based on sub functions)\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\n\n# gatorPredict related paths\nimagePath = projectDir + '/image/exampleImage.tif'\nmarkerChannelMapPath = projectDir + '/markers.csv'\ngatorModelPath = projectDir + '/GATOR/gatorModel/'\n\n# Generate generateGatorScore related paths\nsegmentationPath = projectDir + '/segmentation/exampleSegmentationMask.tif'\n\n# gatorObject related paths\nspatialTablePath = projectDir + '/quantification/exampleSpatialTable.csv'\n</code></pre> <pre><code># Run the pipeline (For function specific parameters, check the documentation)\nga.gatorPipeline(   \n                    # parameters for gatorPredict function\n                    imagePath=imagePath,\n                    gatorModelPath=gatorModelPath,\n                    markerChannelMapPath=markerChannelMapPath,\n\n                    # parameters for generateGatorScore function\n                    segmentationMaskPath=segmentationPath,\n\n                    # parameters for gatorObject function\n                    spatialTablePath=spatialTablePath,\n\n                    # parameters to run gator function\n                    # ..\n\n                    # common parameters\n                    verbose=False,\n                    projectDir=projectDir)\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorPipeline.py \\\n        --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif \\\n        --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ \\\n        --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv \\\n        --segmentationMaskPath /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif \\\n        --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv \\\n        --projectDir /Users/aj/Desktop/gatorExampleData \\\n        --verbose True\n</code></pre></p> <p>Head over to <code>GATOR/gatorOutput</code> to view results</p>"},{"location":"Tutorials/RunGatorAlgorithm/#step-by-step-execution-of-the-gator-prediction-algorithm","title":"Step by step execution of the Gator Prediction Algorithm","text":"<pre><code># import packages in jupyter notebook (not needed for command line interface users)\nimport gatorpy as ga\n</code></pre> <pre><code># Path to all the files that are necessary files for running gatorPredict\nprojectDir = '/Users/aj/Desktop/gatorExampleData'\n\n# gatorPredict related paths\nimagePath = projectDir + '/image/exampleImage.tif'\nmarkerChannelMapPath = projectDir + '/markers.csv'\ngatorModelPath = projectDir + '/GATOR/gatorModel/'\n</code></pre>"},{"location":"Tutorials/RunGatorAlgorithm/#step-1-apply-the-generated-models-on-the-image-of-interest-pixel-level","title":"Step-1: Apply the generated Models on the Image of interest (Pixel Level)","text":"<p>The function <code>gatorPredict</code> is employed to make predictions about the expression of a specified marker on cells in new images using the models generated by <code>gatorTrain</code>. This calculation is done at the pixel level, resulting in an output image where the number of channels corresponds to the number of models applied to the input image. The parameter <code>markerChannelMapPath</code> is used to associate the image channel number with the relevant model to be applied.</p> <pre><code>ga.gatorPredict( imagePath=imagePath,\n                 gatorModelPath=gatorModelPath,\n                 projectDir=projectDir,\n                 markerChannelMapPath=markerChannelMapPath, \n                 markerColumnName='marker', \n                 channelColumnName='channel', \n                 modelColumnName='gatormodel')\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorPredict.py --imagePath /Users/aj/Desktop/gatorExampleData/image/exampleImage.tif \\\n                        --gatorModelPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorModel/ \\\n                        --projectDir /Users/aj/Desktop/gatorExampleData \\\n                        --markerChannelMapPath /Users/aj/Desktop/gatorExampleData/markers.csv\n</code></pre></p>"},{"location":"Tutorials/RunGatorAlgorithm/#step-2-calculate-the-gatorscore-single-cell-level","title":"Step-2: Calculate the gatorScore (Single-cell Level)","text":"<p>After calculating pixel-level probability scores, the next step is to aggregate them to the single-cell level. This can be done by computing the mean or median probability scores using pre-computed segmentation masks. The marker names, if available, should already be included in the probabilityMask image. If the marker names are lost due to file manipulation, the user can provide them through the markerNames parameter.</p> <pre><code># Path to all the files that are necessary files for running generateGatorScore\nsegmentationPath = projectDir + '/segmentation/exampleSegmentationMask.tif'\nprobabilityMaskPath = projectDir + '/GATOR/gatorPredict/exampleImage_gatorPredict.ome.tif'\n</code></pre> <pre><code>ga.generateGatorScore(probabilityMaskPath=probabilityMaskPath,\n                      segmentationMaskPath=segmentationPath,\n                      feature='median',\n                      projectDir=projectDir)\n</code></pre> <pre><code>Quantifying the probability masks\ngatorScore is ready, head over to/Users/aj/Desktop/gatorExampleData/GATOR/gatorScore\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python generateGatorScore.py --probabilityMaskPath /Users/aj/Desktop/gatorExampleData/GATOR/gatorPredict/exampleImage_gatorPredict.ome.tif \\\n                            --segmentationMask /Users/aj/Desktop/gatorExampleData/segmentation/exampleSegmentationMask.tif \\\n                            --projectDir /Users/aj/Desktop/gatorExampleData/\n</code></pre></p> <p>If you head over to <code>GATOR/gatorScore/</code>, you will find the <code>.csv</code> file with the gatorScores for every cell.</p>"},{"location":"Tutorials/RunGatorAlgorithm/#step-3-create-a-gator-object","title":"Step-3: Create a Gator object","text":"<p>We'll use the anndata framework to create a gator object to store all information in one file, making it easier to keep track of intermediate files generated in subsequent steps.  This helps streamline the data analysis process and reduces the risk of losing or misplacing information.</p> <pre><code># Path to all the files that are necessary files for running gatorObject function\nsegmentationPath = projectDir + '/segmentation/exampleSegmentationMask.tif'\ngatorScorePath = projectDir + '/GATOR/gatorScore/exampleImage_gatorPredict.ome.csv'\n</code></pre> <pre><code># please note that there are a number of defaults in the below function that assumes certain structure within the spatialTable.\n# Please confirm it is similar with user data or modifiy the parameters accordingly\n# check out the documentation for further details\nadata = ga.gatorObject (spatialTablePath=spatialTablePath,\n                        gatorScorePath=gatorScorePath,\n                        CellId='CellID',\n                        uniqueCellId=True,\n                        split='X_centroid',\n                        removeDNA=True,\n                        remove_string_from_name=None,\n                        log=True,\n                        dropMarkers=None,\n                        projectDir=projectDir)\n</code></pre> <pre><code>Loading exampleSpatialTable.csv\nGator Object has been created, head over to/Users/aj/Desktop/gatorExampleData/GATOR/gatorObject\" to view results\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gatorObject.py --spatialTablePath /Users/aj/Desktop/gatorExampleData/quantification/exampleSpatialTable.csv \\\n                        --gatorScorePath /Users/aj/Desktop/gatorExampleData//GATOR/gatorScore/exampleImage_gatorPredict.ome.csv \\\n                        --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre></p> <p>If you had provided <code>projectDir</code> the object would be stored in <code>GATOR/gatorObject/</code>, else, the object will be returned to memory</p>"},{"location":"Tutorials/RunGatorAlgorithm/#step-4-run-the-final-gator-algorithm","title":"Step-4: Run the final Gator Algorithm","text":"<p>The <code>gator</code> algorithm is ready to run after pre-processing. To get optimal results, consider adjusting the following parameters:</p> <ol> <li>The <code>minAbundance</code> parameter determines the minimum percentage of a marker's abundance to consider it a failure.</li> <li>It is suggested to drop background markers with the <code>dropMarkers</code> option as they can interfere with classifiers.</li> <li><code>RobustScale</code>: Scaling the data before training the classifier model has been shown to improve results. However, in our experience a simple log transformation was found to be work best. </li> </ol> <pre><code># Path to all the files that are necessary files for running gator function\ngatorObject = projectDir + '/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad'\n</code></pre> <pre><code>adata = ga.gator ( gatorObject=gatorObject,\n                    gatorScore='gatorScore',\n                    minAbundance=0.005,\n                    percentiles=[1, 20, 80, 99],\n                    dropMarkers = None,\n                    RobustScale=False,\n                    log=True,\n                    x_coordinate='X_centroid',\n                    y_coordinate='Y_centroid',\n                    imageid='imageid',\n                    random_state=0,\n                    rescaleMethod='sigmoid',\n                    label='gatorOutput',\n                    verbose=False,\n                   projectDir=projectDir)\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python gator.py --gatorObject /Users/aj/Desktop/gatorExampleData/GATOR/gatorObject/exampleImage_gatorPredict.ome.h5ad \\\n                --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre></p> <p>If <code>projectDir</code> is provided, modified anndata object with results (stored in <code>adata.uns['gatorOutput']</code>) will be saved in <code>GATOR/gatorOutput/</code>. The gator-scaled data (stored in <code>adata.X</code>) considers cells above 0.5 as positive and below 0.5 as negative for the marker.</p>"},{"location":"Tutorials/RunGatorAlgorithm/#step-5-merge-multiple-gator-objects-optional","title":"Step-5: Merge multiple Gator objects (optional)","text":"<p>Use <code>mergeGatorObject</code> to combine multiple gatorObjects into a dataset for analysis when multiple images need to be analyzed.</p> <p>Note that merging gatorObjects requires merging multiple sections, not simple concatenation. Use parameters to specify which parts of the gatorObjects to merge.</p> <pre><code># set the working directory &amp; set paths to the example data\ngatorObjects = [projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad',\n                projectDir + '/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad']\n</code></pre> <pre><code># For this tutorial, supply the same gatorObject twice for merging, but multiple gatorObjects can be merged in ideal conditions.\nadata = ga.mergeGatorObject ( gatorObjects=gatorObjects,\n                              fileName='mergedGatorObject',\n                              layers=['preProcessed'],\n                              uns= ['gatorOutput','gatorScore'],\n                              projectDir=projectDir)\n</code></pre> <pre><code>Extracting data\nExtracting data from: exampleSpatialTable\nExtracting data from: exampleSpatialTable\n\n\n/opt/anaconda3/envs/gator/lib/python3.9/site-packages/anndata/_core/anndata.py:1828: UserWarning: Observation names are not unique. To make them unique, call `.obs_names_make_unique`.\n  utils.warn_names_duplicates(\"obs\")\n</code></pre> <p>Same function if the user wants to run it via Command Line Interface <pre><code>python mergeGatorObject.py --gatorObjects /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad /Users/aj/Desktop/gatorExampleData/GATOR/gatorOutput/exampleImage_gatorPredict.ome.h5ad --projectDir /Users/aj/Desktop/gatorExampleData\n</code></pre></p> <p>If <code>projectDir</code> is provided, modified anndata object with results will be saved in <code>GATOR/mergedGatorObject/</code>.</p> <pre><code># this tutorial ends here. Move to the Phenotyping cells Tutorial\n</code></pre>"},{"location":"Tutorials/SetUp/","title":"\ud83d\udc0a Setting up Gator","text":""},{"location":"Tutorials/SetUp/#kindly-note-that-gator-is-not-a-plug-and-play-solution-rather-its-a-framework-that-requires-significant-upfront-investment-of-time-from-potential-users-for-training-and-validating-deep-learning-models-which-can-then-be-utilized-in-a-plug-and-play-manner-for-processing-large-volumes-of-similar-multiplexed-imaging-data","title":"Kindly note that Gator is not a plug-and-play solution, rather it's a framework that requires significant upfront investment of time from potential users for training and validating deep learning models, which can then be utilized in a plug-and-play manner for processing large volumes of similar multiplexed imaging data.","text":"<p>There are two ways to set it up based on how you would like to run the program - Using an interactive environment like Jupyter Notebooks - Using Command Line Interface</p> <p>Before we set up Gator, we highly recommend using a environment manager like Conda. Using an environment manager like Conda allows you to create and manage isolated environments with specific package versions and dependencies. </p> <p>Download and Install the right conda based on the opertating system that you are using</p>"},{"location":"Tutorials/SetUp/#lets-create-a-new-conda-environment-and-install-gator","title":"Let's create a new conda environment and install Gator","text":"<pre><code># use the terminal (mac/linux) and anaconda promt (windows) to run the following command\nconda create --name gator -y python=3.9\n</code></pre> <p>Install <code>gatorpy</code> within the conda environment.</p> <pre><code>conda activate gator\npip install gatorpy\n</code></pre>"},{"location":"Tutorials/SetUp/#download-the-exemplar-dataset","title":"Download the Exemplar Dataset","text":"<p>To help you get used to the program we have provided some dummy data.  Download link to the exemplar dataset provided here. All of the following files are mandatory for running Gator, but <code>phenotype_workflow.csv</code> is optional and can be skipped if single cell phenotyping is not required. <pre><code>gatorExampleData\n\u251c\u2500\u2500 image\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 exampleImage.tif\n\u251c\u2500\u2500 markers.csv\n\u251c\u2500\u2500 phenotype_workflow.csv\n\u251c\u2500\u2500 quantification\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 exampleSpatialTable.csv\n\u2514\u2500\u2500 segmentation\n    \u2514\u2500\u2500 exampleSegmentationMask.tif\n</code></pre></p>"},{"location":"Tutorials/SetUp/#method-1-set-up-jupyter-notebook-if-you-would-like-to-run-gator-in-an-interactive-setting","title":"Method 1: Set up Jupyter Notebook (If you would like to run Gator in an interactive setting)","text":"<p>Install jupyter notebook within the conda environment <pre><code>conda activate gator\npip install notebook\n</code></pre> After installation, open Jupyter Notebook by typing the following command in the terminal, ensuring that the Gator environment is activated and you are within the environment before executing the jupyter notebook command. <pre><code>jupyter notebook\n</code></pre> We will talk about how to run Gator in the next tutorial.</p>"},{"location":"Tutorials/SetUp/#method-2-set-up-command-line-interface-if-you-like-to-run-gator-in-the-cli-hpc-etc","title":"Method 2: Set up Command Line Interface (If you like to run Gator in the CLI, HPC, etc)","text":"<p>Activate the conda environment that you created earlier <pre><code>conda activate gator\n</code></pre></p> <p>Download the gator program from github <pre><code>wget https://github.com/nirmalLab/gatorpy/archive/main.zip\nunzip main.zip \ncd gatorpy-main/gatorpy \n</code></pre> We will talk about how to run Gator in the next tutorial.</p>"}]}